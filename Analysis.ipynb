{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "import scipy.optimize as opt\n",
    "import lucem_illud_2020\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>weights</th>\n",
       "      <th>state_cate</th>\n",
       "      <th>state_dummy_1</th>\n",
       "      <th>state_dummy_2</th>\n",
       "      <th>state_dummy_3</th>\n",
       "      <th>state_dummy_4</th>\n",
       "      <th>state_dummy_5</th>\n",
       "      <th>state_dummy_6</th>\n",
       "      <th>...</th>\n",
       "      <th>precaution_dummy</th>\n",
       "      <th>retire_dummy</th>\n",
       "      <th>fin_par_dummy</th>\n",
       "      <th>math_perceived_cate</th>\n",
       "      <th>fin_perceived_cate</th>\n",
       "      <th>interest_q</th>\n",
       "      <th>inflation_q</th>\n",
       "      <th>bond_q</th>\n",
       "      <th>mortgage_q</th>\n",
       "      <th>mutual_q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012010001</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.363417</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012010002</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.173593</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012010003</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.577671</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012010004</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.577671</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012010005</td>\n",
       "      <td>2012</td>\n",
       "      <td>2.167569</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012010006</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.513483</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012010007</td>\n",
       "      <td>2012</td>\n",
       "      <td>2.234989</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012010008</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.753603</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012010009</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.576065</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012010010</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.466195</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012010011</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.338353</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012010012</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.415504</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012010013</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.134205</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012010014</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.550855</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012010015</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.352778</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  year   weights  state_cate  state_dummy_1  state_dummy_2  \\\n",
       "0   2012010001  2012  0.363417          24              0              0   \n",
       "1   2012010002  2012  1.173593          10              0              0   \n",
       "2   2012010003  2012  1.577671          23              0              0   \n",
       "3   2012010004  2012  1.577671          14              0              0   \n",
       "4   2012010005  2012  2.167569          44              0              0   \n",
       "5   2012010006  2012  0.513483          25              0              0   \n",
       "6   2012010007  2012  2.234989          31              0              0   \n",
       "7   2012010008  2012  0.753603          22              0              0   \n",
       "8   2012010009  2012  1.576065           5              0              0   \n",
       "9   2012010010  2012  1.466195           4              0              0   \n",
       "10  2012010011  2012  1.338353          14              0              0   \n",
       "11  2012010012  2012  0.415504           7              0              0   \n",
       "12  2012010013  2012  1.134205          38              0              0   \n",
       "13  2012010014  2012  1.550855           5              0              0   \n",
       "14  2012010015  2012  1.352778          38              0              0   \n",
       "\n",
       "    state_dummy_3  state_dummy_4  state_dummy_5  state_dummy_6  ...  \\\n",
       "0               0              0              0              0  ...   \n",
       "1               0              0              0              0  ...   \n",
       "2               0              0              0              0  ...   \n",
       "3               0              0              0              0  ...   \n",
       "4               0              0              0              0  ...   \n",
       "5               0              0              0              0  ...   \n",
       "6               0              0              0              0  ...   \n",
       "7               0              0              0              0  ...   \n",
       "8               0              0              1              0  ...   \n",
       "9               0              1              0              0  ...   \n",
       "10              0              0              0              0  ...   \n",
       "11              0              0              0              0  ...   \n",
       "12              0              0              0              0  ...   \n",
       "13              0              0              1              0  ...   \n",
       "14              0              0              0              0  ...   \n",
       "\n",
       "    precaution_dummy  retire_dummy  fin_par_dummy  math_perceived_cate  \\\n",
       "0                  0             0              1                    7   \n",
       "1                  0             0              0                    6   \n",
       "2                  1             0              0                    7   \n",
       "3                  0             0              1                    4   \n",
       "4                  1             0              0                    6   \n",
       "5                  0             0              1                    1   \n",
       "6                  1             1              1                    7   \n",
       "7                  1             0              0                    5   \n",
       "8                  1             0              0                    5   \n",
       "9                  0             0              0                    2   \n",
       "10                 1             0              1                    3   \n",
       "11                 0             0              0                    5   \n",
       "12                 0             0              0                    7   \n",
       "13                 0             0              0                    6   \n",
       "14                 1             1              0                    6   \n",
       "\n",
       "    fin_perceived_cate  interest_q  inflation_q  bond_q  mortgage_q  mutual_q  \n",
       "0                    6           1            1       3           1         1  \n",
       "1                    5           1            2       2           2         2  \n",
       "2                    5           1            1       2           1         1  \n",
       "3                    4           3            2       2           2         2  \n",
       "4                    6           1            3       2           1         3  \n",
       "5                    6           1            3       3           1         3  \n",
       "6                    6           3            1       3           1         1  \n",
       "7                    3           1            1       3           1         1  \n",
       "8                    4           3            1       1           1         2  \n",
       "9                    5           1            3       3           1         2  \n",
       "10                   4           1            3       1           1         1  \n",
       "11                   5           1            1       1           1         2  \n",
       "12                   5           1            1       1           1         1  \n",
       "13                   4           3            1       3           2         2  \n",
       "14                   5           1            2       1           3         2  \n",
       "\n",
       "[15 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "'''\n",
    "dtype_dic= {'year': pd.Int64Dtype(), \n",
    "            'state_cate': pd.Int64Dtype(),\n",
    "            'age_cate': pd.Int64Dtype(),\n",
    "            'age': pd.Int64Dtype(),\n",
    "            'female_dummy': pd.Int64Dtype(),\n",
    "            'nonwhite_dummy': pd.Int64Dtype(),\n",
    "            'marital_dummy': pd.Int64Dtype(),\n",
    "            'educ_cate': pd.Int64Dtype(),\n",
    "            'high_school_dummy': pd.Int64Dtype(),\n",
    "            'college_dummy': pd.Int64Dtype(),\n",
    "            'graduate_dummy': pd.Int64Dtype(),\n",
    "            'income_cate': pd.Int64Dtype(),\n",
    "            'income': pd.Int64Dtype(),\n",
    "            'precaution_dummy': pd.Int64Dtype(),\n",
    "            'retire_dummy': pd.Int64Dtype(),\n",
    "            'fin_par_dummy': pd.Int64Dtype(),\n",
    "            'math_perceived_cate': pd.Int64Dtype(),\n",
    "            'fin_perceived_cate': pd.Int64Dtype(),\n",
    "            'interest_q': pd.Int64Dtype(),\n",
    "            'inflation_q': pd.Int64Dtype(),\n",
    "            'bond_q': pd.Int64Dtype(),\n",
    "            'compound_q': pd.Int64Dtype(),\n",
    "            'mortgage_q': pd.Int64Dtype(),\n",
    "            'mutual_q': pd.Int64Dtype()}\n",
    "'''\n",
    "df = pd.read_csv(\"processed_NFCS.csv\")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all correct and all incorrect indicator\n",
    "correct_indicator = (df[['interest_q', 'inflation_q', 'bond_q', 'mortgage_q', 'mutual_q']] == 1).sum(axis=1) == 5\n",
    "df['q_all_correct'] = correct_indicator\n",
    "incorrect_indicator = (df[['interest_q', 'inflation_q', 'bond_q', 'mortgage_q', 'mutual_q']] == 1).sum(axis=1) == 0\n",
    "df['q_all_incorrect'] = incorrect_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct pre-trained overconfidence measure\n",
    "df['overconfidence'] = np.nan\n",
    "one_indicator = df['q_all_incorrect'] & (df['math_perceived_cate'] > 5) & (df['fin_perceived_cate'] > 5)\n",
    "zero_indicator = ((df['q_all_incorrect'] & (df['math_perceived_cate'] < 3) & (df['fin_perceived_cate'] < 3)) | \n",
    "                  (df['q_all_correct'] & (df['math_perceived_cate'] > 5) & (df['fin_perceived_cate'] > 5)))\n",
    "df.loc[one_indicator, 'overconfidence'] = 1\n",
    "df.loc[zero_indicator, 'overconfidence'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>weights</th>\n",
       "      <th>state_cate</th>\n",
       "      <th>state_dummy_1</th>\n",
       "      <th>state_dummy_2</th>\n",
       "      <th>state_dummy_3</th>\n",
       "      <th>state_dummy_4</th>\n",
       "      <th>state_dummy_5</th>\n",
       "      <th>state_dummy_6</th>\n",
       "      <th>...</th>\n",
       "      <th>math_perceived_cate</th>\n",
       "      <th>fin_perceived_cate</th>\n",
       "      <th>interest_q</th>\n",
       "      <th>inflation_q</th>\n",
       "      <th>bond_q</th>\n",
       "      <th>mortgage_q</th>\n",
       "      <th>mutual_q</th>\n",
       "      <th>q_all_correct</th>\n",
       "      <th>q_all_incorrect</th>\n",
       "      <th>overconfidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2012010047</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.679737</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2012010082</td>\n",
       "      <td>2012</td>\n",
       "      <td>2.234989</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2012010085</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.178272</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2012010100</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.697046</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2012010114</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.086083</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80108</th>\n",
       "      <td>2018037036</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.385926</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80113</th>\n",
       "      <td>2018037041</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.469334</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80121</th>\n",
       "      <td>2018037049</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.404002</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80132</th>\n",
       "      <td>2018037060</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.485971</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80147</th>\n",
       "      <td>2018037075</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.385926</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8364 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  year   weights  state_cate  state_dummy_1  state_dummy_2  \\\n",
       "46     2012010047  2012  1.679737           5              0              0   \n",
       "81     2012010082  2012  2.234989          31              0              0   \n",
       "84     2012010085  2012  1.178272          14              0              0   \n",
       "99     2012010100  2012  1.697046          50              0              0   \n",
       "113    2012010114  2012  1.086083          47              0              0   \n",
       "...           ...   ...       ...         ...            ...            ...   \n",
       "80108  2018037036  2018  0.385926          51              0              0   \n",
       "80113  2018037041  2018  0.469334          51              0              0   \n",
       "80121  2018037049  2018  0.404002          51              0              0   \n",
       "80132  2018037060  2018  0.485971          51              0              0   \n",
       "80147  2018037075  2018  0.385926          51              0              0   \n",
       "\n",
       "       state_dummy_3  state_dummy_4  state_dummy_5  state_dummy_6  ...  \\\n",
       "46                 0              0              1              0  ...   \n",
       "81                 0              0              0              0  ...   \n",
       "84                 0              0              0              0  ...   \n",
       "99                 0              0              0              0  ...   \n",
       "113                0              0              0              0  ...   \n",
       "...              ...            ...            ...            ...  ...   \n",
       "80108              0              0              0              0  ...   \n",
       "80113              0              0              0              0  ...   \n",
       "80121              0              0              0              0  ...   \n",
       "80132              0              0              0              0  ...   \n",
       "80147              0              0              0              0  ...   \n",
       "\n",
       "       math_perceived_cate  fin_perceived_cate  interest_q  inflation_q  \\\n",
       "46                       7                   6           1            1   \n",
       "81                       7                   6           1            1   \n",
       "84                       7                   6           1            1   \n",
       "99                       7                   6           1            1   \n",
       "113                      7                   7           1            1   \n",
       "...                    ...                 ...         ...          ...   \n",
       "80108                    6                   6           1            1   \n",
       "80113                    7                   6           1            1   \n",
       "80121                    6                   6           1            1   \n",
       "80132                    7                   6           1            1   \n",
       "80147                    7                   7           1            1   \n",
       "\n",
       "       bond_q  mortgage_q  mutual_q  q_all_correct  q_all_incorrect  \\\n",
       "46          1           1         1           True            False   \n",
       "81          1           1         1           True            False   \n",
       "84          1           1         1           True            False   \n",
       "99          1           1         1           True            False   \n",
       "113         1           1         1           True            False   \n",
       "...       ...         ...       ...            ...              ...   \n",
       "80108       1           1         1           True            False   \n",
       "80113       1           1         1           True            False   \n",
       "80121       1           1         1           True            False   \n",
       "80132       1           1         1           True            False   \n",
       "80147       1           1         1           True            False   \n",
       "\n",
       "       overconfidence  \n",
       "46                0.0  \n",
       "81                0.0  \n",
       "84                0.0  \n",
       "99                0.0  \n",
       "113               0.0  \n",
       "...               ...  \n",
       "80108             0.0  \n",
       "80113             0.0  \n",
       "80121             0.0  \n",
       "80132             0.0  \n",
       "80147             0.0  \n",
       "\n",
       "[8364 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a dataframe for machine learning\n",
    "ml_df = df.loc[df['overconfidence'].notnull(), :].copy()\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>weights</th>\n",
       "      <th>state_cate</th>\n",
       "      <th>state_dummy_1</th>\n",
       "      <th>state_dummy_2</th>\n",
       "      <th>state_dummy_3</th>\n",
       "      <th>state_dummy_4</th>\n",
       "      <th>state_dummy_5</th>\n",
       "      <th>state_dummy_6</th>\n",
       "      <th>...</th>\n",
       "      <th>math_perceived_cate</th>\n",
       "      <th>fin_perceived_cate</th>\n",
       "      <th>interest_q</th>\n",
       "      <th>inflation_q</th>\n",
       "      <th>bond_q</th>\n",
       "      <th>mortgage_q</th>\n",
       "      <th>mutual_q</th>\n",
       "      <th>q_all_correct</th>\n",
       "      <th>q_all_incorrect</th>\n",
       "      <th>overconfidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012010001</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.363417</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012010002</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.173593</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012010003</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.577671</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012010004</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.577671</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012010005</td>\n",
       "      <td>2012</td>\n",
       "      <td>2.167569</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80159</th>\n",
       "      <td>2018037087</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.404002</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80160</th>\n",
       "      <td>2018037088</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.475130</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80161</th>\n",
       "      <td>2018037089</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.531368</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80162</th>\n",
       "      <td>2018037090</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.377318</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80163</th>\n",
       "      <td>2018037091</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.475130</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71800 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  year   weights  state_cate  state_dummy_1  state_dummy_2  \\\n",
       "0      2012010001  2012  0.363417          24              0              0   \n",
       "1      2012010002  2012  1.173593          10              0              0   \n",
       "2      2012010003  2012  1.577671          23              0              0   \n",
       "3      2012010004  2012  1.577671          14              0              0   \n",
       "4      2012010005  2012  2.167569          44              0              0   \n",
       "...           ...   ...       ...         ...            ...            ...   \n",
       "80159  2018037087  2018  0.404002          51              0              0   \n",
       "80160  2018037088  2018  0.475130          20              0              0   \n",
       "80161  2018037089  2018  0.531368          20              0              0   \n",
       "80162  2018037090  2018  0.377318          20              0              0   \n",
       "80163  2018037091  2018  0.475130          20              0              0   \n",
       "\n",
       "       state_dummy_3  state_dummy_4  state_dummy_5  state_dummy_6  ...  \\\n",
       "0                  0              0              0              0  ...   \n",
       "1                  0              0              0              0  ...   \n",
       "2                  0              0              0              0  ...   \n",
       "3                  0              0              0              0  ...   \n",
       "4                  0              0              0              0  ...   \n",
       "...              ...            ...            ...            ...  ...   \n",
       "80159              0              0              0              0  ...   \n",
       "80160              0              0              0              0  ...   \n",
       "80161              0              0              0              0  ...   \n",
       "80162              0              0              0              0  ...   \n",
       "80163              0              0              0              0  ...   \n",
       "\n",
       "       math_perceived_cate  fin_perceived_cate  interest_q  inflation_q  \\\n",
       "0                        7                   6           1            1   \n",
       "1                        6                   5           1            2   \n",
       "2                        7                   5           1            1   \n",
       "3                        4                   4           3            2   \n",
       "4                        6                   6           1            3   \n",
       "...                    ...                 ...         ...          ...   \n",
       "80159                    4                   5           1            3   \n",
       "80160                    2                   4           1            3   \n",
       "80161                    5                   5           1            1   \n",
       "80162                    7                   4           1            3   \n",
       "80163                    7                   6           1            1   \n",
       "\n",
       "       bond_q  mortgage_q  mutual_q  q_all_correct  q_all_incorrect  \\\n",
       "0           3           1         1          False            False   \n",
       "1           2           2         2          False            False   \n",
       "2           2           1         1          False            False   \n",
       "3           2           2         2          False             True   \n",
       "4           2           1         3          False            False   \n",
       "...       ...         ...       ...            ...              ...   \n",
       "80159       3           1         1          False            False   \n",
       "80160       2           2         2          False            False   \n",
       "80161       3           2         2          False            False   \n",
       "80162       3           1         1          False            False   \n",
       "80163       3           1         3          False            False   \n",
       "\n",
       "       overconfidence  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "80159             NaN  \n",
       "80160             NaN  \n",
       "80161             NaN  \n",
       "80162             NaN  \n",
       "80163             NaN  \n",
       "\n",
       "[71800 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a dataframe for out-of-sample prediction\n",
    "pr_df = df.loc[~df['overconfidence'].notnull(), :].copy()\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dependent and independent variable\n",
    "state_dummy_list = ['state_dummy_{}'.format(i) for i in range(1, 52)]\n",
    "X_list = state_dummy_list + ['age', 'female_dummy', 'nonwhite_dummy', 'marital_dummy', 'high_school_dummy', \n",
    "                             'college_dummy', 'graduate_dummy', 'income', 'math_perceived_cate', \n",
    "                             'fin_perceived_cate', 'interest_q', 'inflation_q', 'bond_q', 'mortgage_q', 'mutual_q']\n",
    "X = ml_df[X_list]\n",
    "y = ml_df['overconfidence']\n",
    "X_pred = pr_df[X_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal tuning parameter values from randomized hyperparameter search are\n",
      " {'C': 4.267109966596578, 'penalty': 'l1'}\n",
      "The MSE of the optimal results is 0.0003586800573888092\n",
      "\n",
      "Total time used: 7 min 18 s\n"
     ]
    }
   ],
   "source": [
    "# Specify parameter distributions as suggested\n",
    "param_dist_1 = {'C': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "overconfidence_clf_1 = LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "\n",
    "# Run randomized hyperparameter search\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "random_search_1 = RandomizedSearchCV(overconfidence_clf_1, param_distributions=param_dist_1,\n",
    "                                     n_iter=1000, n_jobs=4, cv=5, random_state=0,\n",
    "                                     scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_1.fit(X, y, sample_weight=ml_df['weights'])\n",
    "\n",
    "running_time = timeit.default_timer() - start_time\n",
    "\n",
    "print('The optimal tuning parameter values from randomized hyperparameter search are\\n',\n",
    "      random_search_1.best_params_)\n",
    "print('The MSE of the optimal results is', -random_search_1.best_score_)\n",
    "if running_time < 60:\n",
    "    print('\\nTotal time used: {:.0f} s'.format(running_time))\n",
    "else:\n",
    "    print('\\nTotal time used: {:.0f} min {:.0f} s'.format(running_time // 60, running_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of sample prediction\n",
    "overconfidence_clf_1o = LogisticRegression(C=random_search_1.best_params_['C'], \n",
    "                                           penalty='l2',\n",
    "                                           solver='lbfgs',\n",
    "                                           random_state=0)\n",
    "\n",
    "overconfidence_clf_1o.fit(X, y, sample_weight=ml_df['weights'])\n",
    "\n",
    "y_pred_1 = overconfidence_clf_1o.predict_proba(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df['overconfidence_logit'] = y_pred_1[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal tuning parameter values from randomized hyperparameter search are\n",
      " {'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 12, 'min_samples_split': 10, 'n_estimators': 12}\n",
      "The MSE of the optimal results is 0.006097560975609756\n",
      "\n",
      "Total time used: 26 min 40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/Anaconda3-5.3.0-el7-x86_64/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/software/Anaconda3-5.3.0-el7-x86_64/lib/python3.6/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/software/Anaconda3-5.3.0-el7-x86_64/lib/python3.6/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "# Specify parameter distributions as suggested\n",
    "param_dist_2 = {'n_estimators': sp_randint(10, 200),\n",
    "                'max_depth': sp_randint(2, 4),\n",
    "                'min_samples_split': sp_randint(2, 20),\n",
    "                'min_samples_leaf': sp_randint(2, 20),\n",
    "                'max_features': sp_randint(1, 4)}\n",
    "\n",
    "overconfidence_clf_2 = RandomForestClassifier(bootstrap=True, oob_score=True)\n",
    "\n",
    "# Run randomized hyperparameter search\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "random_search_2 = RandomizedSearchCV(overconfidence_clf_2, param_distributions=param_dist_2,\n",
    "                                     n_iter=1000, n_jobs=4, cv=5, random_state=0,\n",
    "                                     scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_2.fit(X, y)\n",
    "\n",
    "running_time = timeit.default_timer() - start_time\n",
    "\n",
    "print('The optimal tuning parameter values from randomized hyperparameter search are\\n',\n",
    "      random_search_2.best_params_)\n",
    "print('The MSE of the optimal results is', -random_search_2.best_score_)\n",
    "if running_time < 60:\n",
    "    print('\\nTotal time used: {:.0f} s'.format(running_time))\n",
    "else:\n",
    "    print('\\nTotal time used: {:.0f} min {:.0f} s'.format(running_time // 60, running_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of sample prediction\n",
    "overconfidence_clf_2o = RandomForestClassifier(bootstrap=True, \n",
    "                                               oob_score=True,\n",
    "                                               n_estimators=random_search_2.best_params_['n_estimator'],\n",
    "                                               max_depth=random_search_2.best_params_['max_depth'],\n",
    "                                               min_samples_split=random_search_2.best_params_['min_samples_split'],\n",
    "                                               min_samples_leaf=random_search_2.best_params_['min_samples_leaf'],\n",
    "                                               max_features=random_search_2.best_params_['max_features'],\n",
    "                                               random_state=0)\n",
    "\n",
    "overconfidence_clf_2o.fit(X, y, sample_weight=ml_df['weights'])\n",
    "\n",
    "y_pred_2 = overconfidence_clf_2o.predict_proba(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df['overconfidence_forest'] = y_pred_2[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal tuning parameter values from randomized hyperparameter search are\n",
      " {'C': 2.8883894070106906, 'gamma': 'auto', 'shrinking': False}\n",
      "The MSE of the optimal results is -0.0\n",
      "\n",
      "Total time used: 196 min 53 s\n"
     ]
    }
   ],
   "source": [
    "# Specify parameter distributions as suggested\n",
    "param_dist_3 = {'C': sp_uniform(loc=0.1, scale=10.0),\n",
    "                'gamma': ['scale', 'auto'],\n",
    "                'shrinking': [True, False]}\n",
    "\n",
    "overconfidence_clf_3 = SVC(kernel='rbf')\n",
    "\n",
    "# Run randomized hyperparameter search\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "random_search_3 = RandomizedSearchCV(overconfidence_clf_3, param_distributions=param_dist_3,\n",
    "                                     n_iter=1000, n_jobs=4, cv=5, random_state=0,\n",
    "                                     scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_3.fit(X, y)\n",
    "\n",
    "running_time = timeit.default_timer() - start_time\n",
    "\n",
    "print('The optimal tuning parameter values from randomized hyperparameter search are\\n',\n",
    "      random_search_3.best_params_)\n",
    "print('The MSE of the optimal results is', -random_search_3.best_score_)\n",
    "if running_time < 60:\n",
    "    print('\\nTotal time used: {:.0f} s'.format(running_time))\n",
    "else:\n",
    "    print('\\nTotal time used: {:.0f} min {:.0f} s'.format(running_time // 60, running_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of sample prediction\n",
    "overconfidence_clf_3o = SVC(kernel='rbf',\n",
    "                            C=random_search_3.best_params_['C'],\n",
    "                            gamma=random_search_3.best_params_['gamma'],\n",
    "                            shrinking=random_search_3.best_params_['shrinking'],\n",
    "                            random_state=0)\n",
    "\n",
    "overconfidence_clf_3o.fit(X, y, sample_weight=ml_df['weights'])\n",
    "\n",
    "y_pred_3 = overconfidence_clf_3o.predict_proba(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df['overconfidence_svm'] = y_pred_3[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal tuning parameter values from randomized hyperparameter search are\n",
      " {'alpha': 10.097876950070463}\n",
      "The MSE of the optimal results is 0.009745304232805565\n",
      "\n",
      "Total time used: 1 min 43 s\n"
     ]
    }
   ],
   "source": [
    "# Specify parameter distributions as suggested\n",
    "param_dist_4 = {'alpha': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "overconfidence_clf_4 = Ridge()\n",
    "\n",
    "# Run randomized hyperparameter search\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "random_search_4 = RandomizedSearchCV(overconfidence_clf_4, param_distributions=param_dist_4,\n",
    "                                     n_iter=1000, n_jobs=4, cv=5, random_state=0,\n",
    "                                     scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_4.fit(X, y)\n",
    "\n",
    "running_time = timeit.default_timer() - start_time\n",
    "\n",
    "print('The optimal tuning parameter values from randomized hyperparameter search are\\n',\n",
    "      random_search_4.best_params_)\n",
    "print('The MSE of the optimal results is', -random_search_4.best_score_)\n",
    "if running_time < 60:\n",
    "    print('\\nTotal time used: {:.0f} s'.format(running_time))\n",
    "else:\n",
    "    print('\\nTotal time used: {:.0f} min {:.0f} s'.format(running_time // 60, running_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of sample prediction\n",
    "overconfidence_clf_4o = Ridge(alpha=random_search_4.best_params_['alpha'],\n",
    "                              random_state=0)\n",
    "\n",
    "overconfidence_clf_4o.fit(X, y, sample_weight=ml_df['weights'])\n",
    "\n",
    "y_pred_4 = overconfidence_clf_4o.predict_proba(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df['overconfidence_ridge'] = y_pred_4[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal tuning parameter values from randomized hyperparameter search are\n",
      " {'alpha': 0.1021661566151221}\n",
      "The MSE of the optimal results is 0.08009352459180479\n",
      "\n",
      "Total time used: 1 min 34 s\n"
     ]
    }
   ],
   "source": [
    "# Specify parameter distributions as suggested\n",
    "param_dist_5 = {'alpha': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "overconfidence_clf_5 = Lasso()\n",
    "\n",
    "# Run randomized hyperparameter search\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "random_search_5 = RandomizedSearchCV(overconfidence_clf_5, param_distributions=param_dist_5,\n",
    "                                     n_iter=1000, n_jobs=4, cv=5, random_state=25,\n",
    "                                     scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_5.fit(X, y)\n",
    "\n",
    "running_time = timeit.default_timer() - start_time\n",
    "\n",
    "print('The optimal tuning parameter values from randomized hyperparameter search are\\n',\n",
    "      random_search_5.best_params_)\n",
    "print('The MSE of the optimal results is', -random_search_5.best_score_)\n",
    "if running_time < 60:\n",
    "    print('\\nTotal time used: {:.0f} s'.format(running_time))\n",
    "else:\n",
    "    print('\\nTotal time used: {:.0f} min {:.0f} s'.format(running_time // 60, running_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of sample prediction\n",
    "overconfidence_clf_5o = Lasso(alpha=random_search_5.best_params_['alpha'],\n",
    "                              random_state=0)\n",
    "\n",
    "overconfidence_clf_5o.fit(X, y, sample_weight=ml_df['weights'])\n",
    "\n",
    "y_pred_5 = overconfidence_clf_5o.predict_proba(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df['overconfidence_lasso'] = y_pred_5[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MLPClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e83a8c920116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 'alpha': sp_uniform(0.1, 10.0)}\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moverconfidence_clf_6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Run randomized hyperparameter search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MLPClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify parameter distributions as suggested\n",
    "param_dist_6 = {'hidden_layer_sizes': sp_randint(1, 100),\n",
    "                'activation': ['logistic', 'relu'],\n",
    "                'alpha': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "overconfidence_clf_6 = MLPClassifier(solver='lbfgs')\n",
    "\n",
    "# Run randomized hyperparameter search\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "random_search_6 = RandomizedSearchCV(overconfidence_clf_6, param_distributions=param_dist_6,\n",
    "                                     n_iter=1000, n_jobs=4, cv=5, random_state=25,\n",
    "                                     scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_6.fit(X, y)\n",
    "\n",
    "running_time = timeit.default_timer() - start_time \n",
    "\n",
    "print('The optimal tuning parameter values from randomized hyperparameter search are\\n',\n",
    "      random_search_6.best_params_)\n",
    "print('The MSE of the optimal results is', -random_search_6.best_score_)\n",
    "if running_time < 60:\n",
    "    print('\\nTotal time used: {:.0f} s'.format(running_time))\n",
    "else:\n",
    "    print('\\nTotal time used: {:.0f} min {:.0f} s'.format(running_time // 60, running_time % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of sample prediction\n",
    "overconfidence_clf_6o = Lasso(alpha=random_search_6.best_params_['alpha'],\n",
    "                              hidden_layer_sizes=random_search_6.best_params_['hidden_layer_sizes'],\n",
    "                              activation=random_search_6.best_params_['activation'],\n",
    "                              random_state=0)\n",
    "\n",
    "overconfidence_clf_6o.fit(X, y, sample_weight=ml_df['weights'])\n",
    "\n",
    "y_pred_6 = overconfidence_clf_6o.predict_proba(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df['overconfidence_mlp'] = y_pred_6[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '~/Overconfidence-Financial-Behaviors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dataframe for MSEs\n",
    "MSE_dict = {'method': ['Logistic', 'Forest', 'SVM', 'Ridge', 'Lasso', 'MLP'],\n",
    "            'MSE': [-random_search_1.best_score_, -random_search_2.best_score_, \n",
    "                    -random_search_3.best_score_, -random_search_4.best_score_,\n",
    "                    -random_search_5.best_score_, -random_search_6.best_score_]}\n",
    "\n",
    "MSE_df = pd.DataFrame(MSE_dict)\n",
    "MSE_df.to_csv(address + 'MSE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw a bar plot to compare MSEs\n",
    "ax = MSE_df.plot.bar(x='method', y='MSE', rot=0, legend=None)\n",
    "ax.set_title(\"MSEs of different machine learning algorithms\", fontsize=14)\n",
    "ax.set_xlabel(\"Machine learning algorithms\", fontsize=12)\n",
    "ax.set_ylabel(\"MSE\", fontsize=12)\n",
    "plt.show()\n",
    "plt.savefig(address + 'MSE.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a new dataframe for export\n",
    "full_df = ml_df.append(pr_df)\n",
    "hardcode_indicator = ~full_df['overconfidence_logit'].notnull()\n",
    "full_df.loc[hardcode_indicator, 'overconfidence_logit'] = full_df.loc[hardcode_indicator, 'overconfidence']\n",
    "full_df.loc[hardcode_indicator, 'overconfidence_forest'] = full_df.loc[hardcode_indicator, 'overconfidence']\n",
    "full_df.loc[hardcode_indicator, 'overconfidence_svm'] = full_df.loc[hardcode_indicator, 'overconfidence']\n",
    "full_df.loc[hardcode_indicator, 'overconfidence_ridge'] = full_df.loc[hardcode_indicator, 'overconfidence']\n",
    "full_df.loc[hardcode_indicator, 'overconfidence_lasso'] = full_df.loc[hardcode_indicator, 'overconfidence']\n",
    "full_df.loc[hardcode_indicator, 'overconfidence_mlp'] = full_df.loc[hardcode_indicator, 'overconfidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the dataframe\n",
    "full_df.to_csv(address + 'overconfidence_measure.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
