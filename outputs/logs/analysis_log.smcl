
. 
. * import data
. import excel "${data_dir}/overconfidence_measure.xlsx", ///
>         sheet("overconfidence_measure") firstrow

.         
. * count overconfident and not overconfident households in the learning set
. count if overconfidence == 1
  858

. count if overconfidence == 0
  7,506

. 
. * generate key variables
. *** age
. gen age2 = age^2

. *** income
. gen logincome = log(income)

. gen logincome2 = logincome^2

. *** financial literacy measure (measured by factor analysis score and normalized)
. ***** factor analysis
. gen interest_q_c = interest_q == 1

. gen inflation_q_c = inflation_q == 1

. gen bond_q_c = bond_q == 1

. gen mortgage_q_c = mortgage_q == 1

. gen mutual_q_c = mutual_q == 1

. factor *q_c, pcf
(obs=80,164)

Factor analysis/correlation                      Number of obs    =     80,164
    Method: principal-component factors          Retained factors =          1
    Rotation: (unrotated)                        Number of params =          5

    --------------------------------------------------------------------------
         Factor  |   Eigenvalue   Difference        Proportion   Cumulative
    -------------+------------------------------------------------------------
        Factor1  |      2.08551      1.15877            0.4171       0.4171
        Factor2  |      0.92674      0.22666            0.1853       0.6025
        Factor3  |      0.70008      0.00584            0.1400       0.7425
        Factor4  |      0.69424      0.10083            0.1388       0.8813
        Factor5  |      0.59341            .            0.1187       1.0000
    --------------------------------------------------------------------------
    LR test: independent vs. saturated:  chi2(10) = 4.7e+04 Prob>chi2 = 0.0000

Factor loadings (pattern matrix) and unique variances

    ---------------------------------------
        Variable |  Factor1 |   Uniqueness 
    -------------+----------+--------------
    interest_q_c |   0.6435 |      0.5859  
    inflation_~c |   0.7315 |      0.4649  
        bond_q_c |   0.4972 |      0.7528  
    mortgage_q_c |   0.6508 |      0.5765  
      mutual_q_c |   0.6824 |      0.5344  
    ---------------------------------------

. predict score
(regression scoring assumed)

Scoring coefficients (method = regression)

    ------------------------
        Variable |  Factor1 
    -------------+----------
    interest_q_c |  0.30857 
    inflation_~c |  0.35075 
        bond_q_c |  0.23839 
    mortgage_q_c |  0.31204 
      mutual_q_c |  0.32719 
    ------------------------


. ***** normalization
. summ score

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
       score |     80,164   -1.84e-09           1  -2.030406   1.336009

. gen fin_lit = (score - r(min)) / (r(max) - r(min))

. 
. * summary statistics
. estpost tabstat retire_dummy precaution_dummy fin_par_dummy female_dummy ///
>         age nonwhite_dummy marital_dummy income high_school_dummy college_dummy ///
>         fin_lit overconfidence_* ///
>         [aw=weights], statistics(p10 p50 p90 mean sd N) columns(statistics)

Summary statistics: p10 p50 p90 mean sd count
     for variables: retire_dummy precaution_dummy fin_par_dummy female_dummy age nonwhite_dummy ma
> rital_dummy income high_school_dummy college_dummy fin_lit overconfidence_bnb overconfidence_for
> est overconfidence_knn overconfidence_logit overconfidence_mlp overconfidence_svm

             |    e(p10)     e(p50)     e(p90)    e(mean)      e(sd)   e(count) 
-------------+------------------------------------------------------------------
retire_dummy |         0          0          1   .3089863   .4620784      80164 
precaution~y |         0          0          1   .4490168    .497397      80164 
fin_par_du~y |         0          0          1    .313935   .4640932      80164 
female_dummy |         0          1          1   .5136688   .4998162      80164 
         age |        20         50         70   46.34164   16.52453      80164 
nonwhite_d~y |         0          0          1   .3500791   .4769974      80164 
marital_du~y |         0          1          1   .5226527   .4994897      80164 
      income |      7500      42500     125000   62054.31   49231.67      80164 
high_schoo~y |         1          1          1   .9537342   .2100614      80164 
college_du~y |         0          0          1   .3553699   .4786282      80164 
     fin_lit |  .2138178   .6296108          1   .5800545   .2993637      80164 
overconfid~b |  .0097383    .187493    .590684   .2468887   .2308618      80164 
overconfi~st |  .0286683   .2029464   .4551141   .2335589   .1703746      80164 
overconfid~n |         0   .1546392   .4639175   .2026388   .1999288      80164 
overconfi~it |  .0018099   .1132302   .7885393   .2639741   .3010764      80164 
overconfid~p |  .0108795   .1687191   .3531788   .1894704   .1537241      80164 
overconfid~m |  .0000437   .1333883   .9999974   .3923306   .4262681      80164 

. 
. estout using "${tables_dir}/sum_stat.tex", ///
>         cells("p10 p50 p90 mean(fmt(a3)) sd(fmt(a3)) count(label(#Obs.))") ///
>         varlabels(`e(var)') sty(tex) replace
(output written to ../outputs/tables/sum_stat.tex)

. 
. local household_X "age age2 logincome logincome2 female_dummy nonwhite_dummy marital_dummy high_
> school_dummy college_dummy"

. 
. * baseline regressions with svm
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_svm fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43077.119  
Iteration 2:   log pseudolikelihood = -42834.139  
Iteration 3:   log pseudolikelihood = -42832.904  
Iteration 4:   log pseudolikelihood = -42832.904  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    7573.09
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -42832.904               Pseudo R2         =     0.1358

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |    .816695   .0361885    22.57   0.000     .7457669    .8876231
           fin_lit |   1.903958   .0576561    33.02   0.000     1.790955    2.016962
               age |   .1289217    .004202    30.68   0.000     .1206859    .1371575
              age2 |  -.0017136   .0000445   -38.52   0.000    -.0018008   -.0016264
         logincome |  -1.721525   .2383722    -7.22   0.000    -2.188726   -1.254324
        logincome2 |    .109213   .0112258     9.73   0.000     .0872109    .1312152
      female_dummy |  -.1376402   .0200817    -6.85   0.000    -.1769996   -.0982808
    nonwhite_dummy |   .0914407   .0226265     4.04   0.000     .0470935    .1357879
     marital_dummy |   -.000152   .0229813    -0.01   0.995    -.0451945    .0448904
 high_school_dummy |   .3283497   .0662079     4.96   0.000     .1985846    .4581148
     college_dummy |   .2834624   .0210729    13.45   0.000     .2421603    .3247645
                   |
              year |
             2015  |   .0212984   .0246373     0.86   0.387    -.0269899    .0695866
             2018  |   .0735256    .025168     2.92   0.003     .0241971     .122854
                   |
             _cons |   1.193582   1.258919     0.95   0.343    -1.273855    3.661018
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_svm fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .1462839   .0063667    22.98   0.000     .1338055    .1587624
           fin_lit |   .3410313   .0099262    34.36   0.000     .3215764    .3604862
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Readiness")
../outputs/tables/SVM.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_svm fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43021.121  
Iteration 2:   log pseudolikelihood = -42774.304  
Iteration 3:   log pseudolikelihood = -42773.022  
Iteration 4:   log pseudolikelihood = -42773.022  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    7665.16
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -42773.022               Pseudo R2         =     0.1370

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |     .82241   .0362728    22.67   0.000     .7513166    .8935033
           fin_lit |   1.893639   .0577569    32.79   0.000     1.780437     2.00684
               age |    .128823   .0042064    30.63   0.000     .1205785    .1370674
              age2 |  -.0017108   .0000445   -38.41   0.000    -.0017981   -.0016235
         logincome |  -1.775951   .2388341    -7.44   0.000    -2.244058   -1.307845
        logincome2 |     .11196   .0112559     9.95   0.000     .0898988    .1340212
      female_dummy |  -.1456801   .0201476    -7.23   0.000    -.1851687   -.1061916
    nonwhite_dummy |   .1141488   .0242696     4.70   0.000     .0665812    .1617164
     marital_dummy |  -.0022549   .0232207    -0.10   0.923    -.0477666    .0432569
 high_school_dummy |   .3212634   .0662886     4.85   0.000     .1913402    .4511866
     college_dummy |   .2776716   .0211887    13.10   0.000     .2361424    .3192007
                   |
              year |
             2015  |   .0210039   .0246237     0.85   0.394    -.0272576    .0692655
             2018  |   .0721174   .0251832     2.86   0.004     .0227593    .1214756
                   |
        state_cate |
                2  |    .156949   .0851227     1.84   0.065    -.0098885    .3237865
                3  |  -.0878468   .0897561    -0.98   0.328    -.2637655     .088072
                4  |  -.1424664   .0902189    -1.58   0.114    -.3192922    .0343593
                5  |   -.134816    .085408    -1.58   0.114    -.3022127    .0325807
                6  |  -.1029941   .0861838    -1.20   0.232    -.2719112    .0659231
                7  |  -.0666407   .0874753    -0.76   0.446    -.2380892    .1048079
                8  |  -.1575095   .0869825    -1.81   0.070    -.3279921    .0129731
                9  |   .0272461   .0874748     0.31   0.755    -.1442013    .1986935
               10  |  -.1155964   .0911484    -1.27   0.205     -.294244    .0630512
               11  |    .026699   .0859033     0.31   0.756    -.1416683    .1950663
               12  |   -.024613   .0886361    -0.28   0.781    -.1983367    .1491106
               13  |  -.0787176   .0866547    -0.91   0.364    -.2485577    .0911225
               14  |  -.0748481   .0845539    -0.89   0.376    -.2405708    .0908746
               15  |  -.1040199   .0866736    -1.20   0.230    -.2738969    .0658572
               16  |  -.0523651   .0866898    -0.60   0.546     -.222274    .1175437
               17  |  -.0121392   .0880243    -0.14   0.890    -.1846636    .1603852
               18  |   -.103553   .0872747    -1.19   0.235    -.2746083    .0675023
               19  |  -.0389663   .0865241    -0.45   0.652    -.2085505    .1306179
               20  |  -.0211924   .0860164    -0.25   0.805    -.1897814    .1473966
               21  |  -.0964227   .0871644    -1.11   0.269    -.2672618    .0744164
               22  |  -.1874438   .0893267    -2.10   0.036    -.3625209   -.0123667
               23  |  -.0635689   .0875257    -0.73   0.468    -.2351161    .1079783
               24  |  -.0846434   .0866836    -0.98   0.329    -.2545402    .0852534
               25  |   .0274988   .0851488     0.32   0.747    -.1393897    .1943874
               26  |  -.0853995   .0862991    -0.99   0.322    -.2545427    .0837437
               27  |   .1783344   .0854067     2.09   0.037     .0109403    .3457286
               28  |   .0053102   .0865281     0.06   0.951    -.1642817    .1749022
               29  |  -.1870042   .0894238    -2.09   0.037    -.3622716   -.0117369
               30  |   -.046742   .0869063    -0.54   0.591    -.2170752    .1235912
               31  |  -.2013005   .0885968    -2.27   0.023     -.374947   -.0276541
               32  |  -.0710909   .0895931    -0.79   0.427    -.2466902    .1045083
               33  |  -.0447972   .0849574    -0.53   0.598    -.2113105    .1217162
               34  |   -.094691    .088448    -1.07   0.284    -.2680459    .0786639
               35  |   .0909865   .0865056     1.05   0.293    -.0785613    .2605343
               36  |  -.0827426   .0868348    -0.95   0.341    -.2529356    .0874505
               37  |  -.0465641   .0875417    -0.53   0.595    -.2181427    .1250145
               38  |   .0379698   .0817916     0.46   0.642    -.1223387    .1982784
               39  |  -.1797342   .0898637    -2.00   0.045    -.3558638   -.0036046
               40  |  -.1196466   .0866319    -1.38   0.167     -.289442    .0501489
               41  |   .0085563   .0866255     0.10   0.921    -.1612265    .1783391
               42  |   .1260378   .0854689     1.47   0.140    -.0414782    .2935538
               43  |   -.034103   .0875429    -0.39   0.697     -.205684     .137478
               44  |  -.2439445   .0848134    -2.88   0.004    -.4101758   -.0777133
               45  |   .2095448   .0854546     2.45   0.014     .0420569    .3770328
               46  |  -.0697115   .0848765    -0.82   0.411    -.2360663    .0966434
               47  |   .0068165   .0872336     0.08   0.938    -.1641583    .1777912
               48  |  -.0624036   .0822023    -0.76   0.448    -.2235171    .0987099
               49  |  -.0997526   .0876187    -1.14   0.255    -.2714821     .071977
               50  |  -.0066817   .0862621    -0.08   0.938    -.1757524     .162389
               51  |    .116259   .0848083     1.37   0.170    -.0499622    .2824801
                   |
             _cons |   1.528607   1.261835     1.21   0.226    -.9445441    4.001758
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_svm fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .1470628   .0063708    23.08   0.000     .1345763    .1595493
           fin_lit |   .3386193   .0099472    34.04   0.000     .3191231    .3581155
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/SVM.tex
dir : seeout

.         
. *** precautionary saving
. ***** without state dummies
. logit precaution_dummy overconfidence_svm fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47021.181  
Iteration 2:   log pseudolikelihood = -46959.508  
Iteration 3:   log pseudolikelihood = -46959.305  
Iteration 4:   log pseudolikelihood = -46959.305  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    8585.62
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -46959.305               Pseudo R2         =     0.1485

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .8158523   .0334389    24.40   0.000     .7503133    .8813913
           fin_lit |   1.581582   .0520168    30.41   0.000     1.479631    1.683533
               age |  -.1187597   .0039239   -30.27   0.000    -.1264504    -.111069
              age2 |   .0014338   .0000414    34.64   0.000     .0013526    .0015149
         logincome |  -2.254087   .2359597    -9.55   0.000    -2.716559   -1.791614
        logincome2 |   .1422843   .0111919    12.71   0.000     .1203487      .16422
      female_dummy |  -.1706091   .0191462    -8.91   0.000     -.208135   -.1330832
    nonwhite_dummy |   .0035496   .0220125     0.16   0.872    -.0395942    .0466933
     marital_dummy |   .0333558   .0213744     1.56   0.119    -.0085372    .0752488
 high_school_dummy |   .4094395   .0604101     6.78   0.000      .291038    .5278411
     college_dummy |    .351746    .020296    17.33   0.000     .3119666    .3915255
                   |
              year |
             2015  |   .1896199   .0233708     8.11   0.000     .1438141    .2354258
             2018  |   .2911229   .0238445    12.21   0.000     .2443886    .3378573
                   |
             _cons |   7.653026    1.23882     6.18   0.000     5.224983    10.08107
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_svm fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .1636849   .0065689    24.92   0.000     .1508101    .1765597
           fin_lit |   .3173136   .0100917    31.44   0.000     .2975342     .337093
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Precaution")
../outputs/tables/SVM.tex
dir : seeout

. 
. ***** with state dummies
. logit precaution_dummy overconfidence_svm fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -46927.598  
Iteration 2:   log pseudolikelihood = -46863.052  
Iteration 3:   log pseudolikelihood = -46862.848  
Iteration 4:   log pseudolikelihood = -46862.848  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    8744.55
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -46862.848               Pseudo R2         =     0.1502

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .8204493   .0335034    24.49   0.000     .7547838    .8861148
           fin_lit |   1.592828   .0521592    30.54   0.000     1.490598    1.695058
               age |  -.1188102   .0039306   -30.23   0.000     -.126514   -.1111065
              age2 |   .0014321   .0000415    34.54   0.000     .0013508    .0015133
         logincome |  -2.190928   .2365888    -9.26   0.000    -2.654634   -1.727223
        logincome2 |   .1391215   .0112298    12.39   0.000     .1171115    .1611315
      female_dummy |  -.1684747   .0191923    -8.78   0.000    -.2060908   -.1308585
    nonwhite_dummy |  -.0388094   .0234545    -1.65   0.098    -.0847794    .0071607
     marital_dummy |   .0412159   .0215893     1.91   0.056    -.0010984    .0835302
 high_school_dummy |   .4127042   .0604319     6.83   0.000     .2942598    .5311486
     college_dummy |   .3503194   .0204337    17.14   0.000     .3102701    .3903688
                   |
              year |
             2015  |   .1917823   .0233906     8.20   0.000     .1459376     .237627
             2018  |   .2946631   .0238865    12.34   0.000     .2478464    .3414797
                   |
        state_cate |
                2  |  -.0542752    .085052    -0.64   0.523    -.2209741    .1124237
                3  |  -.1584485   .0850565    -1.86   0.062    -.3251563    .0082593
                4  |  -.0787413   .0844035    -0.93   0.351     -.244169    .0866865
                5  |   .0470674   .0834127     0.56   0.573    -.1164185    .2105533
                6  |  -.1152955   .0848398    -1.36   0.174    -.2815784    .0509875
                7  |  -.1647177   .0849588    -1.94   0.053    -.3312339    .0017985
                8  |  -.1888637   .0833001    -2.27   0.023    -.3521288   -.0255985
                9  |  -.0688258   .0861307    -0.80   0.424    -.2376388    .0999871
               10  |   .0675345     .08624     0.78   0.434    -.1014928    .2365618
               11  |  -.0231699   .0852755    -0.27   0.786    -.1903068     .143967
               12  |   .1372239    .085751     1.60   0.110    -.0308448    .3052927
               13  |  -.1787774   .0838507    -2.13   0.033    -.3431217   -.0144331
               14  |    .084568   .0819573     1.03   0.302    -.0760653    .2452013
               15  |  -.2281524   .0840975    -2.71   0.007    -.3929805   -.0633244
               16  |  -.1018504     .08392    -1.21   0.225    -.2663305    .0626297
               17  |  -.1874326   .0839039    -2.23   0.025    -.3518812   -.0229841
               18  |  -.0493449   .0838516    -0.59   0.556    -.2136911    .1150013
               19  |  -.0342746   .0838264    -0.41   0.683    -.1985713     .130022
               20  |  -.2241441   .0843715    -2.66   0.008    -.3895091    -.058779
               21  |  -.2703906   .0846516    -3.19   0.001    -.4363047   -.1044764
               22  |  -.0580348   .0862147    -0.67   0.501    -.2270125    .1109429
               23  |  -.1073062   .0830457    -1.29   0.196    -.2700727    .0554603
               24  |   .0153983   .0837036     0.18   0.854    -.1486578    .1794544
               25  |  -.0763013   .0833543    -0.92   0.360    -.2396727    .0870701
               26  |  -.2329599   .0843042    -2.76   0.006    -.3981932   -.0677266
               27  |  -.1713912   .0817603    -2.10   0.036    -.3316385    -.011144
               28  |  -.1021796   .0840928    -1.22   0.224    -.2669985    .0626392
               29  |  -.0310566   .0849364    -0.37   0.715    -.1975288    .1354156
               30  |   -.113491   .0838554    -1.35   0.176    -.2778445    .0508626
               31  |  -.1572798   .0849826    -1.85   0.064    -.3238426     .009283
               32  |  -.1189419   .0854278    -1.39   0.164    -.2863773    .0484935
               33  |   .1466962   .0825624     1.78   0.076    -.0151231    .3085156
               34  |  -.0144191   .0849271    -0.17   0.865    -.1808731    .1520349
               35  |   .0925907   .0838458     1.10   0.269     -.071744    .2569254
               36  |  -.1279897   .0840941    -1.52   0.128    -.2928111    .0368317
               37  |  -.2633723   .0848594    -3.10   0.002    -.4296937    -.097051
               38  |  -.1409223   .0796245    -1.77   0.077    -.2969834    .0151388
               39  |  -.0327184   .0839622    -0.39   0.697    -.1972812    .1318445
               40  |  -.0882776   .0835731    -1.06   0.291    -.2520778    .0755226
               41  |  -.0496768   .0842392    -0.59   0.555    -.2147827    .1154291
               42  |  -.0686695    .083162    -0.83   0.409    -.2316641    .0943251
               43  |  -.2055727   .0844267    -2.43   0.015    -.3710459   -.0400994
               44  |  -.1179136   .0823303    -1.43   0.152     -.279278    .0434508
               45  |   -.101688   .0846582    -1.20   0.230     -.267615     .064239
               46  |  -.2828079   .0831057    -3.40   0.001     -.445692   -.1199237
               47  |  -.2336958   .0852602    -2.74   0.006    -.4008028   -.0665889
               48  |  -.0317701   .0803351    -0.40   0.692     -.189224    .1256838
               49  |  -.2110969   .0828904    -2.55   0.011    -.3735591   -.0486347
               50  |  -.1837703   .0838418    -2.19   0.028    -.3480972   -.0194434
               51  |  -.1167262   .0831548    -1.40   0.160    -.2797065    .0462542
                   |
             _cons |   7.424866    1.24284     5.97   0.000     4.988943    9.860788
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_svm fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .1641869   .0065632    25.02   0.000     .1513233    .1770505
           fin_lit |    .318754   .0100938    31.58   0.000     .2989705    .3385375
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/SVM.tex
dir : seeout

.         
. *** financial market participation
. ***** without state dummies
. logit fin_par_dummy overconfidence_svm fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -41045.732  
Iteration 2:   log pseudolikelihood = -40561.136  
Iteration 3:   log pseudolikelihood = -40553.349  
Iteration 4:   log pseudolikelihood = -40553.341  
Iteration 5:   log pseudolikelihood = -40553.341  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    9325.48
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40553.341               Pseudo R2         =     0.1870

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .8641729   .0390878    22.11   0.000     .7875623    .9407835
           fin_lit |   2.225225   .0631436    35.24   0.000     2.101466    2.348985
               age |  -.0801258   .0043014   -18.63   0.000    -.0885564   -.0716953
              age2 |   .0009857   .0000446    22.12   0.000     .0008984     .001073
         logincome |  -1.917609   .2807807    -6.83   0.000     -2.46793   -1.367289
        logincome2 |   .1331199   .0130661    10.19   0.000     .1075108     .158729
      female_dummy |  -.2542509   .0203663   -12.48   0.000    -.2941681   -.2143337
    nonwhite_dummy |  -.0853154   .0240117    -3.55   0.000    -.1323775   -.0382533
     marital_dummy |  -.0346387   .0231963    -1.49   0.135    -.0801025    .0108251
 high_school_dummy |   .6715422   .0816789     8.22   0.000     .5114546    .8316299
     college_dummy |   .4327827   .0215278    20.10   0.000      .390589    .4749764
                   |
              year |
             2015  |  -.2501064   .0248714   -10.06   0.000    -.2988535   -.2013593
             2018  |  -.1829404    .025593    -7.15   0.000    -.2331017   -.1327791
                   |
             _cons |   3.371651   1.510611     2.23   0.026     .4109075    6.332395
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_svm fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .1453818   .0064814    22.43   0.000     .1326785    .1580851
           fin_lit |   .3743549   .0102025    36.69   0.000     .3543584    .3943513
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Participation")
../outputs/tables/SVM.tex
dir : seeout

. 
. ***** with state dummies
. logit fin_par_dummy overconfidence_svm fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -40928.154  
Iteration 2:   log pseudolikelihood = -40433.726  
Iteration 3:   log pseudolikelihood = -40425.741  
Iteration 4:   log pseudolikelihood = -40425.733  
Iteration 5:   log pseudolikelihood = -40425.733  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    9525.92
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40425.733               Pseudo R2         =     0.1895

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .8844377    .039202    22.56   0.000     .8076032    .9612722
           fin_lit |   2.239268   .0634159    35.31   0.000     2.114975    2.363561
               age |   -.080471   .0043117   -18.66   0.000    -.0889218   -.0720202
              age2 |   .0009859   .0000447    22.07   0.000     .0008983    .0010735
         logincome |  -1.801009   .2810975    -6.41   0.000    -2.351949   -1.250068
        logincome2 |   .1269699   .0130895     9.70   0.000     .1013149    .1526249
      female_dummy |  -.2605941   .0204411   -12.75   0.000    -.3006579   -.2205303
    nonwhite_dummy |  -.1421794   .0258226    -5.51   0.000    -.1927908   -.0915681
     marital_dummy |  -.0202375   .0234805    -0.86   0.389    -.0662585    .0257835
 high_school_dummy |    .666131   .0820513     8.12   0.000     .5053133    .8269487
     college_dummy |   .4215178   .0216705    19.45   0.000     .3790443    .4639913
                   |
              year |
             2015  |  -.2467334    .024898    -9.91   0.000    -.2955327   -.1979342
             2018  |  -.1788977   .0256589    -6.97   0.000    -.2291881   -.1286072
                   |
        state_cate |
                2  |   .2090832   .0916312     2.28   0.023     .0294894    .3886771
                3  |   .0185529   .0936498     0.20   0.843    -.1649973    .2021032
                4  |   .0570024   .0948774     0.60   0.548    -.1289539    .2429587
                5  |   .2980283   .0915758     3.25   0.001      .118543    .4775135
                6  |   .1416425   .0946387     1.50   0.134    -.0438459    .3271309
                7  |   .2497414   .0919219     2.72   0.007     .0695777    .4299051
                8  |   .1605386    .092268     1.74   0.082    -.0203034    .3413805
                9  |   .3409827   .0932237     3.66   0.000     .1582675    .5236978
               10  |   .2110412   .0953513     2.21   0.027      .024156    .3979264
               11  |   .1514504   .0943059     1.61   0.108    -.0333858    .3362865
               12  |   .6444628   .0929305     6.93   0.000     .4623224    .8266032
               13  |   .0998976   .0912758     1.09   0.274    -.0789998    .2787949
               14  |   .0999543   .0881979     1.13   0.257    -.0729104    .2728191
               15  |  -.0607039    .094142    -0.64   0.519    -.2452188     .123811
               16  |   .2057484    .091451     2.25   0.024     .0265077    .3849892
               17  |    .160525   .0931117     1.72   0.085    -.0219705    .3430206
               18  |   .0115383   .0939004     0.12   0.902    -.1725032    .1955797
               19  |   .1096258   .0942158     1.16   0.245    -.0750338    .2942855
               20  |     .13977    .093623     1.49   0.135    -.0437276    .3232676
               21  |   .0747308     .09382     0.80   0.426     -.109153    .2586145
               22  |   .1384066   .0934455     1.48   0.139    -.0447433    .3215565
               23  |   .0371959   .0946514     0.39   0.694    -.1483176    .2227093
               24  |   .1963038   .0930615     2.11   0.035     .0139066     .378701
               25  |    .060738   .0954221     0.64   0.524    -.1262858    .2477619
               26  |      .0875   .0934734     0.94   0.349    -.0957046    .2707046
               27  |   .2820159   .0921927     3.06   0.002     .1013216    .4627103
               28  |   .1490966   .0921387     1.62   0.106    -.0314919    .3296852
               29  |    .010499   .0950174     0.11   0.912    -.1757316    .1967297
               30  |   .0067701   .0920522     0.07   0.941    -.1736488    .1871891
               31  |   .1936386   .0919221     2.11   0.035     .0134746    .3738025
               32  |   .1298963   .0944519     1.38   0.169    -.0552261    .3150186
               33  |   .3432957   .0897536     3.82   0.000     .1673819    .5192096
               34  |  -.0001654   .0935235    -0.00   0.999    -.1834681    .1831372
               35  |   .2056553   .0907685     2.27   0.023     .0277524    .3835582
               36  |    .165876   .0936002     1.77   0.076    -.0175769    .3493289
               37  |   .0374211   .0954697     0.39   0.695     -.149696    .2245382
               38  |   .1568772   .0883749     1.78   0.076    -.0163345    .3300888
               39  |   .1304685   .0938054     1.39   0.164    -.0533867    .3143237
               40  |   .0958179   .0914345     1.05   0.295    -.0833905    .2750263
               41  |    .058208   .0952867     0.61   0.541    -.1285506    .2449665
               42  |   .2429181   .0907676     2.68   0.007     .0650168    .4208194
               43  |  -.0593955   .0952026    -0.62   0.533    -.2459893    .1271982
               44  |  -.0128892    .091897    -0.14   0.888     -.193004    .1672257
               45  |   .0426999    .094073     0.45   0.650    -.1416798    .2270797
               46  |   .1998548   .0931123     2.15   0.032      .017358    .3823517
               47  |    .176447   .0942666     1.87   0.061    -.0083121    .3612061
               48  |   .2498825   .0882412     2.83   0.005      .076933     .422832
               49  |  -.0421549   .0937844    -0.45   0.653     -.225969    .1416592
               50  |   .2298824   .0925706     2.48   0.013     .0484474    .4113173
               51  |   .1788317   .0922549     1.94   0.053    -.0019846     .359648
                   |
             _cons |    2.70012   1.512109     1.79   0.074    -.2635603      5.6638
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_svm fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .1482386    .006472    22.90   0.000     .1355537    .1609235
           fin_lit |   .3753185    .010216    36.74   0.000     .3552954    .3953416
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/SVM.tex
dir : seeout

. 
. * baseline regressions with forest
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_forest fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43215.127  
Iteration 2:   log pseudolikelihood = -42980.814  
Iteration 3:   log pseudolikelihood = -42979.726  
Iteration 4:   log pseudolikelihood = -42979.726  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    7435.70
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -42979.726               Pseudo R2         =     0.1329

---------------------------------------------------------------------------------------
                      |               Robust
         retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   2.513298   .1380537    18.21   0.000     2.242718    2.783878
              fin_lit |   2.345917    .083484    28.10   0.000     2.182291    2.509543
                  age |   .1311476   .0041967    31.25   0.000     .1229223    .1393729
                 age2 |  -.0017358   .0000445   -39.04   0.000     -.001823   -.0016487
            logincome |  -1.603136   .2391316    -6.70   0.000    -2.071825   -1.134447
           logincome2 |   .1040166   .0112558     9.24   0.000     .0819557    .1260775
         female_dummy |  -.1444433   .0200204    -7.21   0.000    -.1836826   -.1052041
       nonwhite_dummy |    .111174    .022577     4.92   0.000     .0669239     .155424
        marital_dummy |   .0260629   .0229093     1.14   0.255    -.0188384    .0709643
    high_school_dummy |   .3538971   .0660484     5.36   0.000     .2244447    .4833495
        college_dummy |   .2749477   .0210347    13.07   0.000     .2337204    .3161749
                      |
                 year |
                2015  |   .0317486    .024593     1.29   0.197    -.0164527    .0799499
                2018  |   .0834438   .0251434     3.32   0.001     .0341636     .132724
                      |
                _cons |  -.0862883   1.265031    -0.07   0.946    -2.565704    2.393127
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_forest fin_lit

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .4519643   .0245658    18.40   0.000     .4038163    .5001124
              fin_lit |   .4218643   .0146306    28.83   0.000     .3931889    .4505397
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Readiness")
../outputs/tables/Forest.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_forest fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43160.623  
Iteration 2:   log pseudolikelihood = -42922.761  
Iteration 3:   log pseudolikelihood = -42921.634  
Iteration 4:   log pseudolikelihood = -42921.634  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    7523.53
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -42921.634               Pseudo R2         =     0.1340

---------------------------------------------------------------------------------------
                      |               Robust
         retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   2.534455   .1386142    18.28   0.000     2.262776    2.806134
              fin_lit |   2.340297    .083715    27.96   0.000     2.176219    2.504376
                  age |   .1310412    .004201    31.19   0.000     .1228075    .1392749
                 age2 |  -.0017329   .0000445   -38.93   0.000    -.0018202   -.0016457
            logincome |  -1.667528   .2396889    -6.96   0.000     -2.13731   -1.197746
           logincome2 |   .1072781   .0112906     9.50   0.000     .0851489    .1294074
         female_dummy |  -.1525271    .020093    -7.59   0.000    -.1919087   -.1131455
       nonwhite_dummy |   .1373511   .0242121     5.67   0.000     .0898963    .1848058
        marital_dummy |   .0229803   .0231478     0.99   0.321    -.0223885    .0683491
    high_school_dummy |   .3474194   .0661138     5.25   0.000     .2178388        .477
        college_dummy |   .2698535   .0211577    12.75   0.000     .2283852    .3113218
                      |
                 year |
                2015  |   .0310212    .024581     1.26   0.207    -.0171567    .0791991
                2018  |   .0817319   .0251619     3.25   0.001     .0324154    .1310484
                      |
           state_cate |
                   2  |   .1749989   .0844309     2.07   0.038     .0095174    .3404804
                   3  |  -.0506874   .0893105    -0.57   0.570    -.2257327    .1243579
                   4  |  -.1067934   .0896775    -1.19   0.234     -.282558    .0689713
                   5  |  -.1139909   .0851956    -1.34   0.181    -.2809711    .0529894
                   6  |  -.0644309   .0860801    -0.75   0.454    -.2331448     .104283
                   7  |  -.0144404   .0876027    -0.16   0.869    -.1861387    .1572578
                   8  |  -.1242861   .0866302    -1.43   0.151    -.2940781     .045506
                   9  |    .038988   .0874337     0.45   0.656    -.1323789    .2103549
                  10  |  -.1030485    .091009    -1.13   0.258    -.2814228    .0753257
                  11  |    .088458   .0858807     1.03   0.303    -.0798651    .2567812
                  12  |   -.002983   .0884924    -0.03   0.973    -.1764248    .1704589
                  13  |  -.0686094    .086528    -0.79   0.428    -.2382012    .1009823
                  14  |  -.0472084   .0841899    -0.56   0.575    -.2122176    .1178007
                  15  |  -.0535197   .0864576    -0.62   0.536    -.2229735    .1159342
                  16  |  -.0241798   .0863726    -0.28   0.780    -.1934669    .1451074
                  17  |   .0079952   .0876797     0.09   0.927    -.1638538    .1798443
                  18  |  -.0503052   .0870307    -0.58   0.563    -.2208821    .1202718
                  19  |  -.0040492   .0866074    -0.05   0.963    -.1737965    .1656981
                  20  |   .0111071   .0856789     0.13   0.897    -.1568206    .1790347
                  21  |  -.0571143   .0869148    -0.66   0.511    -.2274641    .1132355
                  22  |  -.1570969   .0891409    -1.76   0.078    -.3318099    .0176161
                  23  |  -.0275578   .0870315    -0.32   0.752    -.1981365    .1430208
                  24  |  -.0541979   .0864135    -0.63   0.531    -.2235653    .1151695
                  25  |   .0723861   .0852858     0.85   0.396    -.0947711    .2395432
                  26  |  -.0458729   .0857987    -0.53   0.593    -.2140353    .1222895
                  27  |   .2200713   .0850805     2.59   0.010     .0533166    .3868259
                  28  |   .0409141    .086018     0.48   0.634    -.1276781    .2095063
                  29  |  -.1472769   .0888464    -1.66   0.097    -.3214126    .0268587
                  30  |  -.0173094   .0863472    -0.20   0.841    -.1865469    .1519281
                  31  |  -.1569559   .0885283    -1.77   0.076    -.3304683    .0165564
                  32  |  -.0298899   .0889998    -0.34   0.737    -.2043263    .1445465
                  33  |  -.0562447   .0847276    -0.66   0.507    -.2223078    .1098183
                  34  |  -.0656188   .0876199    -0.75   0.454    -.2373507    .1061131
                  35  |   .1051965   .0860096     1.22   0.221    -.0633792    .2737722
                  36  |   -.052403   .0865994    -0.61   0.545    -.2221348    .1173287
                  37  |   .0067692   .0877697     0.08   0.939    -.1652562    .1787945
                  38  |   .0534743   .0816768     0.65   0.513    -.1066093    .2135579
                  39  |  -.1567953   .0894405    -1.75   0.080    -.3320956     .018505
                  40  |  -.0648148   .0866813    -0.75   0.455    -.2347069    .1050774
                  41  |   .0589106   .0863741     0.68   0.495    -.1103794    .2282007
                  42  |   .1554934   .0853218     1.82   0.068    -.0117342     .322721
                  43  |  -.0064975   .0871927    -0.07   0.941    -.1773921    .1643971
                  44  |  -.2275315   .0844459    -2.69   0.007    -.3930425   -.0620204
                  45  |   .2226191   .0852635     2.61   0.009     .0555057    .3897325
                  46  |  -.0150417   .0848248    -0.18   0.859    -.1812954    .1512119
                  47  |   .0097155    .086791     0.11   0.911    -.1603917    .1798228
                  48  |  -.0404426   .0819404    -0.49   0.622    -.2010427    .1201576
                  49  |   -.036219   .0872858    -0.41   0.678     -.207296     .134858
                  50  |   .0160538   .0864002     0.19   0.853    -.1532875    .1853952
                  51  |   .1358341   .0843964     1.61   0.108    -.0295798    .3012479
                      |
                _cons |   .2605829   1.268498     0.21   0.837    -2.225628    2.746794
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_forest fin_lit

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .4550312   .0246143    18.49   0.000     .4067881    .5032743
              fin_lit |   .4201725   .0146548    28.67   0.000     .3914496    .4488954
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/Forest.tex
dir : seeout

.         
. *** precautionary saving
. ***** without state dummies
. logit precaution_dummy overconfidence_forest fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47229.322  
Iteration 2:   log pseudolikelihood = -47177.807  
Iteration 3:   log pseudolikelihood = -47177.613  
Iteration 4:   log pseudolikelihood = -47177.613  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    8523.28
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -47177.613               Pseudo R2         =     0.1445

---------------------------------------------------------------------------------------
                      |               Robust
     precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   2.343607   .1341338    17.47   0.000      2.08071    2.606504
              fin_lit |   1.934716   .0785121    24.64   0.000     1.780835    2.088597
                  age |  -.1162048   .0039052   -29.76   0.000    -.1238589   -.1085507
                 age2 |   .0014082   .0000412    34.18   0.000     .0013275    .0014889
            logincome |    -2.1534   .2362137    -9.12   0.000     -2.61637   -1.690429
           logincome2 |    .137887    .011206    12.30   0.000     .1159236    .1598504
         female_dummy |  -.1779134   .0191071    -9.31   0.000    -.2153626   -.1404642
       nonwhite_dummy |   .0249162   .0219686     1.13   0.257    -.0181415    .0679738
        marital_dummy |   .0577233   .0212866     2.71   0.007     .0160024    .0994442
    high_school_dummy |    .440866    .060151     7.33   0.000     .3229723    .5587597
        college_dummy |    .342259   .0202919    16.87   0.000     .3024876    .3820303
                      |
                 year |
                2015  |   .1999625   .0233471     8.56   0.000     .1542031     .245722
                2018  |   .2996423   .0238416    12.57   0.000     .2529136     .346371
                      |
                _cons |    6.55009   1.240861     5.28   0.000     4.118046    8.982133
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_forest fin_lit

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .4728167   .0267893    17.65   0.000     .4203105    .5253228
              fin_lit |    .390324     .01552    25.15   0.000     .3599054    .4207425
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Precaution")
../outputs/tables/Forest.tex
dir : seeout

. 
. ***** with state dummies
. logit precaution_dummy overconfidence_forest fin_lit `household_X' i.year i.state_cate [pw=weigh
> ts]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47146.567  
Iteration 2:   log pseudolikelihood = -47093.111  
Iteration 3:   log pseudolikelihood = -47092.914  
Iteration 4:   log pseudolikelihood = -47092.914  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    8673.93
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -47092.914               Pseudo R2         =     0.1461

---------------------------------------------------------------------------------------
                      |               Robust
     precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   2.314882   .1345342    17.21   0.000       2.0512    2.578564
              fin_lit |    1.92505   .0785985    24.49   0.000        1.771    2.079101
                  age |  -.1163228   .0039113   -29.74   0.000    -.1239888   -.1086569
                 age2 |   .0014073   .0000413    34.10   0.000     .0013264    .0014881
            logincome |  -2.098385   .2368483    -8.86   0.000    -2.562599   -1.634171
           logincome2 |   .1351617   .0112448    12.02   0.000     .1131222    .1572012
         female_dummy |  -.1764312   .0191517    -9.21   0.000    -.2139679   -.1388944
       nonwhite_dummy |  -.0136752   .0233935    -0.58   0.559    -.0595257    .0321753
        marital_dummy |   .0643355   .0214934     2.99   0.003     .0222093    .1064618
    high_school_dummy |   .4452626    .060162     7.40   0.000     .3273472     .563178
        college_dummy |   .3415947   .0204335    16.72   0.000     .3015458    .3816436
                      |
                 year |
                2015  |   .2019923   .0233676     8.64   0.000     .1561926     .247792
                2018  |   .3027281   .0238837    12.68   0.000     .2559169    .3495393
                      |
           state_cate |
                   2  |  -.0395779   .0850978    -0.47   0.642    -.2063666    .1272108
                   3  |  -.1267204   .0850663    -1.49   0.136    -.2934473    .0400064
                   4  |  -.0440982   .0839881    -0.53   0.600    -.2087119    .1205154
                   5  |   .0664975   .0831393     0.80   0.424    -.0964525    .2294475
                   6  |  -.0803476   .0845352    -0.95   0.342    -.2460336    .0853383
                   7  |   -.114596   .0851418    -1.35   0.178    -.2814709    .0522789
                   8  |  -.1582367   .0831353    -1.90   0.057    -.3211789    .0047055
                   9  |  -.0596563   .0860834    -0.69   0.488    -.2283767    .1090641
                  10  |   .0841225   .0859206     0.98   0.328    -.0842787    .2525237
                  11  |   .0355004   .0854428     0.42   0.678    -.1319644    .2029652
                  12  |   .1530999   .0855359     1.79   0.073    -.0145474    .3207473
                  13  |   -.169998   .0836934    -2.03   0.042    -.3340342   -.0059619
                  14  |   .1058036   .0815202     1.30   0.194     -.053973    .2655802
                  15  |  -.1804461   .0840702    -2.15   0.032    -.3452207   -.0156715
                  16  |  -.0769581   .0836889    -0.92   0.358    -.2409853    .0870692
                  17  |  -.1669683   .0833109    -2.00   0.045    -.3302547   -.0036819
                  18  |   .0013024   .0838156     0.02   0.988    -.1629732     .165578
                  19  |  -.0026014   .0835352    -0.03   0.975    -.1663274    .1611246
                  20  |  -.1920886   .0840486    -2.29   0.022    -.3568209   -.0273563
                  21  |   -.233543   .0845735    -2.76   0.006     -.399304    -.067782
                  22  |  -.0317546   .0858763    -0.37   0.712    -.2000691    .1365599
                  23  |  -.0752897   .0827203    -0.91   0.363    -.2374184     .086839
                  24  |   .0383073   .0836609     0.46   0.647    -.1256651    .2022796
                  25  |  -.0336672   .0834249    -0.40   0.687    -.1971769    .1298425
                  26  |  -.1955237   .0839589    -2.33   0.020    -.3600801   -.0309674
                  27  |  -.1352159   .0815898    -1.66   0.097     -.295129    .0246971
                  28  |    -.06946   .0838474    -0.83   0.407    -.2337978    .0948778
                  29  |   .0046463   .0848611     0.05   0.956    -.1616784     .170971
                  30  |  -.0897341   .0833652    -1.08   0.282    -.2531269    .0736587
                  31  |  -.1172518   .0850213    -1.38   0.168    -.2838905     .049387
                  32  |  -.0824219   .0853918    -0.97   0.334    -.2497867    .0849429
                  33  |   .1367393   .0826014     1.66   0.098    -.0251565    .2986351
                  34  |   .0081351     .08443     0.10   0.923    -.1573446    .1736148
                  35  |   .1048357   .0835215     1.26   0.209    -.0588634    .2685348
                  36  |  -.1013072   .0837449    -1.21   0.226    -.2654442    .0628298
                  37  |   -.212813   .0846588    -2.51   0.012    -.3787412   -.0468847
                  38  |  -.1248055   .0794294    -1.57   0.116    -.2804843    .0308732
                  39  |  -.0134055   .0837005    -0.16   0.873    -.1774554    .1506444
                  40  |  -.0415937   .0837569    -0.50   0.619    -.2057542    .1225668
                  41  |  -.0066109   .0837163    -0.08   0.937    -.1706918    .1574699
                  42  |  -.0458596   .0830948    -0.55   0.581    -.2087225    .1170032
                  43  |  -.1804593   .0835865    -2.16   0.031    -.3442859   -.0166327
                  44  |  -.1038328   .0820967    -1.26   0.206    -.2647395    .0570738
                  45  |  -.0896378    .084407    -1.06   0.288    -.2550724    .0757968
                  46  |  -.2307035   .0829705    -2.78   0.005    -.3933227   -.0680842
                  47  |  -.2300293   .0845364    -2.72   0.007    -.3957175   -.0643411
                  48  |  -.0111845   .0797353    -0.14   0.888    -.1674628    .1450939
                  49  |  -.1508309    .082578    -1.83   0.068    -.3126808    .0110191
                  50  |  -.1611484   .0834269    -1.93   0.053    -.3246621    .0023654
                  51  |  -.0952803   .0827116    -1.15   0.249    -.2573921    .0668315
                      |
                _cons |   6.353047   1.244823     5.10   0.000     3.913239    8.792854
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_forest fin_lit

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .4659719   .0268111    17.38   0.000     .4134232    .5185206
              fin_lit |   .3875011   .0155052    24.99   0.000     .3571115    .4178907
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/Forest.tex
dir : seeout

.         
. *** financial market participation
. ***** without state dummies
. logit fin_par_dummy overconfidence_forest fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood =  -41146.33  
Iteration 2:   log pseudolikelihood = -40683.933  
Iteration 3:   log pseudolikelihood = -40676.094  
Iteration 4:   log pseudolikelihood = -40676.088  
Iteration 5:   log pseudolikelihood = -40676.088  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    9423.23
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40676.088               Pseudo R2         =     0.1845

---------------------------------------------------------------------------------------
                      |               Robust
        fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   2.761251   .1434357    19.25   0.000     2.480122    3.042379
              fin_lit |   2.722952   .0892971    30.49   0.000     2.547933    2.897971
                  age |  -.0766216   .0042805   -17.90   0.000    -.0850113    -.068232
                 age2 |   .0009515   .0000444    21.45   0.000     .0008646    .0010384
            logincome |  -1.706463   .2828075    -6.03   0.000    -2.260755    -1.15217
           logincome2 |   .1235255   .0131456     9.40   0.000     .0977606    .1492904
         female_dummy |  -.2626843   .0203219   -12.93   0.000    -.3025145    -.222854
       nonwhite_dummy |  -.0637016   .0239848    -2.66   0.008    -.1107109   -.0166922
        marital_dummy |  -.0094062   .0231455    -0.41   0.684    -.0547705    .0359582
    high_school_dummy |     .70187   .0823012     8.53   0.000     .5405626    .8631774
        college_dummy |   .4244826   .0215361    19.71   0.000     .3822726    .4666925
                      |
                 year |
                2015  |  -.2362005   .0248599    -9.50   0.000    -.2849251   -.1874759
                2018  |   -.168032   .0256006    -6.56   0.000    -.2182083   -.1178558
                      |
                _cons |   1.499968   1.526559     0.98   0.326    -1.492032    4.491968
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_forest fin_lit

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .4658792   .0239905    19.42   0.000     .4188586    .5128997
              fin_lit |   .4594174   .0146881    31.28   0.000     .4306293    .4882055
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Participation")
../outputs/tables/Forest.tex
dir : seeout

. 
. ***** with state dummies
. logit fin_par_dummy overconfidence_forest fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -41037.585  
Iteration 2:   log pseudolikelihood = -40568.624  
Iteration 3:   log pseudolikelihood = -40560.677  
Iteration 4:   log pseudolikelihood = -40560.669  
Iteration 5:   log pseudolikelihood = -40560.669  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    9620.41
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40560.669               Pseudo R2         =     0.1868

---------------------------------------------------------------------------------------
                      |               Robust
        fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   2.794253   .1440588    19.40   0.000     2.511903    3.076603
              fin_lit |   2.730436   .0895357    30.50   0.000     2.554949    2.905923
                  age |  -.0769716   .0042904   -17.94   0.000    -.0853805   -.0685627
                 age2 |   .0009518   .0000445    21.40   0.000     .0008646    .0010389
            logincome |  -1.597484   .2832194    -5.64   0.000    -2.152584   -1.042385
           logincome2 |   .1177919   .0131745     8.94   0.000     .0919703    .1436134
         female_dummy |   -.269546   .0203971   -13.21   0.000    -.3095236   -.2295684
       nonwhite_dummy |  -.1158022   .0257979    -4.49   0.000    -.1663653   -.0652392
        marital_dummy |   .0039938   .0234181     0.17   0.865    -.0419048    .0498924
    high_school_dummy |   .6965179    .082645     8.43   0.000     .5345366    .8584992
        college_dummy |   .4135579   .0216814    19.07   0.000     .3710632    .4560526
                      |
                 year |
                2015  |  -.2327339   .0248904    -9.35   0.000    -.2815182   -.1839497
                2018  |  -.1640055   .0256676    -6.39   0.000    -.2143132   -.1136979
                      |
           state_cate |
                   2  |   .2211765   .0917328     2.41   0.016     .0413836    .4009694
                   3  |   .0505469   .0935862     0.54   0.589    -.1328787    .2339725
                   4  |   .0931431   .0947674     0.98   0.326    -.0925975    .2788837
                   5  |   .3148693   .0915676     3.44   0.001     .1354001    .4943386
                   6  |   .1788415   .0943536     1.90   0.058    -.0060882    .3637712
                   7  |   .3006704   .0916635     3.28   0.001     .1210133    .4803274
                   8  |   .1972877   .0918392     2.15   0.032     .0172861    .3772893
                   9  |   .3477256   .0928401     3.75   0.000     .1657623    .5296889
                  10  |   .2256682   .0949127     2.38   0.017     .0396428    .4116936
                  11  |   .2064106   .0946739     2.18   0.029      .020853    .3919681
                  12  |   .6632853   .0925791     7.16   0.000     .4818336    .8447371
                  13  |   .1115343   .0910248     1.23   0.220     -.066871    .2899396
                  14  |   .1222824   .0877594     1.39   0.164     -.049723    .2942877
                  15  |  -.0112904   .0943565    -0.12   0.905    -.1962257    .1736449
                  16  |   .2316242   .0910393     2.54   0.011     .0531905    .4100578
                  17  |   .1830609   .0924659     1.98   0.048     .0018311    .3642906
                  18  |   .0591989   .0939723     0.63   0.529    -.1249835    .2433812
                  19  |   .1403549    .094257     1.49   0.136    -.0443854    .3250953
                  20  |   .1774304   .0934029     1.90   0.057     -.005636    .3604968
                  21  |   .1142553   .0935514     1.22   0.222     -.069102    .2976126
                  22  |   .1662866   .0931587     1.78   0.074     -.016301    .3488742
                  23  |   .0744529   .0942046     0.79   0.429    -.1101846    .2590905
                  24  |   .2205101   .0928314     2.38   0.018      .038564    .4024563
                  25  |   .1031372    .095777     1.08   0.282    -.0845824    .2908567
                  26  |    .123446   .0931912     1.32   0.185    -.0592055    .3060974
                  27  |    .322414   .0918028     3.51   0.000     .1424838    .5023442
                  28  |   .1844246   .0916923     2.01   0.044     .0047111    .3641382
                  29  |   .0455499   .0950568     0.48   0.632    -.1407581    .2318578
                  30  |   .0345174    .091713     0.38   0.707    -.1452368    .2142716
                  31  |   .2375317   .0918596     2.59   0.010     .0574901    .4175732
                  32  |   .1664897   .0942466     1.77   0.077    -.0182302    .3512096
                  33  |   .3216513   .0897237     3.58   0.000     .1457961    .4975066
                  34  |   .0304371   .0929482     0.33   0.743     -.151738    .2126122
                  35  |    .216434   .0904802     2.39   0.017      .039096     .393772
                  36  |   .1937158   .0930862     2.08   0.037     .0112701    .3761614
                  37  |   .0907415   .0950189     0.95   0.340    -.0954921    .2769751
                  38  |   .1715765   .0881664     1.95   0.052    -.0012264    .3443794
                  39  |   .1560035      .0933     1.67   0.095    -.0268611     .338868
                  40  |   .1446564   .0915253     1.58   0.114      -.03473    .3240427
                  41  |   .1060773   .0949133     1.12   0.264    -.0799494     .292104
                  42  |   .2702388   .0902751     2.99   0.003     .0933029    .4471747
                  43  |  -.0309551   .0949792    -0.33   0.744    -.2171108    .1552006
                  44  |   .0026372   .0915947     0.03   0.977    -.1768852    .1821596
                  45  |   .0564018    .093682     0.60   0.547    -.1272115    .2400152
                  46  |   .2581874   .0928494     2.78   0.005     .0762059    .4401688
                  47  |   .1822026   .0935446     1.95   0.051    -.0011415    .3655467
                  48  |   .2744499   .0877805     3.13   0.002     .1024033    .4464965
                  49  |   .0233157   .0935835     0.25   0.803    -.1601046    .2067361
                  50  |   .2540488   .0921083     2.76   0.006     .0735199    .4345778
                  51  |   .1989135   .0917751     2.17   0.030     .0190377    .3787893
                      |
                _cons |   .8384644   1.528815     0.55   0.583    -2.157957    3.834886
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_forest fin_lit

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .4698338   .0239992    19.58   0.000     .4227962    .5168714
              fin_lit |   .4591034    .014678    31.28   0.000     .4303351    .4878717
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/Forest.tex
dir : seeout

.         
. * baseline regressions with logistic
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_logit fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood =  -43121.69  
Iteration 2:   log pseudolikelihood = -42835.392  
Iteration 3:   log pseudolikelihood = -42833.818  
Iteration 4:   log pseudolikelihood = -42833.818  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    7181.99
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -42833.818               Pseudo R2         =     0.1358

--------------------------------------------------------------------------------------
                     |               Robust
        retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   1.732632   .0783989    22.10   0.000     1.578972    1.886291
             fin_lit |   1.381391   .0427634    32.30   0.000     1.297576    1.465205
                 age |   .1961711   .0052821    37.14   0.000     .1858183     .206524
                age2 |  -.0022391   .0000515   -43.50   0.000      -.00234   -.0021382
           logincome |  -1.903789   .2409877    -7.90   0.000    -2.376116   -1.431462
          logincome2 |   .1273735   .0113651    11.21   0.000     .1050983    .1496488
        female_dummy |  -.1345171    .019989    -6.73   0.000    -.1736949   -.0953393
      nonwhite_dummy |   .0906372   .0225596     4.02   0.000     .0464212    .1348533
       marital_dummy |  -.0118273   .0229419    -0.52   0.606    -.0567925     .033138
   high_school_dummy |   .3318961   .0659134     5.04   0.000     .2027083    .4610839
       college_dummy |   .2782845   .0210117    13.24   0.000     .2371024    .3194666
                     |
                year |
               2015  |   .0272257   .0245598     1.11   0.268    -.0209106     .075362
               2018  |   .0769086   .0250839     3.07   0.002      .027745    .1260722
                     |
               _cons |   -.636983   1.277494    -0.50   0.618    -3.140825    1.866859
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_logit fin_lit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   .3110365   .0138558    22.45   0.000     .2838796    .3381934
             fin_lit |   .2479829   .0074147    33.44   0.000     .2334503    .2625154
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Readiness")
../outputs/tables/Logit.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_logit fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43073.143  
Iteration 2:   log pseudolikelihood = -42784.004  
Iteration 3:   log pseudolikelihood = -42782.416  
Iteration 4:   log pseudolikelihood = -42782.416  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    7270.78
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -42782.416               Pseudo R2         =     0.1368

--------------------------------------------------------------------------------------
                     |               Robust
        retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   1.725498   .0786109    21.95   0.000     1.571424    1.879573
             fin_lit |   1.365199   .0429013    31.82   0.000     1.281114    1.449284
                 age |   .1957658   .0052894    37.01   0.000     .1853987    .2061329
                age2 |  -.0022338   .0000515   -43.35   0.000    -.0023348   -.0021328
           logincome |  -1.954296   .2414259    -8.09   0.000    -2.427482    -1.48111
          logincome2 |   .1299021   .0113942    11.40   0.000     .1075698    .1522344
        female_dummy |  -.1417161   .0200577    -7.07   0.000    -.1810284   -.1024038
      nonwhite_dummy |   .1147134   .0241766     4.74   0.000      .067328    .1620987
       marital_dummy |  -.0133468   .0231797    -0.58   0.565    -.0587781    .0320846
   high_school_dummy |   .3274136   .0659818     4.96   0.000     .1980916    .4567356
       college_dummy |   .2732351   .0211367    12.93   0.000     .2318078    .3146623
                     |
                year |
               2015  |   .0269561   .0245452     1.10   0.272    -.0211516    .0750639
               2018  |   .0755545   .0251024     3.01   0.003     .0263548    .1247543
                     |
          state_cate |
                  2  |   .1340858   .0847201     1.58   0.113    -.0319626    .3001341
                  3  |  -.0738411   .0894391    -0.83   0.409    -.2491385    .1014563
                  4  |  -.1408742    .090367    -1.56   0.119    -.3179903    .0362418
                  5  |  -.1412489   .0853699    -1.65   0.098    -.3085709     .026073
                  6  |  -.0824124   .0860837    -0.96   0.338    -.2511334    .0863086
                  7  |  -.0457849   .0874161    -0.52   0.600    -.2171173    .1255476
                  8  |   -.159989   .0866827    -1.85   0.065    -.3298839    .0099059
                  9  |    .018509   .0873979     0.21   0.832    -.1527878    .1898058
                 10  |  -.1109199   .0912043    -1.22   0.224     -.289677    .0678372
                 11  |   .0407137   .0859467     0.47   0.636    -.1277386     .209166
                 12  |   -.039709   .0887545    -0.45   0.655    -.2136647    .1342466
                 13  |  -.1010895   .0869029    -1.16   0.245    -.2714161    .0692371
                 14  |  -.0721365   .0842447    -0.86   0.392     -.237253      .09298
                 15  |   -.077298   .0870599    -0.89   0.375    -.2479323    .0933362
                 16  |  -.0546412   .0867365    -0.63   0.529    -.2246415    .1153592
                 17  |  -.0097546   .0879706    -0.11   0.912    -.1821738    .1626647
                 18  |  -.0908833   .0874327    -1.04   0.299    -.2622482    .0804817
                 19  |  -.0409736   .0866906    -0.47   0.636    -.2108841     .128937
                 20  |  -.0325703    .086058    -0.38   0.705    -.2012408    .1361002
                 21  |   -.076729   .0866338    -0.89   0.376    -.2465282    .0930702
                 22  |  -.1874991   .0889243    -2.11   0.035    -.3617875   -.0132107
                 23  |  -.0534519   .0873788    -0.61   0.541    -.2247111    .1178073
                 24  |  -.0690733   .0866207    -0.80   0.425    -.2388467    .1007001
                 25  |   .0124312   .0856487     0.15   0.885    -.1554371    .1802995
                 26  |  -.0781064   .0863319    -0.90   0.366    -.2473138     .091101
                 27  |   .1629744   .0857145     1.90   0.057     -.005023    .3309718
                 28  |   .0028887   .0865912     0.03   0.973    -.1668269    .1726043
                 29  |  -.1759878   .0890946    -1.98   0.048    -.3506099   -.0013657
                 30  |  -.0488337    .086913    -0.56   0.574      -.21918    .1215126
                 31  |  -.1828542   .0884151    -2.07   0.039    -.3561445   -.0095638
                 32  |  -.0718896   .0894651    -0.80   0.422     -.247238    .1034588
                 33  |   -.044995   .0846517    -0.53   0.595    -.2109093    .1209193
                 34  |  -.0829751   .0879526    -0.94   0.345     -.255359    .0894088
                 35  |   .0672303   .0864065     0.78   0.437    -.1021233     .236584
                 36  |  -.0648494   .0869608    -0.75   0.456    -.2352895    .1055906
                 37  |  -.0601035   .0879531    -0.68   0.494    -.2324884    .1122814
                 38  |   .0409087   .0819329     0.50   0.618    -.1196769    .2014942
                 39  |  -.1562914   .0902433    -1.73   0.083     -.333165    .0205822
                 40  |  -.1120783   .0868546    -1.29   0.197    -.2823101    .0581535
                 41  |   .0113337   .0866577     0.13   0.896    -.1585122    .1811796
                 42  |    .123177   .0857826     1.44   0.151    -.0449539    .2913079
                 43  |  -.0178715   .0875885    -0.20   0.838    -.1895419    .1537989
                 44  |  -.2406006   .0848703    -2.83   0.005    -.4069434   -.0742578
                 45  |   .1960962   .0851946     2.30   0.021     .0291178    .3630745
                 46  |  -.0885447   .0850126    -1.04   0.298    -.2551664    .0780769
                 47  |  -.0060738   .0872701    -0.07   0.945    -.1771201    .1649725
                 48  |  -.0574747   .0823569    -0.70   0.485    -.2188913    .1039419
                 49  |  -.0829518   .0876868    -0.95   0.344    -.2548148    .0889112
                 50  |  -.0044558   .0863471    -0.05   0.959     -.173693    .1647814
                 51  |   .0914695   .0849787     1.08   0.282    -.0750856    .2580246
                     |
               _cons |  -.3097018   1.280505    -0.24   0.809    -2.819445    2.200041
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_logit fin_lit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   .3092988   .0138783    22.29   0.000     .2820979    .3364997
             fin_lit |   .2447145   .0074497    32.85   0.000     .2301134    .2593156
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/Logit.tex
dir : seeout

.         
. *** precautionary saving
. ***** without state dummies
. logit precaution_dummy overconfidence_logit fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -46830.467  
Iteration 2:   log pseudolikelihood = -46761.155  
Iteration 3:   log pseudolikelihood = -46760.915  
Iteration 4:   log pseudolikelihood = -46760.915  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    8461.95
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -46760.915               Pseudo R2         =     0.1521

--------------------------------------------------------------------------------------
                     |               Robust
    precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   2.182546   .0813525    26.83   0.000     2.023098    2.341994
             fin_lit |   1.116981   .0390151    28.63   0.000     1.040513    1.193449
                 age |  -.0398145   .0048755    -8.17   0.000    -.0493704   -.0302587
                age2 |   .0008709   .0000461    18.88   0.000     .0007805    .0009614
           logincome |  -3.028154   .2439819   -12.41   0.000     -3.50635   -2.549958
          logincome2 |   .1903718   .0116798    16.30   0.000     .1674799    .2132637
        female_dummy |  -.1604056   .0191561    -8.37   0.000    -.1979508   -.1228604
      nonwhite_dummy |  -.0013918   .0218914    -0.06   0.949    -.0442982    .0415147
       marital_dummy |   .0113625   .0213126     0.53   0.594    -.0304095    .0531345
   high_school_dummy |    .395877   .0593864     6.67   0.000     .2794819    .5122721
       college_dummy |   .3528755   .0203718    17.32   0.000     .3129476    .3928034
                     |
                year |
               2015  |   .1958747   .0234928     8.34   0.000     .1498295    .2419198
               2018  |   .2961322   .0239272    12.38   0.000     .2492358    .3430286
                     |
               _cons |   8.146058   1.259114     6.47   0.000      5.67824    10.61388
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_logit fin_lit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   .4358422   .0158326    27.53   0.000     .4048109    .4668735
             fin_lit |   .2230548   .0075865    29.40   0.000     .2081856    .2379241
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Precaution")
../outputs/tables/Logit.tex
dir : seeout

. 
. ***** with state dummies
. logit precaution_dummy overconfidence_logit fin_lit `household_X' i.year i.state_cate [pw=weight
> s]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -46741.262  
Iteration 2:   log pseudolikelihood = -46668.963  
Iteration 3:   log pseudolikelihood = -46668.704  
Iteration 4:   log pseudolikelihood = -46668.704  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    8603.73
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -46668.704               Pseudo R2         =     0.1538

--------------------------------------------------------------------------------------
                     |               Robust
    precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   2.185893     .08165    26.77   0.000     2.025862    2.345924
             fin_lit |   1.125453   .0392212    28.70   0.000     1.048581    1.202325
                 age |  -.0397724   .0048874    -8.14   0.000    -.0493516   -.0301932
                age2 |   .0008686   .0000462    18.79   0.000     .0007779    .0009592
           logincome |  -2.966183   .2445281   -12.13   0.000    -3.445449   -2.486917
          logincome2 |   .1872949   .0117133    15.99   0.000     .1643372    .2102526
        female_dummy |  -.1573347   .0192023    -8.19   0.000    -.1949705   -.1196989
      nonwhite_dummy |  -.0422377   .0233175    -1.81   0.070    -.0879392    .0034637
       marital_dummy |    .019281   .0215126     0.90   0.370    -.0228828    .0614449
   high_school_dummy |     .40089   .0593955     6.75   0.000      .284477     .517303
       college_dummy |   .3517221   .0205157    17.14   0.000      .311512    .3919322
                     |
                year |
               2015  |   .1980151   .0235141     8.42   0.000     .1519284    .2441018
               2018  |   .2994421   .0239718    12.49   0.000     .2524582    .3464259
                     |
          state_cate |
                  2  |  -.0741765   .0855991    -0.87   0.386    -.2419476    .0935946
                  3  |  -.1417293   .0852203    -1.66   0.096     -.308758    .0252994
                  4  |  -.0683333     .08439    -0.81   0.418    -.2337346     .097068
                  5  |   .0478115   .0832787     0.57   0.566    -.1154118    .2110347
                  6  |  -.0831893   .0845335    -0.98   0.325     -.248872    .0824934
                  7  |  -.1385605   .0854465    -1.62   0.105    -.3060327    .0289116
                  8  |   -.193248   .0835033    -2.31   0.021    -.3569114   -.0295845
                  9  |  -.0646935   .0863754    -0.75   0.454    -.2339862    .1045993
                 10  |   .0807446    .086084     0.94   0.348    -.0879769    .2494662
                 11  |  -.0089343   .0851796    -0.10   0.916    -.1758834    .1580147
                 12  |   .1309746   .0859214     1.52   0.127    -.0374284    .2993775
                 13  |  -.1926282   .0841492    -2.29   0.022    -.3575577   -.0276988
                 14  |   .0847246   .0814714     1.04   0.298    -.0749565    .2444056
                 15  |  -.1967412   .0845492    -2.33   0.020    -.3624546   -.0310278
                 16  |  -.0987112   .0839023    -1.18   0.239    -.2631567    .0657343
                 17  |  -.1745016   .0835738    -2.09   0.037    -.3383033      -.0107
                 18  |  -.0331172   .0837425    -0.40   0.693    -.1972494    .1310151
                 19  |  -.0326751   .0835251    -0.39   0.696    -.1963813    .1310311
                 20  |    -.23353   .0844569    -2.77   0.006    -.3990625   -.0679976
                 21  |  -.2458347   .0846539    -2.90   0.004    -.4117533    -.079916
                 22  |   -.054449   .0861675    -0.63   0.527    -.2233341    .1144362
                 23  |  -.0926733   .0828188    -1.12   0.263    -.2549951    .0696486
                 24  |   .0329473   .0841887     0.39   0.696    -.1320595    .1979542
                 25  |  -.0929247   .0832096    -1.12   0.264    -.2560126    .0701632
                 26  |  -.2196856   .0843032    -2.61   0.009    -.3849167   -.0544544
                 27  |  -.1871167   .0820734    -2.28   0.023    -.3479777   -.0262557
                 28  |  -.0988366   .0841075    -1.18   0.240    -.2636842    .0660111
                 29  |  -.0142771   .0847797    -0.17   0.866    -.1804423    .1518881
                 30  |  -.1130271   .0841352    -1.34   0.179    -.2779291    .0518748
                 31  |  -.1377784   .0851213    -1.62   0.106    -.3046131    .0290563
                 32  |  -.1161503   .0858517    -1.35   0.176    -.2844165    .0521159
                 33  |   .1448583   .0825076     1.76   0.079    -.0168537    .3065702
                 34  |   -.007373    .084776    -0.09   0.931    -.1735309    .1587849
                 35  |   .0718362   .0836908     0.86   0.391    -.0921947    .2358672
                 36  |  -.1065407   .0838395    -1.27   0.204    -.2708631    .0577818
                 37  |  -.2719468   .0852391    -3.19   0.001    -.4390124   -.1048813
                 38  |  -.1293733   .0799778    -1.62   0.106    -.2861269    .0273802
                 39  |  -.0013483   .0841962    -0.02   0.987    -.1663699    .1636732
                 40  |  -.0758347    .083764    -0.91   0.365    -.2400091    .0883396
                 41  |  -.0527206   .0836207    -0.63   0.528    -.2166142     .111173
                 42  |  -.0703971   .0834373    -0.84   0.399    -.2339312     .093137
                 43  |  -.1880984   .0842278    -2.23   0.026    -.3531819   -.0230149
                 44  |   -.112866   .0820933    -1.37   0.169    -.2737659    .0480338
                 45  |  -.1071472   .0848506    -1.26   0.207    -.2734512    .0591569
                 46  |  -.3007286   .0835327    -3.60   0.000    -.4644497   -.1370074
                 47  |   -.245852   .0852137    -2.89   0.004    -.4128677   -.0788363
                 48  |  -.0164093   .0804514    -0.20   0.838    -.1740912    .1412726
                 49  |  -.1893285   .0830057    -2.28   0.023    -.3520167   -.0266404
                 50  |  -.1706782   .0835613    -2.04   0.041    -.3344553    -.006901
                 51  |  -.1324462   .0834379    -1.59   0.112    -.2959816    .0310891
                     |
               _cons |   7.910875   1.262738     6.26   0.000     5.435955     10.3858
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_logit fin_lit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   .4354363   .0158474    27.48   0.000     .4043759    .4664966
             fin_lit |   .2241935   .0076098    29.46   0.000     .2092785    .2391084
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/Logit.tex
dir : seeout

.         
. *** financial market participation
. ***** without state dummies
. logit fin_par_dummy overconfidence_logit fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -40939.209  
Iteration 2:   log pseudolikelihood = -40528.389  
Iteration 3:   log pseudolikelihood = -40522.191  
Iteration 4:   log pseudolikelihood = -40522.186  
Iteration 5:   log pseudolikelihood = -40522.186  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    9529.44
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40522.186               Pseudo R2         =     0.1876

--------------------------------------------------------------------------------------
                     |               Robust
       fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   1.911523   .0849451    22.50   0.000     1.745034    2.078012
             fin_lit |   1.629716   .0446733    36.48   0.000     1.542158    1.717274
                 age |  -.0101015   .0052732    -1.92   0.055    -.0204368    .0002338
                age2 |   .0004635     .00005     9.26   0.000     .0003654    .0005615
           logincome |  -2.239663   .2881881    -7.77   0.000    -2.804502   -1.674825
          logincome2 |   .1579518   .0134697    11.73   0.000     .1315516    .1843519
        female_dummy |  -.2531105   .0203487   -12.44   0.000    -.2929933   -.2132277
      nonwhite_dummy |  -.0839876   .0239238    -3.51   0.000    -.1308775   -.0370977
       marital_dummy |  -.0494227   .0231737    -2.13   0.033    -.0948424   -.0040031
   high_school_dummy |   .6684093   .0816368     8.19   0.000      .508404    .8284146
       college_dummy |   .4328773   .0215904    20.05   0.000      .390561    .4751936
                     |
                year |
               2015  |  -.2434295   .0249726    -9.75   0.000    -.2923749   -.1944842
               2018  |  -.1774217   .0256771    -6.91   0.000     -.227748   -.1270955
                     |
               _cons |    2.18397   1.543037     1.42   0.157    -.8403257    5.208266
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_logit fin_lit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   .3204791   .0140428    22.82   0.000     .2929558    .3480024
             fin_lit |   .2732324   .0072135    37.88   0.000     .2590943    .2873705
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Participation")
../outputs/tables/Logit.tex
dir : seeout

. 
. ***** with state dummies
. logit fin_par_dummy overconfidence_logit fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -40828.527  
Iteration 2:   log pseudolikelihood =  -40410.78  
Iteration 3:   log pseudolikelihood = -40404.472  
Iteration 4:   log pseudolikelihood = -40404.466  
Iteration 5:   log pseudolikelihood = -40404.466  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    9725.53
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40404.466               Pseudo R2         =     0.1900

--------------------------------------------------------------------------------------
                     |               Robust
       fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   1.930738   .0855775    22.56   0.000     1.763009    2.098467
             fin_lit |   1.626159   .0449575    36.17   0.000     1.538044    1.714274
                 age |  -.0096953   .0053027    -1.83   0.067    -.0200883    .0006977
                age2 |   .0004578   .0000503     9.11   0.000     .0003593    .0005563
           logincome |  -2.123619   .2886372    -7.36   0.000    -2.689337     -1.5579
          logincome2 |   .1519442   .0135007    11.25   0.000     .1254834     .178405
        female_dummy |  -.2588235   .0204246   -12.67   0.000     -.298855    -.218792
      nonwhite_dummy |  -.1379197   .0257406    -5.36   0.000    -.1883705    -.087469
       marital_dummy |  -.0348451   .0234475    -1.49   0.137    -.0808014    .0111111
   high_school_dummy |    .664598   .0819876     8.11   0.000     .5039053    .8252906
       college_dummy |   .4221904   .0217455    19.42   0.000       .37957    .4648109
                     |
                year |
               2015  |  -.2396286   .0250043    -9.58   0.000    -.2886362    -.190621
               2018  |  -.1730896   .0257457    -6.72   0.000    -.2235502   -.1226291
                     |
          state_cate |
                  2  |   .1791937   .0922435     1.94   0.052    -.0016003    .3599876
                  3  |   .0318155   .0938704     0.34   0.735    -.1521672    .2157981
                  4  |   .0626985    .095254     0.66   0.510     -.123996     .249393
                  5  |   .2885954   .0915747     3.15   0.002     .1091124    .4680784
                  6  |   .1668512    .094679     1.76   0.078    -.0187163    .3524187
                  7  |   .2709419   .0923199     2.93   0.003     .0899982    .4518857
                  8  |   .1591414   .0925447     1.72   0.086    -.0222429    .3405256
                  9  |   .3342978   .0933745     3.58   0.000     .1512872    .5173085
                 10  |   .2160986   .0956469     2.26   0.024     .0286341     .403563
                 11  |   .1602028   .0943721     1.70   0.090    -.0247631    .3451687
                 12  |   .6289565   .0930651     6.76   0.000     .4465523    .8113607
                 13  |   .0777879   .0917354     0.85   0.396    -.1020101     .257586
                 14  |   .0958377   .0881515     1.09   0.277     -.076936    .2686115
                 15  |  -.0323237   .0947685    -0.34   0.733    -.2180665    .1534191
                 16  |   .2025899   .0916531     2.21   0.027     .0229532    .3822266
                 17  |   .1672044   .0931886     1.79   0.073     -.015442    .3498508
                 18  |   .0209636   .0942446     0.22   0.824    -.1637525    .2056797
                 19  |   .1070784   .0942738     1.14   0.256    -.0776948    .2918517
                 20  |   .1334149   .0936023     1.43   0.154    -.0500423    .3168721
                 21  |   .0954016   .0941487     1.01   0.311    -.0891265    .2799297
                 22  |   .1346549   .0938747     1.43   0.151    -.0493361    .3186458
                 23  |   .0493264   .0945263     0.52   0.602    -.1359416    .2345945
                 24  |   .2071587   .0931448     2.22   0.026     .0245982    .3897191
                 25  |   .0408463   .0954552     0.43   0.669    -.1462424     .227935
                 26  |   .0953376    .093766     1.02   0.309    -.0884404    .2791157
                 27  |   .2637546    .092446     2.85   0.004     .0825637    .4449454
                 28  |   .1492178   .0924783     1.61   0.107    -.0320362    .3304719
                 29  |    .017528   .0953773     0.18   0.854     -.169408     .204464
                 30  |  -.0006478   .0927815    -0.01   0.994    -.1824963    .1812006
                 31  |   .2070221   .0922865     2.24   0.025     .0261439    .3879004
                 32  |   .1248852   .0950878     1.31   0.189    -.0614835    .3112538
                 33  |   .3344386   .0901027     3.71   0.000     .1578405    .5110366
                 34  |   .0101591   .0934454     0.11   0.913    -.1729906    .1933088
                 35  |   .1770142    .091105     1.94   0.052    -.0015484    .3555767
                 36  |   .1827133   .0936154     1.95   0.051    -.0007695    .3661961
                 37  |   .0260876   .0957296     0.27   0.785    -.1615389    .2137141
                 38  |    .157762   .0887462     1.78   0.075    -.0161775    .3317014
                 39  |    .156675   .0942464     1.66   0.096    -.0280446    .3413946
                 40  |   .1000377   .0922314     1.08   0.278    -.0807325    .2808078
                 41  |   .0624254   .0948488     0.66   0.510    -.1234748    .2483255
                 42  |   .2378293   .0908753     2.62   0.009      .059717    .4159416
                 43  |  -.0395229   .0957428    -0.41   0.680    -.2271753    .1481295
                 44  |  -.0132497   .0919473    -0.14   0.885     -.193463    .1669636
                 45  |    .027419   .0941725     0.29   0.771    -.1571557    .2119937
                 46  |   .1786833   .0936974     1.91   0.057    -.0049603    .3623269
                 47  |   .1642247   .0944615     1.74   0.082    -.0209165    .3493659
                 48  |   .2542746   .0886025     2.87   0.004     .0806168    .4279323
                 49  |  -.0272762   .0939352    -0.29   0.772    -.2113857    .1568334
                 50  |   .2389857   .0925202     2.58   0.010     .0576495    .4203219
                 51  |    .151278   .0927131     1.63   0.103    -.0304363    .3329923
                     |
               _cons |   1.489997   1.545258     0.96   0.335    -1.538654    4.518648
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_logit fin_lit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   .3225725   .0140983    22.88   0.000     .2949404    .3502046
             fin_lit |   .2716858   .0072512    37.47   0.000     .2574739    .2858978
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/Logit.tex
dir : seeout

.         
. * baseline regressions with Bernoulli NB
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_bnb fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43442.257  
Iteration 2:   log pseudolikelihood = -43231.037  
Iteration 3:   log pseudolikelihood =  -43230.28  
Iteration 4:   log pseudolikelihood =  -43230.28  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    7394.20
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -43230.28               Pseudo R2         =     0.1278

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .2302462   .0830801     2.77   0.006     .0674122    .3930802
           fin_lit |    1.04705    .039953    26.21   0.000     .9687436    1.125357
               age |   .1288175   .0041721    30.88   0.000     .1206403    .1369946
              age2 |  -.0017158   .0000443   -38.77   0.000    -.0018025    -.001629
         logincome |  -1.422639    .237793    -5.98   0.000    -1.888704   -.9565731
        logincome2 |   .0956505   .0111932     8.55   0.000     .0737121    .1175888
      female_dummy |  -.1895596   .0213212    -8.89   0.000    -.2313485   -.1477707
    nonwhite_dummy |   .0764263   .0273375     2.80   0.005     .0228458    .1300068
     marital_dummy |   .0480697   .0242838     1.98   0.048     .0004742    .0956651
 high_school_dummy |   .4386485   .0688203     6.37   0.000     .3037631    .5735339
     college_dummy |   .3249139   .0249842    13.00   0.000     .2759457    .3738821
                   |
              year |
             2015  |    .030854   .0245513     1.26   0.209    -.0172656    .0789736
             2018  |   .0739669   .0250563     2.95   0.003     .0248575    .1230762
                   |
             _cons |   .2298901   1.259799     0.18   0.855    -2.239271    2.699051
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .0416694    .015043     2.77   0.006     .0121856    .0711532
           fin_lit |   .1894924   .0070836    26.75   0.000     .1756088     .203376
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Readiness")
../outputs/tables/BNB.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_bnb fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood =  -43385.34  
Iteration 2:   log pseudolikelihood = -43170.365  
Iteration 3:   log pseudolikelihood = -43169.572  
Iteration 4:   log pseudolikelihood = -43169.572  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    7501.81
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -43169.572               Pseudo R2         =     0.1290

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .3391891    .091009     3.73   0.000     .1608147    .5175635
           fin_lit |   1.043771    .040086    26.04   0.000     .9652042    1.122338
               age |   .1288863   .0041767    30.86   0.000     .1207002    .1370724
              age2 |  -.0017148   .0000443   -38.70   0.000    -.0018017    -.001628
         logincome |  -1.469463   .2383072    -6.17   0.000    -1.936536   -1.002389
        logincome2 |   .0980823    .011226     8.74   0.000     .0760798    .1200847
      female_dummy |  -.2089583     .02169    -9.63   0.000      -.25147   -.1664466
    nonwhite_dummy |   .0829981   .0289757     2.86   0.004     .0262068    .1397894
     marital_dummy |   .0571705   .0247008     2.31   0.021     .0087578    .1055832
 high_school_dummy |   .4576127   .0692669     6.61   0.000     .3218521    .5933733
     college_dummy |   .3377758   .0255087    13.24   0.000     .2877797    .3877719
                   |
              year |
             2015  |   .0299792   .0245361     1.22   0.222    -.0181107     .078069
             2018  |    .072206    .025077     2.88   0.004     .0230561    .1213559
                   |
        state_cate |
                2  |   .1505137   .0851812     1.77   0.077    -.0164384    .3174657
                3  |  -.0884375   .0895644    -0.99   0.323    -.2639805    .0871056
                4  |  -.1509443   .0897495    -1.68   0.093    -.3268501    .0249616
                5  |  -.1769101   .0850082    -2.08   0.037    -.3435232   -.0102971
                6  |  -.0932906    .086761    -1.08   0.282    -.2633391    .0767579
                7  |  -.0446552   .0879138    -0.51   0.611     -.216963    .1276526
                8  |  -.1537437   .0870146    -1.77   0.077    -.3242892    .0168017
                9  |   -.002409   .0872877    -0.03   0.978    -.1734897    .1686717
               10  |  -.1518651   .0908559    -1.67   0.095    -.3299393    .0262092
               11  |   .0337853   .0857929     0.39   0.694    -.1343656    .2019362
               12  |  -.0244601   .0896246    -0.27   0.785    -.2001211    .1512009
               13  |  -.1018248   .0868517    -1.17   0.241    -.2720511    .0684014
               14  |  -.0830355   .0842512    -0.99   0.324    -.2481649    .0820939
               15  |  -.0970689   .0865961    -1.12   0.262    -.2667941    .0726564
               16  |  -.0481063   .0872529    -0.55   0.581    -.2191189    .1229062
               17  |  -.0277537   .0877439    -0.32   0.752    -.1997285    .1442211
               18  |   -.093314   .0872071    -1.07   0.285    -.2642366    .0776087
               19  |  -.0668942   .0865606    -0.77   0.440    -.2365498    .1027615
               20  |  -.0217222   .0861923    -0.25   0.801     -.190656    .1472115
               21  |  -.0901459    .087071    -1.04   0.301    -.2608018    .0805101
               22  |  -.1919906    .089437    -2.15   0.032    -.3672839   -.0166974
               23  |  -.0840397   .0869704    -0.97   0.334    -.2544986    .0864192
               24  |  -.0888146    .086887    -1.02   0.307      -.25911    .0814807
               25  |   .0098004    .085034     0.12   0.908    -.1568632     .176464
               26  |  -.0893171   .0858666    -1.04   0.298    -.2576125    .0789782
               27  |   .1707574   .0855207     2.00   0.046     .0031398    .3383749
               28  |   .0073248   .0865564     0.08   0.933    -.1623226    .1769723
               29  |  -.1900035   .0889904    -2.14   0.033    -.3644215   -.0155856
               30  |  -.0409847   .0872438    -0.47   0.639    -.2119794      .13001
               31  |  -.1783665     .08912    -2.00   0.045    -.3530384   -.0036946
               32  |  -.0571951   .0895978    -0.64   0.523    -.2328036    .1184135
               33  |  -.0904534   .0849192    -1.07   0.287    -.2568921    .0759852
               34  |  -.1007643   .0874847    -1.15   0.249    -.2722312    .0707025
               35  |   .0681468   .0863292     0.79   0.430    -.1010553    .2373489
               36  |   -.081326   .0867772    -0.94   0.349    -.2514061    .0887542
               37  |  -.0555173   .0875323    -0.63   0.526    -.2270775    .1160429
               38  |   .0146007   .0817301     0.18   0.858    -.1455873    .1747886
               39  |  -.1958841   .0894514    -2.19   0.029    -.3712057   -.0205625
               40  |  -.1055597   .0872567    -1.21   0.226    -.2765796    .0654602
               41  |   .0250911   .0867186     0.29   0.772    -.1448742    .1950565
               42  |   .1284572   .0859896     1.49   0.135    -.0400793    .2969937
               43  |  -.0396525     .08728    -0.45   0.650    -.2107181    .1314131
               44  |  -.2845849   .0843568    -3.37   0.001    -.4499211   -.1192487
               45  |   .1913568   .0856706     2.23   0.026     .0234454    .3592681
               46  |  -.0685791   .0855288    -0.80   0.423    -.2362125    .0990543
               47  |  -.0209484   .0869355    -0.24   0.810    -.1913389    .1494421
               48  |  -.0839188   .0822646    -1.02   0.308    -.2451545     .077317
               49  |  -.1014192   .0871667    -1.16   0.245    -.2722628    .0694244
               50  |  -.0222395   .0863432    -0.26   0.797    -.1914691    .1469902
               51  |   .1157215   .0853996     1.36   0.175    -.0516586    .2831017
                   |
             _cons |    .473209   1.263473     0.37   0.708    -2.003152     2.94957
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .0612824   .0164482     3.73   0.000     .0290446    .0935202
           fin_lit |   .1885816   .0071053    26.54   0.000     .1746554    .2025078
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/BNB.tex
dir : seeout

.         
. *** precautionary saving
. ***** without state dummies
. logit precaution_dummy overconfidence_bnb fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47460.348  
Iteration 2:   log pseudolikelihood = -47425.168  
Iteration 3:   log pseudolikelihood = -47425.061  
Iteration 4:   log pseudolikelihood = -47425.061  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    8480.14
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -47425.061               Pseudo R2         =     0.1400

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .2491381   .0761435     3.27   0.001     .0998997    .3983765
           fin_lit |   .7465016   .0371411    20.10   0.000     .6737064    .8192967
               age |  -.1174308    .003889   -30.20   0.000    -.1250532   -.1098085
              age2 |   .0014176   .0000411    34.53   0.000     .0013371     .001498
         logincome |  -1.951479   .2349652    -8.31   0.000    -2.412002   -1.490956
        logincome2 |   .1284339   .0111453    11.52   0.000     .1065896    .1502782
      female_dummy |  -.2232632   .0203759   -10.96   0.000    -.2631992   -.1833272
    nonwhite_dummy |  -.0151107   .0262397    -0.58   0.565    -.0665396    .0363182
     marital_dummy |   .0845685   .0227598     3.72   0.000     .0399602    .1291769
 high_school_dummy |   .5244841    .062424     8.40   0.000     .4021352    .6468329
     college_dummy |   .3954477    .023853    16.58   0.000     .3486968    .4421987
                   |
              year |
             2015  |   .1985404   .0233139     8.52   0.000     .1528459    .2442349
             2018  |   .2895756   .0237646    12.19   0.000     .2429979    .3361533
                   |
             _cons |   6.624745    1.23619     5.36   0.000     4.201857    9.047634
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .0505719    .015464     3.27   0.001      .020263    .0808807
           fin_lit |   .1515304   .0074489    20.34   0.000     .1369307      .16613
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Precaution")
../outputs/tables/BNB.tex
dir : seeout

. 
. ***** with state dummies
. logit precaution_dummy overconfidence_bnb fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47374.546  
Iteration 2:   log pseudolikelihood = -47337.646  
Iteration 3:   log pseudolikelihood = -47337.531  
Iteration 4:   log pseudolikelihood =  -47337.53  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    8632.45
                                                Prob > chi2       =     0.0000
Log pseudolikelihood =  -47337.53               Pseudo R2         =     0.1416

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .1505793   .0850133     1.77   0.077    -.0160438    .3172024
           fin_lit |   .7410953   .0372433    19.90   0.000     .6680998    .8140908
               age |   -.117656   .0038956   -30.20   0.000    -.1252912   -.1100208
              age2 |   .0014178   .0000411    34.47   0.000     .0013372    .0014984
         logincome |  -1.899005   .2355516    -8.06   0.000    -2.360677   -1.437332
        logincome2 |   .1257776   .0111816    11.25   0.000     .1038621    .1476932
      female_dummy |  -.2112606   .0208179   -10.15   0.000     -.252063   -.1704582
    nonwhite_dummy |  -.0347121   .0278354    -1.25   0.212    -.0892685    .0198442
     marital_dummy |   .0810686   .0231903     3.50   0.000     .0356164    .1265208
 high_school_dummy |   .5054013   .0629482     8.03   0.000     .3820252    .6287775
     college_dummy |   .3767209   .0245875    15.32   0.000     .3285302    .4249115
                   |
              year |
             2015  |   .2009886   .0233278     8.62   0.000     .1552669    .2467103
             2018  |   .2931278   .0238092    12.31   0.000     .2464627     .339793
                   |
        state_cate |
                2  |   -.083648   .0854466    -0.98   0.328    -.2511203    .0838243
                3  |  -.1752394    .084926    -2.06   0.039    -.3416913   -.0087874
                4  |   -.092295   .0838919    -1.10   0.271    -.2567202    .0721301
                5  |   .0054073   .0826184     0.07   0.948    -.1565218    .1673364
                6  |   -.125207   .0849794    -1.47   0.141    -.2917635    .0413496
                7  |  -.1590425   .0855068    -1.86   0.063    -.3266328    .0085479
                8  |  -.1997237   .0835761    -2.39   0.017    -.3635299   -.0359176
                9  |  -.0992819   .0859988    -1.15   0.248    -.2678364    .0692727
               10  |   .0399587    .085829     0.47   0.642     -.128263    .2081804
               11  |  -.0172486   .0851979    -0.20   0.840    -.1842333    .1497361
               12  |   .0982341   .0868329     1.13   0.258    -.0719552    .2684234
               13  |  -.2184013   .0839484    -2.60   0.009    -.3829372   -.0538655
               14  |   .0604074   .0816145     0.74   0.459    -.0995541    .2203689
               15  |  -.2304049   .0840142    -2.74   0.006    -.3950696   -.0657401
               16  |  -.1210448   .0842761    -1.44   0.151     -.286223    .0441333
               17  |  -.2107393   .0834428    -2.53   0.012    -.3742843   -.0471943
               18  |  -.0464022   .0836406    -0.55   0.579    -.2103349    .1175304
               19  |  -.0561506    .083697    -0.67   0.502    -.2201938    .1078926
               20  |  -.2372782   .0843674    -2.81   0.005    -.4026354   -.0719211
               21  |  -.2788816   .0845633    -3.30   0.001    -.4446227   -.1131405
               22  |  -.0820735   .0860546    -0.95   0.340    -.2507375    .0865905
               23  |  -.1269054   .0824394    -1.54   0.124    -.2884836    .0346728
               24  |  -.0080374   .0837585    -0.10   0.924     -.172201    .1561261
               25  |  -.0937478   .0830969    -1.13   0.259    -.2566147    .0691192
               26  |  -.2400714   .0839207    -2.86   0.004     -.404553   -.0755899
               27  |  -.1997754    .081859    -2.44   0.015     -.360216   -.0393348
               28  |  -.1179643   .0841377    -1.40   0.161    -.2828711    .0469425
               29  |  -.0476964   .0848371    -0.56   0.574    -.2139742    .1185813
               30  |  -.1317882   .0842804    -1.56   0.118    -.2969747    .0333982
               31  |  -.1626291   .0856679    -1.90   0.058    -.3305352     .005277
               32  |  -.1255066   .0856068    -1.47   0.143    -.2932929    .0422797
               33  |   .1134338    .082731     1.37   0.170    -.0487158    .2755835
               34  |   -.027596     .08459    -0.33   0.744    -.1933894    .1381974
               35  |   .0554003    .083393     0.66   0.506    -.1080469    .2188476
               36  |    -.13888   .0838101    -1.66   0.098    -.3031447    .0253848
               37  |  -.2784577    .084468    -3.30   0.001    -.4440119   -.1129035
               38  |  -.1709225   .0792539    -2.16   0.031    -.3262573   -.0155877
               39  |  -.0542214   .0835602    -0.65   0.516    -.2179964    .1095536
               40  |  -.1002445   .0843186    -1.19   0.234    -.2655059    .0650168
               41  |  -.0503601   .0838041    -0.60   0.548    -.2146131     .113893
               42  |  -.0907123   .0835948    -1.09   0.278    -.2545551    .0731305
               43  |  -.2146925   .0839526    -2.56   0.011    -.3792366   -.0501484
               44  |  -.1518372   .0820351    -1.85   0.064    -.3126231    .0089487
               45  |  -.1365569   .0845386    -1.62   0.106    -.3022495    .0291356
               46  |  -.3020696   .0835226    -3.62   0.000    -.4657709   -.1383683
               47  |  -.2556806   .0848627    -3.01   0.003    -.4220085   -.0893528
               48  |   -.064388   .0797602    -0.81   0.420     -.220715    .0919391
               49  |  -.2224693    .082343    -2.70   0.007    -.3838586   -.0610799
               50  |  -.2099865   .0835169    -2.51   0.012    -.3736766   -.0462964
               51  |  -.1384034   .0834569    -1.66   0.097    -.3019758     .025169
                   |
             _cons |   6.532046   1.240323     5.27   0.000     4.101058    8.963034
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .0304946   .0172222     1.77   0.077    -.0032602    .0642494
           fin_lit |   .1500831   .0074558    20.13   0.000     .1354701    .1646962
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/BNB.tex
dir : seeout

.         
. *** financial market participation
. ***** without state dummies
. logit fin_par_dummy overconfidence_bnb fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -41327.413  
Iteration 2:   log pseudolikelihood = -40932.942  
Iteration 3:   log pseudolikelihood = -40926.269  
Iteration 4:   log pseudolikelihood = -40926.266  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    9443.80
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40926.266               Pseudo R2         =     0.1795

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |  -.2989289   .0941265    -3.18   0.001    -.4834135   -.1144443
           fin_lit |   1.200872   .0416762    28.81   0.000     1.119189    1.282556
               age |  -.0798302   .0042604   -18.74   0.000    -.0881805   -.0714799
              age2 |   .0009799   .0000442    22.18   0.000     .0008933    .0010665
         logincome |  -1.579352   .2812412    -5.62   0.000    -2.130575    -1.02813
        logincome2 |   .1173799   .0130748     8.98   0.000     .0917538    .1430059
      female_dummy |  -.2560624   .0220394   -11.62   0.000    -.2992588    -.212866
    nonwhite_dummy |  -.0035675   .0292749    -0.12   0.903    -.0609453    .0538103
     marital_dummy |  -.0435942   .0249292    -1.75   0.080    -.0924546    .0052662
 high_school_dummy |   .6489838   .0842101     7.71   0.000     .4839351    .8140325
     college_dummy |   .3823383   .0262672    14.56   0.000     .3308555     .433821
                   |
              year |
             2015  |  -.2353391   .0248167    -9.48   0.000     -.283979   -.1866991
             2018  |  -.1755437    .025512    -6.88   0.000    -.2255462   -.1255412
                   |
             _cons |   2.609686   1.518599     1.72   0.086    -.3667124    5.586085
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |  -.0507325   .0159473    -3.18   0.001    -.0819886   -.0194763
           fin_lit |   .2038051    .006921    29.45   0.000     .1902401    .2173701
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Participation")
../outputs/tables/BNB.tex
dir : seeout

. 
. ***** with state dummies
. logit fin_par_dummy overconfidence_bnb fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -41224.975  
Iteration 2:   log pseudolikelihood = -40824.275  
Iteration 3:   log pseudolikelihood = -40817.531  
Iteration 4:   log pseudolikelihood = -40817.527  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    9654.63
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40817.527               Pseudo R2         =     0.1817

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   -.267417   .1044781    -2.56   0.010    -.4721903   -.0626437
           fin_lit |   1.202328   .0418711    28.71   0.000     1.120262    1.284393
               age |  -.0799608   .0042699   -18.73   0.000    -.0883296    -.071592
              age2 |   .0009777   .0000443    22.07   0.000     .0008909    .0010645
         logincome |  -1.451072   .2815239    -5.15   0.000    -2.002848   -.8992947
        logincome2 |   .1107485   .0130965     8.46   0.000     .0850798    .1364171
      female_dummy |  -.2633512   .0225135   -11.70   0.000    -.3074768   -.2192256
    nonwhite_dummy |  -.0655849   .0311751    -2.10   0.035    -.1266871   -.0044828
     marital_dummy |  -.0250787   .0254586    -0.99   0.325    -.0749767    .0248193
 high_school_dummy |   .6556448   .0851072     7.70   0.000     .4888377    .8224519
     college_dummy |   .3783267   .0270495    13.99   0.000     .3253106    .4313427
                   |
              year |
             2015  |  -.2319397   .0248355    -9.34   0.000    -.2806163   -.1832631
             2018  |  -.1714866   .0255689    -6.71   0.000    -.2216007   -.1213726
                   |
        state_cate |
                2  |   .1241755   .0925616     1.34   0.180     -.057242     .305593
                3  |  -.0289542   .0940673    -0.31   0.758    -.2133226    .1554143
                4  |   .0266128   .0951606     0.28   0.780    -.1598985    .2131241
                5  |   .2636286   .0917211     2.87   0.004     .0838586    .4433986
                6  |   .0880227   .0948111     0.93   0.353    -.0978036    .2738491
                7  |   .2101563   .0924461     2.27   0.023     .0289652    .3913474
                8  |   .1120792   .0925121     1.21   0.226    -.0692412    .2933996
                9  |   .2972345   .0936908     3.17   0.002     .1136039    .4808651
               10  |   .1978983   .0957522     2.07   0.039     .0102274    .3855692
               11  |   .1480102   .0949162     1.56   0.119    -.0380221    .3340426
               12  |   .5275439   .0939154     5.62   0.000      .343473    .7116148
               13  |   .0246711   .0914507     0.27   0.787    -.1545689    .2039111
               14  |   .0526965   .0882085     0.60   0.550    -.1201889    .2255819
               15  |  -.0875297   .0946608    -0.92   0.355    -.2730615     .098002
               16  |   .1337821   .0918376     1.46   0.145    -.0462164    .3137806
               17  |   .1152204   .0929868     1.24   0.215    -.0670305    .2974712
               18  |  -.0033122   .0943961    -0.04   0.972     -.188325    .1817007
               19  |   .0961956   .0946996     1.02   0.310    -.0894121    .2818034
               20  |   .0902186   .0935182     0.96   0.335    -.0930738     .273511
               21  |   .0326477   .0942371     0.35   0.729    -.1520536     .217349
               22  |   .0755144   .0935332     0.81   0.419    -.1078073    .2588361
               23  |   .0241814   .0946161     0.26   0.798    -.1612628    .2096257
               24  |   .1344727   .0935794     1.44   0.151    -.0489396    .3178849
               25  |   .0349595   .0958001     0.36   0.715    -.1528052    .2227243
               26  |   .0619956   .0937459     0.66   0.508    -.1217429    .2457341
               27  |     .21253    .092386     2.30   0.021     .0314567    .3936033
               28  |   .0887262   .0922035     0.96   0.336    -.0919893    .2694417
               29  |  -.0293811   .0951284    -0.31   0.757    -.2158294    .1570672
               30  |  -.0648906   .0927159    -0.70   0.484    -.2466105    .1168293
               31  |    .125689   .0927132     1.36   0.175    -.0560256    .3074035
               32  |   .0771307    .094846     0.81   0.416     -.108764    .2630254
               33  |    .345171   .0908434     3.80   0.000     .1671212    .5232208
               34  |   -.013771   .0937442    -0.15   0.883    -.1975063    .1699643
               35  |   .1366722   .0907915     1.51   0.132    -.0412759    .3146203
               36  |   .1318743   .0939024     1.40   0.160    -.0521711    .3159196
               37  |   .0036128   .0953706     0.04   0.970    -.1833102    .1905357
               38  |   .1066583   .0882552     1.21   0.227    -.0663188    .2796353
               39  |   .1036779   .0937006     1.11   0.269    -.0799719    .2873277
               40  |   .0317218   .0922585     0.34   0.731    -.1491015    .2125452
               41  |     .03354   .0955816     0.35   0.726    -.1537965    .2208764
               42  |   .1753312   .0909751     1.93   0.054    -.0029768    .3536392
               43  |  -.0734294    .095519    -0.77   0.442    -.2606431    .1137844
               44  |   -.029359   .0923003    -0.32   0.750    -.2102642    .1515462
               45  |  -.0320823   .0941686    -0.34   0.733    -.2166495    .1524848
               46  |   .1266219   .0934807     1.35   0.176    -.0565968    .3098406
               47  |   .1579199   .0945193     1.67   0.095    -.0273345    .3431743
               48  |   .1901664   .0884345     2.15   0.032     .0168381    .3634948
               49  |  -.0771187   .0936435    -0.82   0.410    -.2606565    .1064192
               50  |   .1742611   .0925902     1.88   0.060    -.0072125    .3557346
               51  |   .1005196   .0926353     1.09   0.278    -.0810422    .2820814
                   |
             _cons |   1.898995   1.520892     1.25   0.212    -1.081899    4.879889
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |  -.0452397   .0176551    -2.56   0.010    -.0798431   -.0106363
           fin_lit |   .2034012   .0069373    29.32   0.000     .1898043    .2169982
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/BNB.tex
dir : seeout

. 
. * baseline regressions with KNN
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_knn fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43366.773  
Iteration 2:   log pseudolikelihood =     -43141  
Iteration 3:   log pseudolikelihood = -43139.993  
Iteration 4:   log pseudolikelihood = -43139.993  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    7235.59
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -43139.993               Pseudo R2         =     0.1296

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .9928558   .0891075    11.14   0.000     .8182082    1.167503
           fin_lit |   1.296216   .0462344    28.04   0.000     1.205599    1.386834
               age |    .143576   .0045016    31.89   0.000      .134753    .1523991
              age2 |  -.0018209   .0000463   -39.34   0.000    -.0019116   -.0017302
         logincome |  -1.804875   .2403074    -7.51   0.000    -2.275868   -1.333881
        logincome2 |   .1170476   .0113338    10.33   0.000     .0948337    .1392615
      female_dummy |   -.158188   .0199546    -7.93   0.000    -.1972984   -.1190776
    nonwhite_dummy |   .1097644   .0224747     4.88   0.000     .0657149    .1538139
     marital_dummy |   .0204483   .0228332     0.90   0.370    -.0243038    .0652005
 high_school_dummy |   .3723729   .0657369     5.66   0.000      .243531    .5012147
     college_dummy |   .2804008   .0209594    13.38   0.000     .2393211    .3214805
                   |
              year |
             2015  |   .0311056   .0245108     1.27   0.204    -.0169346    .0791457
             2018  |   .0761112     .02504     3.04   0.002     .0270337    .1251886
                   |
             _cons |   1.193025    1.27327     0.94   0.349    -1.302538    3.688588
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_knn fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .1794221   .0160224    11.20   0.000     .1480189    .2108254
           fin_lit |   .2342434   .0081296    28.81   0.000     .2183098    .2501771
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Readiness")
../outputs/tables/KNN.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_knn fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43314.697  
Iteration 2:   log pseudolikelihood =  -43085.77  
Iteration 3:   log pseudolikelihood = -43084.731  
Iteration 4:   log pseudolikelihood = -43084.731  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    7324.86
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -43084.731               Pseudo R2         =     0.1307

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .9881344   .0891872    11.08   0.000     .8133307    1.162938
           fin_lit |   1.281002   .0463547    27.63   0.000     1.190148    1.371855
               age |   .1433971   .0045057    31.83   0.000     .1345661    .1522281
              age2 |  -.0018176   .0000463   -39.23   0.000    -.0019084   -.0017268
         logincome |  -1.857958   .2407019    -7.72   0.000    -2.329725   -1.386191
        logincome2 |   .1197502   .0113612    10.54   0.000     .0974826    .1420178
      female_dummy |  -.1652758   .0200231    -8.25   0.000    -.2045203   -.1260312
    nonwhite_dummy |   .1338107   .0241021     5.55   0.000     .0865714      .18105
     marital_dummy |   .0182824   .0230765     0.79   0.428    -.0269468    .0635116
 high_school_dummy |   .3680946   .0657991     5.59   0.000     .2391308    .4970584
     college_dummy |   .2755972   .0210818    13.07   0.000     .2342777    .3169168
                   |
              year |
             2015  |   .0305185   .0244992     1.25   0.213    -.0174991    .0785361
             2018  |   .0745994   .0250572     2.98   0.003     .0254882    .1237107
                   |
        state_cate |
                2  |   .1132104   .0842435     1.34   0.179    -.0519038    .2783247
                3  |  -.0990652   .0893416    -1.11   0.268    -.2741715    .0760412
                4  |  -.1654906   .0897194    -1.84   0.065    -.3413375    .0103562
                5  |  -.1679242    .085122    -1.97   0.049    -.3347603   -.0010881
                6  |  -.1227519    .086017    -1.43   0.154    -.2913421    .0458382
                7  |  -.0726139   .0872869    -0.83   0.405    -.2436932    .0984653
                8  |  -.1765732   .0865889    -2.04   0.041    -.3462843   -.0068621
                9  |  -.0098813    .087382    -0.11   0.910    -.1811469    .1613843
               10  |  -.1340561   .0907157    -1.48   0.139    -.3118556    .0437434
               11  |   .0355328    .085788     0.41   0.679    -.1326085    .2036741
               12  |  -.0732164   .0881899    -0.83   0.406    -.2460656    .0996327
               13  |  -.1216074   .0863626    -1.41   0.159    -.2908749    .0476601
               14  |  -.0942653   .0841431    -1.12   0.263    -.2591827    .0706522
               15  |  -.1084238   .0864574    -1.25   0.210    -.2778772    .0610296
               16  |  -.0833266   .0864325    -0.96   0.335    -.2527312    .0860779
               17  |   -.041773    .087542    -0.48   0.633    -.2133521     .129806
               18  |  -.1017863   .0870844    -1.17   0.242    -.2724685    .0688959
               19  |  -.0492561   .0864674    -0.57   0.569    -.2187292     .120217
               20  |  -.0439206   .0856652    -0.51   0.608    -.2118213    .1239801
               21  |  -.1078653    .086665    -1.24   0.213    -.2777256     .061995
               22  |  -.2136162   .0888949    -2.40   0.016     -.387847   -.0393854
               23  |  -.0778592    .087017    -0.89   0.371    -.2484093    .0926909
               24  |   -.103769   .0864357    -1.20   0.230    -.2731799    .0656419
               25  |   .0112893   .0851195     0.13   0.894    -.1555419    .1781204
               26  |  -.0956833   .0858686    -1.11   0.265    -.2639828    .0726161
               27  |   .1418795   .0849994     1.67   0.095    -.0247161    .3084752
               28  |  -.0201861   .0859788    -0.23   0.814    -.1887015    .1483293
               29  |   -.207016   .0888024    -2.33   0.020    -.3810655   -.0329664
               30  |  -.0744861   .0863134    -0.86   0.388    -.2436572     .094685
               31  |  -.2138915   .0882345    -2.42   0.015    -.3868279   -.0409551
               32  |   -.084583   .0891435    -0.95   0.343    -.2593011    .0901351
               33  |  -.0652085   .0846116    -0.77   0.441    -.2310442    .1006271
               34  |  -.0989124   .0875638    -1.13   0.259    -.2705343    .0727094
               35  |   .0497565   .0859022     0.58   0.562    -.1186088    .2181218
               36  |  -.0925676   .0866088    -1.07   0.285    -.2623177    .0771824
               37  |  -.0706753   .0875852    -0.81   0.420    -.2423391    .1009885
               38  |   .0051183   .0815238     0.06   0.950    -.1546653     .164902
               39  |  -.1932659   .0895604    -2.16   0.031    -.3688011   -.0177307
               40  |  -.1391013   .0864436    -1.61   0.108    -.3085277    .0303252
               41  |    .004571   .0864541     0.05   0.958     -.164876     .174018
               42  |   .0969706   .0852777     1.14   0.255    -.0701706    .2641118
               43  |  -.0383545   .0871569    -0.44   0.660    -.2091789      .13247
               44  |  -.2670304   .0844052    -3.16   0.002    -.4324615   -.1015992
               45  |    .164233    .085212     1.93   0.054    -.0027793    .3312454
               46  |  -.1040395   .0845699    -1.23   0.219    -.2697935    .0617145
               47  |  -.0223019   .0870368    -0.26   0.798    -.1928909    .1482872
               48  |  -.0984068   .0820126    -1.20   0.230    -.2591486     .062335
               49  |  -.1122228   .0870042    -1.29   0.197    -.2827479    .0583023
               50  |  -.0365512   .0860057    -0.42   0.671    -.2051193     .132017
               51  |    .076193   .0845306     0.90   0.367    -.0894839    .2418698
                   |
             _cons |   1.544486    1.27572     1.21   0.226    -.9558792    4.044851
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_knn fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .1782908   .0160103    11.14   0.000     .1469112    .2096704
           fin_lit |   .2311333   .0081544    28.34   0.000     .2151511    .2471156
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/KNN.tex
dir : seeout

.         
. *** precautionary saving
. ***** without state dummies
. logit precaution_dummy overconfidence_knn fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47379.921  
Iteration 2:   log pseudolikelihood = -47336.892  
Iteration 3:   log pseudolikelihood = -47336.748  
Iteration 4:   log pseudolikelihood = -47336.748  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    8310.70
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -47336.748               Pseudo R2         =     0.1416

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .9324851   .0841138    11.09   0.000      .767625    1.097345
           fin_lit |   .9654583   .0422695    22.84   0.000     .8826117    1.048305
               age |  -.1058846   .0040966   -25.85   0.000    -.1139138   -.0978554
              age2 |   .0013463   .0000421    32.01   0.000     .0012638    .0014287
         logincome |  -2.346891    .238215    -9.85   0.000    -2.813783   -1.879998
        logincome2 |   .1503986   .0113264    13.28   0.000     .1281994    .1725979
      female_dummy |  -.1904735   .0190587    -9.99   0.000    -.2278279    -.153119
    nonwhite_dummy |   .0251586   .0218711     1.15   0.250    -.0177078    .0680251
     marital_dummy |   .0563068   .0211813     2.66   0.008     .0147922    .0978215
 high_school_dummy |   .4521757    .059885     7.55   0.000     .3348032    .5695481
     college_dummy |    .347593   .0202339    17.18   0.000     .3079352    .3872507
                   |
              year |
             2015  |   .1986784   .0233222     8.52   0.000     .1529678     .244389
             2018  |   .2921048   .0237796    12.28   0.000     .2454977    .3387119
                   |
             _cons |   7.776652    1.25168     6.21   0.000     5.323405     10.2299
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_knn fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .1889386   .0169722    11.13   0.000     .1556737    .2222035
           fin_lit |   .1956196   .0084162    23.24   0.000     .1791241     .212115
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Precaution")
../outputs/tables/KNN.tex
dir : seeout

. 
. ***** with state dummies
. logit precaution_dummy overconfidence_knn fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47289.147  
Iteration 2:   log pseudolikelihood = -47244.111  
Iteration 3:   log pseudolikelihood = -47243.956  
Iteration 4:   log pseudolikelihood = -47243.956  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    8472.57
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -47243.956               Pseudo R2         =     0.1433

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .9296792   .0843411    11.02   0.000     .7643736    1.094985
           fin_lit |   .9731724   .0424229    22.94   0.000     .8900251     1.05632
               age |  -.1060127   .0041032   -25.84   0.000    -.1140547   -.0979706
              age2 |   .0013451   .0000421    31.93   0.000     .0012626    .0014277
         logincome |  -2.286481   .2388437    -9.57   0.000    -2.754606   -1.818356
        logincome2 |   .1473942    .011366    12.97   0.000     .1251173    .1696711
      female_dummy |  -.1878561   .0191029    -9.83   0.000    -.2252972   -.1504151
    nonwhite_dummy |  -.0154711    .023288    -0.66   0.506    -.0611148    .0301726
     marital_dummy |   .0639332   .0213926     2.99   0.003     .0220045    .1058619
 high_school_dummy |   .4576897   .0598807     7.64   0.000     .3403257    .5750537
     college_dummy |   .3468908   .0203779    17.02   0.000     .3069508    .3868308
                   |
              year |
             2015  |   .2006809   .0233425     8.60   0.000     .1549304    .2464314
             2018  |   .2954167   .0238233    12.40   0.000     .2487238    .3421096
                   |
        state_cate |
                2  |  -.0992744   .0848858    -1.17   0.242    -.2656476    .0670987
                3  |  -.1754445   .0847696    -2.07   0.038    -.3415898   -.0092991
                4  |  -.1003089   .0836448    -1.20   0.230    -.2642496    .0636318
                5  |    .010843   .0828049     0.13   0.896    -.1514517    .1731377
                6  |  -.1389924   .0843996    -1.65   0.100    -.3044127    .0264279
                7  |   -.170272   .0851012    -2.00   0.045    -.3370672   -.0034768
                8  |  -.2074234   .0831795    -2.49   0.013    -.3704522   -.0443946
                9  |  -.1040088   .0860761    -1.21   0.227    -.2727148    .0646973
               10  |   .0481936   .0858636     0.56   0.575     -.120096    .2164832
               11  |  -.0158413   .0851103    -0.19   0.852    -.1826545    .1509719
               12  |    .083493   .0854672     0.98   0.329    -.0840198    .2510057
               13  |  -.2233887   .0835559    -2.67   0.008    -.3871554   -.0596221
               14  |   .0580351   .0814294     0.71   0.476    -.1015635    .2176338
               15  |   -.234191   .0838471    -2.79   0.005    -.3985282   -.0698537
               16  |  -.1353902   .0834558    -1.62   0.105    -.2989605    .0281801
               17  |   -.217992   .0831007    -2.62   0.009    -.3808663   -.0551176
               18  |  -.0480088   .0834336    -0.58   0.565    -.2115356     .115518
               19  |  -.0477244   .0835214    -0.57   0.568    -.2114234    .1159745
               20  |  -.2440103   .0838824    -2.91   0.004    -.4084169   -.0796038
               21  |  -.2844583   .0843553    -3.37   0.001    -.4497916    -.119125
               22  |  -.0878257   .0857379    -1.02   0.306    -.2558689    .0802176
               23  |  -.1247585   .0824931    -1.51   0.130     -.286442     .036925
               24  |  -.0113894   .0833973    -0.14   0.891    -.1748451    .1520662
               25  |  -.0923427   .0831171    -1.11   0.267    -.2552492    .0705638
               26  |  -.2440951   .0838919    -2.91   0.004    -.4085201   -.0796701
               27  |  -.2106656    .081353    -2.59   0.010    -.3701146   -.0512166
               28  |  -.1286373   .0836693    -1.54   0.124    -.2926261    .0353514
               29  |  -.0565002   .0845554    -0.67   0.504    -.2222258    .1092254
               30  |  -.1427823   .0833452    -1.71   0.087    -.3061359    .0205713
               31  |  -.1737135   .0849354    -2.05   0.041    -.3401839   -.0072432
               32  |  -.1346223   .0852047    -1.58   0.114    -.3016204    .0323759
               33  |    .122654   .0823627     1.49   0.136     -.038774    .2840819
               34  |  -.0260266   .0846177    -0.31   0.758    -.1918743    .1398211
               35  |   .0482442   .0831694     0.58   0.562    -.1147649    .2112533
               36  |  -.1411934   .0835892    -1.69   0.091    -.3050253    .0226384
               37  |  -.2865417   .0844195    -3.39   0.001    -.4520009   -.1210825
               38  |  -.1748641   .0792317    -2.21   0.027    -.3301554   -.0195728
               39  |  -.0506489   .0835561    -0.61   0.544    -.2144158    .1131181
               40  |  -.1116673   .0834348    -1.34   0.181    -.2751965    .0518619
               41  |  -.0581386   .0835384    -0.70   0.486    -.2218709    .1055937
               42  |  -.1025132     .08286    -1.24   0.216    -.2649159    .0598895
               43  |  -.2134585   .0838086    -2.55   0.011    -.3777204   -.0491966
               44  |  -.1437171   .0820109    -1.75   0.080    -.3044556    .0170214
               45  |  -.1474578    .084094    -1.75   0.080     -.312279    .0173634
               46  |  -.3149338   .0827475    -3.81   0.000    -.4771159   -.1527517
               47  |  -.2599085   .0848402    -3.06   0.002    -.4261923   -.0936248
               48  |  -.0688311   .0795922    -0.86   0.387    -.2248289    .0871667
               49  |  -.2248615   .0821776    -2.74   0.006    -.3859265   -.0637964
               50  |  -.2155748   .0830934    -2.59   0.009    -.3784349   -.0527147
               51  |  -.1538407   .0826109    -1.86   0.063    -.3157551    .0080736
                   |
             _cons |    7.58657   1.255214     6.04   0.000     5.126395    10.04674
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_knn fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .1879053   .0169744    11.07   0.000     .1546361    .2211746
           fin_lit |   .1966961   .0084266    23.34   0.000     .1801804    .2132119
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/KNN.tex
dir : seeout

.         
. *** financial market participation
. ***** without state dummies
. logit fin_par_dummy overconfidence_knn fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -41226.463  
Iteration 2:   log pseudolikelihood = -40806.914  
Iteration 3:   log pseudolikelihood = -40799.615  
Iteration 4:   log pseudolikelihood = -40799.609  
Iteration 5:   log pseudolikelihood = -40799.609  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    9209.06
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40799.609               Pseudo R2         =     0.1820

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   1.295709   .0969058    13.37   0.000     1.105777    1.485641
           fin_lit |   1.602989   .0490767    32.66   0.000       1.5068    1.699177
               age |  -.0590647   .0046274   -12.76   0.000    -.0681342   -.0499953
              age2 |    .000831   .0000463    17.94   0.000     .0007402    .0009218
         logincome |  -1.787947   .2874656    -6.22   0.000    -2.351369   -1.224524
        logincome2 |   .1320792   .0133318     9.91   0.000     .1059493    .1582091
      female_dummy |  -.2734561   .0202716   -13.49   0.000    -.3131877   -.2337246
    nonwhite_dummy |  -.0679766   .0238533    -2.85   0.004    -.1147281   -.0212251
     marital_dummy |   -.017178   .0230353    -0.75   0.456    -.0623263    .0279704
 high_school_dummy |   .7065413   .0814922     8.67   0.000     .5468194    .8662632
     college_dummy |   .4297535    .021482    20.01   0.000     .3876495    .4718575
                   |
              year |
             2015  |  -.2380084    .024814    -9.59   0.000     -.286643   -.1893739
             2018  |  -.1752209   .0255347    -6.86   0.000    -.2252679   -.1251739
                   |
             _cons |   1.919293   1.571448     1.22   0.222    -1.160687    4.999274
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_knn fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .2191838   .0162764    13.47   0.000     .1872826     .251085
           fin_lit |   .2711637   .0080203    33.81   0.000     .2554442    .2868832
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Participation")
../outputs/tables/KNN.tex
dir : seeout

. 
. ***** with state dummies
. logit fin_par_dummy overconfidence_knn fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -41119.674  
Iteration 2:   log pseudolikelihood = -40694.531  
Iteration 3:   log pseudolikelihood = -40687.142  
Iteration 4:   log pseudolikelihood = -40687.135  
Iteration 5:   log pseudolikelihood = -40687.135  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    9405.30
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40687.135               Pseudo R2         =     0.1843

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |    1.29985    .097153    13.38   0.000     1.109433    1.490266
           fin_lit |   1.597228   .0493081    32.39   0.000     1.500585     1.69387
               age |  -.0593289   .0046388   -12.79   0.000    -.0684208   -.0502371
              age2 |   .0008304   .0000464    17.88   0.000     .0007394    .0009214
         logincome |  -1.673075   .2876776    -5.82   0.000    -2.236913   -1.109237
        logincome2 |   .1260622   .0133523     9.44   0.000     .0998921    .1522323
      female_dummy |  -.2794592    .020345   -13.74   0.000    -.3193346   -.2395838
    nonwhite_dummy |  -.1213169   .0256584    -4.73   0.000    -.1716064   -.0710274
     marital_dummy |  -.0027144   .0233174    -0.12   0.907    -.0484157     .042987
 high_school_dummy |   .7026113   .0818019     8.59   0.000     .5422826      .86294
     college_dummy |   .4192693   .0216291    19.38   0.000      .376877    .4616615
                   |
              year |
             2015  |  -.2344459   .0248436    -9.44   0.000    -.2831384   -.1857534
             2018  |  -.1710004   .0255987    -6.68   0.000    -.2211729   -.1208279
                   |
        state_cate |
                2  |   .1601762    .091924     1.74   0.081    -.0199916     .340344
                3  |   .0052037   .0937118     0.06   0.956     -.178468    .1888755
                4  |   .0378312   .0948697     0.40   0.690    -.1481101    .2237724
                5  |   .2593868    .091491     2.84   0.005     .0800677    .4387059
                6  |   .1201831   .0944394     1.27   0.203    -.0649147    .3052809
                7  |   .2404565    .091979     2.61   0.009     .0601809     .420732
                8  |   .1439108   .0924133     1.56   0.119    -.0372159    .3250375
                9  |   .2977597   .0934624     3.19   0.001     .1145767    .4809427
               10  |   .1886773   .0953024     1.98   0.048     .0018879    .3754666
               11  |   .1545148   .0945357     1.63   0.102    -.0307718    .3398015
               12  |   .5911036   .0926016     6.38   0.000     .4096078    .7725993
               13  |   .0574759   .0913784     0.63   0.529    -.1216225    .2365742
               14  |   .0742219   .0881346     0.84   0.400    -.0985186    .2469625
               15  |  -.0651057   .0943889    -0.69   0.490    -.2501046    .1198932
               16  |    .172731   .0912725     1.89   0.058    -.0061599    .3516219
               17  |   .1299742   .0927857     1.40   0.161    -.0518824    .3118309
               18  |   .0096688   .0941677     0.10   0.918    -.1748965    .1942341
               19  |   .0946894   .0942776     1.00   0.315    -.0900912    .2794701
               20  |   .1242311     .09351     1.33   0.184    -.0590452    .3075074
               21  |    .062687   .0938858     0.67   0.504    -.1213257    .2466997
               22  |   .1088745   .0935044     1.16   0.244    -.0743907    .2921398
               23  |   .0236889   .0944625     0.25   0.802    -.1614541     .208832
               24  |   .1722289   .0931628     1.85   0.065    -.0103668    .3548247
               25  |   .0409834   .0956962     0.43   0.668    -.1465776    .2285444
               26  |   .0751749   .0935798     0.80   0.422    -.1082382     .258588
               27  |   .2422964   .0919897     2.63   0.008     .0619999     .422593
               28  |   .1235827   .0919545     1.34   0.179    -.0566449    .3038103
               29  |  -.0146069   .0948182    -0.15   0.878    -.2004471    .1712333
               30  |  -.0208632   .0921763    -0.23   0.821    -.2015254     .159799
               31  |   .1784409   .0921059     1.94   0.053    -.0020833    .3589651
               32  |   .1137554   .0945069     1.20   0.229    -.0714747    .2989856
               33  |   .3124032   .0898276     3.48   0.001     .1363444     .488462
               34  |  -.0061416   .0933728    -0.07   0.948    -.1891489    .1768656
               35  |   .1615482   .0906368     1.78   0.075    -.0160967    .3391932
               36  |   .1543634   .0934321     1.65   0.099    -.0287601    .3374869
               37  |   .0130417   .0952627     0.14   0.891    -.1736697    .1997531
               38  |   .1227864   .0882563     1.39   0.164    -.0501928    .2957655
               39  |    .117294   .0936704     1.25   0.210    -.0662967    .3008847
               40  |   .0729439   .0917702     0.79   0.427    -.1069223    .2528102
               41  |   .0533671   .0951342     0.56   0.575    -.1330926    .2398268
               42  |   .2121535   .0905342     2.34   0.019     .0347097    .3895972
               43  |  -.0617935   .0952911    -0.65   0.517    -.2485606    .1249737
               44  |   -.038292   .0918766    -0.42   0.677    -.2183667    .1417828
               45  |  -.0002809   .0937754    -0.00   0.998    -.1840773    .1835154
               46  |   .1655328   .0930881     1.78   0.075    -.0169165    .3479821
               47  |   .1472179   .0943085     1.56   0.119    -.0376233    .3320591
               48  |   .2159114   .0881537     2.45   0.014     .0431334    .3886894
               49  |  -.0517344   .0935837    -0.55   0.580     -.235155    .1316863
               50  |   .2027746   .0923169     2.20   0.028     .0218368    .3837124
               51  |   .1382754   .0922347     1.50   0.134    -.0425012    .3190521
                   |
             _cons |    1.28836   1.572115     0.82   0.412    -1.792929    4.369649
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_knn fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .2191511   .0162631    13.48   0.000      .187276    .2510261
           fin_lit |   .2692882   .0080455    33.47   0.000     .2535193    .2850571
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/KNN.tex
dir : seeout

. 
. * baseline regressions with MLP
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_mlp fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43328.437  
Iteration 2:   log pseudolikelihood = -43117.141  
Iteration 3:   log pseudolikelihood = -43116.377  
Iteration 4:   log pseudolikelihood = -43116.377  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    7459.30
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -43116.377               Pseudo R2         =     0.1301

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   1.368244   .1104145    12.39   0.000     1.151835    1.584652
           fin_lit |   1.282954   .0441667    29.05   0.000     1.196389    1.369519
               age |   .1260768   .0041837    30.14   0.000     .1178769    .1342768
              age2 |  -.0017014   .0000443   -38.38   0.000    -.0017883   -.0016145
         logincome |  -1.495698    .239435    -6.25   0.000    -1.964982   -1.026414
        logincome2 |   .1057893   .0113029     9.36   0.000     .0836361    .1279425
      female_dummy |  -.1605401   .0199968    -8.03   0.000    -.1997331   -.1213471
    nonwhite_dummy |   .1122251   .0225187     4.98   0.000     .0680891     .156361
     marital_dummy |   .0213764   .0228866     0.93   0.350    -.0234804    .0662333
 high_school_dummy |   .3576595   .0657354     5.44   0.000     .2288205    .4864985
     college_dummy |   .2813072   .0210475    13.37   0.000     .2400548    .3225596
                   |
              year |
             2015  |   .0317957   .0245824     1.29   0.196    -.0163849    .0799763
             2018  |   .0803577   .0251124     3.20   0.001     .0311383    .1295772
                   |
             _cons |  -.3260928   1.267816    -0.26   0.797    -2.810966    2.158781
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .2467683   .0198236    12.45   0.000     .2079147    .2856219
           fin_lit |    .231386   .0077587    29.82   0.000     .2161792    .2465928
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Readiness")
../outputs/tables/MLP.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_mlp fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49564.375  
Iteration 1:   log pseudolikelihood = -43276.686  
Iteration 2:   log pseudolikelihood = -43062.125  
Iteration 3:   log pseudolikelihood = -43061.332  
Iteration 4:   log pseudolikelihood = -43061.332  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    7548.81
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -43061.332               Pseudo R2         =     0.1312

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   1.362958   .1104679    12.34   0.000     1.146445    1.579471
           fin_lit |    1.26786   .0442993    28.62   0.000     1.181035    1.354685
               age |    .125982    .004188    30.08   0.000     .1177736    .1341903
              age2 |  -.0016986   .0000444   -38.27   0.000    -.0017856   -.0016116
         logincome |  -1.549357   .2398775    -6.46   0.000    -2.019508   -1.079206
        logincome2 |   .1085062   .0113316     9.58   0.000     .0862967    .1307156
      female_dummy |   -.167755    .020065    -8.36   0.000    -.2070818   -.1284283
    nonwhite_dummy |   .1361431   .0241601     5.64   0.000     .0887901    .1834961
     marital_dummy |   .0189582   .0231263     0.82   0.412    -.0263684    .0642849
 high_school_dummy |   .3530581   .0657918     5.37   0.000     .2241086    .4820075
     college_dummy |   .2766053   .0211689    13.07   0.000     .2351149    .3180957
                   |
              year |
             2015  |   .0312069   .0245714     1.27   0.204    -.0169521    .0793659
             2018  |   .0788305   .0251311     3.14   0.002     .0295745    .1280866
                   |
        state_cate |
                2  |   .1186143   .0844181     1.41   0.160    -.0468421    .2840706
                3  |  -.1032233   .0893397    -1.16   0.248     -.278326    .0718794
                4  |  -.1599203    .089674    -1.78   0.075     -.335678    .0158375
                5  |   -.164743   .0852062    -1.93   0.053    -.3317441    .0022581
                6  |  -.1187435   .0862692    -1.38   0.169    -.2878281    .0503411
                7  |   -.068609    .087528    -0.78   0.433    -.2401608    .1029428
                8  |  -.1759433   .0867283    -2.03   0.042    -.3459277   -.0059589
                9  |  -.0129621    .087528    -0.15   0.882    -.1845139    .1585896
               10  |  -.1351008   .0907986    -1.49   0.137    -.3130628    .0428613
               11  |   .0350454   .0858908     0.41   0.683    -.1332975    .2033883
               12  |  -.0713154    .088316    -0.81   0.419    -.2444115    .1017807
               13  |  -.1207088   .0865072    -1.40   0.163    -.2902598    .0488422
               14  |  -.0908188   .0842138    -1.08   0.281    -.2558748    .0742373
               15  |  -.1100659   .0864445    -1.27   0.203     -.279494    .0593622
               16  |  -.0792958   .0865066    -0.92   0.359    -.2488456    .0902539
               17  |  -.0432479    .087746    -0.49   0.622     -.215227    .1287311
               18  |  -.1027963   .0871301    -1.18   0.238    -.2735682    .0679755
               19  |  -.0495016   .0865406    -0.57   0.567     -.219118    .1201149
               20  |  -.0430096   .0857396    -0.50   0.616    -.2110562     .125037
               21  |  -.1069969     .08696    -1.23   0.219    -.2774353    .0634416
               22  |  -.2127105   .0892263    -2.38   0.017    -.3875908   -.0378302
               23  |  -.0813997    .086974    -0.94   0.349    -.2518656    .0890662
               24  |  -.1066109   .0865391    -1.23   0.218    -.2762244    .0630025
               25  |   .0133721   .0851664     0.16   0.875     -.153551    .1802953
               26  |  -.0975782   .0859325    -1.14   0.256    -.2660027    .0708464
               27  |   .1454728   .0851354     1.71   0.088    -.0213895    .3123352
               28  |  -.0201358    .086127    -0.23   0.815    -.1889416      .14867
               29  |  -.2003365    .088773    -2.26   0.024    -.3743285   -.0263445
               30  |  -.0753001   .0864615    -0.87   0.384    -.2447614    .0941613
               31  |  -.2074484   .0884805    -2.34   0.019     -.380867   -.0340298
               32  |  -.0840857   .0890884    -0.94   0.345    -.2586957    .0905243
               33  |  -.0691774   .0848674    -0.82   0.415    -.2355145    .0971597
               34  |  -.1015027   .0875709    -1.16   0.246    -.2731386    .0701332
               35  |   .0525803   .0860856     0.61   0.541    -.1161443    .2213049
               36  |  -.0885999   .0866707    -1.02   0.307    -.2584714    .0812716
               37  |  -.0652958   .0876306    -0.75   0.456    -.2370486     .106457
               38  |   .0063124   .0816554     0.08   0.938    -.1537292    .1663539
               39  |  -.1965763   .0897491    -2.19   0.029    -.3724814   -.0206712
               40  |  -.1349178   .0865988    -1.56   0.119    -.3046483    .0348127
               41  |   .0083155   .0863469     0.10   0.923    -.1609214    .1775524
               42  |   .0996049   .0853444     1.17   0.243     -.067667    .2668769
               43  |  -.0421441   .0872414    -0.48   0.629    -.2131341    .1288459
               44  |  -.2638859   .0845043    -3.12   0.002    -.4295114   -.0982605
               45  |   .1704389   .0852111     2.00   0.045     .0034283    .3374496
               46  |  -.0965003   .0847391    -1.14   0.255    -.2625859    .0695853
               47  |  -.0213905   .0871426    -0.25   0.806    -.1921869    .1494059
               48  |  -.0948515   .0821622    -1.15   0.248    -.2558865    .0661835
               49  |  -.1105556    .087063    -1.27   0.204     -.281196    .0600848
               50  |  -.0394629   .0861866    -0.46   0.647    -.2083855    .1294597
               51  |   .0817117   .0845598     0.97   0.334    -.0840225    .2474458
                   |
             _cons |   .0266003   1.270696     0.02   0.983    -2.463918    2.517118
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .2454381   .0198023    12.39   0.000     .2066263      .28425
           fin_lit |   .2283132   .0077877    29.32   0.000     .2130495    .2435769
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/MLP.tex
dir : seeout

.         
. *** precautionary saving
. ***** without state dummies
. logit precaution_dummy overconfidence_mlp fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47406.625  
Iteration 2:   log pseudolikelihood = -47367.896  
Iteration 3:   log pseudolikelihood = -47367.769  
Iteration 4:   log pseudolikelihood = -47367.769  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    8432.91
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -47367.769               Pseudo R2         =     0.1411

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .9562895   .1056467     9.05   0.000     .7492259    1.163353
           fin_lit |   .9003593   .0411129    21.90   0.000     .8197796    .9809391
               age |  -.1196864   .0039007   -30.68   0.000    -.1273317   -.1120411
              age2 |   .0014289   .0000411    34.78   0.000     .0013483    .0015094
         logincome |  -2.024902   .2366421    -8.56   0.000    -2.488712   -1.561092
        logincome2 |   .1367543   .0112534    12.15   0.000     .1146981    .1588105
      female_dummy |  -.1942353   .0190623   -10.19   0.000    -.2315968   -.1568739
    nonwhite_dummy |     .02833   .0219139     1.29   0.196    -.0146206    .0712805
     marital_dummy |   .0562979   .0212379     2.65   0.008     .0146724    .0979234
 high_school_dummy |   .4482495   .0598874     7.48   0.000     .3308723    .5656266
     college_dummy |   .3477726   .0202701    17.16   0.000      .308044    .3875012
                   |
              year |
             2015  |    .199527   .0233203     8.56   0.000       .15382     .245234
             2018  |   .2944466   .0237884    12.38   0.000     .2478222     .341071
                   |
             _cons |   6.391966   1.244496     5.14   0.000     3.952798    8.831134
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .1938544   .0213712     9.07   0.000     .1519676    .2357412
           fin_lit |   .1825165   .0082096    22.23   0.000      .166426     .198607
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Precaution")
../outputs/tables/MLP.tex
dir : seeout

. 
. ***** with state dummies
. logit precaution_dummy overconfidence_mlp fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -55147.986  
Iteration 1:   log pseudolikelihood = -47316.211  
Iteration 2:   log pseudolikelihood =  -47275.43  
Iteration 3:   log pseudolikelihood = -47275.294  
Iteration 4:   log pseudolikelihood = -47275.294  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    8596.28
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -47275.294               Pseudo R2         =     0.1428

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .9502053   .1061808     8.95   0.000     .7420948    1.158316
           fin_lit |   .9076694    .041278    21.99   0.000      .826766    .9885728
               age |  -.1197598   .0039076   -30.65   0.000    -.1274185   -.1121011
              age2 |   .0014275   .0000412    34.68   0.000     .0013468    .0015081
         logincome |   -1.96464   .2372349    -8.28   0.000    -2.429612   -1.499668
        logincome2 |   .1337379   .0112917    11.84   0.000     .1116066    .1558693
      female_dummy |  -.1915978   .0191056   -10.03   0.000    -.2290441   -.1541516
    nonwhite_dummy |  -.0123948   .0233318    -0.53   0.595    -.0581243    .0333347
     marital_dummy |   .0637862   .0214481     2.97   0.003     .0217486    .1058238
 high_school_dummy |   .4537332   .0599004     7.57   0.000     .3363306    .5711358
     college_dummy |   .3472319   .0204142    17.01   0.000     .3072209    .3872429
                   |
              year |
             2015  |   .2014329   .0233412     8.63   0.000     .1556851    .2471808
             2018  |   .2977038   .0238324    12.49   0.000     .2509931    .3444145
                   |
        state_cate |
                2  |  -.0955102   .0848815    -1.13   0.260    -.2618748    .0708544
                3  |  -.1793932   .0848683    -2.11   0.035    -.3457321   -.0130544
                4  |  -.0963294   .0838117    -1.15   0.250    -.2605974    .0679386
                5  |    .013363   .0828809     0.16   0.872    -.1490806    .1758066
                6  |  -.1356018    .084487    -1.61   0.108    -.3011933    .0299897
                7  |  -.1685127   .0850865    -1.98   0.048    -.3352793   -.0017461
                8  |  -.2074723   .0831603    -2.49   0.013    -.3704635   -.0444812
                9  |  -.1056861     .08612    -1.23   0.220    -.2744782     .063106
               10  |   .0483174   .0858431     0.56   0.574    -.1199319    .2165667
               11  |  -.0160163   .0853189    -0.19   0.851    -.1832383    .1512058
               12  |   .0821372    .085412     0.96   0.336    -.0852672    .2495416
               13  |  -.2233745   .0836155    -2.67   0.008    -.3872579   -.0594912
               14  |   .0600448   .0815235     0.74   0.461    -.0997382    .2198279
               15  |   -.234339   .0838965    -2.79   0.005     -.398773    -.069905
               16  |  -.1328738   .0835744    -1.59   0.112    -.2966766     .030929
               17  |  -.2181295   .0833343    -2.62   0.009    -.3814618   -.0547972
               18  |  -.0497362   .0836243    -0.59   0.552    -.2136368    .1141644
               19  |  -.0472996   .0836647    -0.57   0.572    -.2112793    .1166802
               20  |  -.2450557   .0839172    -2.92   0.003    -.4095304   -.0805809
               21  |  -.2841633   .0844148    -3.37   0.001    -.4496132   -.1187134
               22  |  -.0870795   .0858083    -1.01   0.310    -.2552606    .0811016
               23  |  -.1271088   .0825715    -1.54   0.124    -.2889459    .0347283
               24  |  -.0141043   .0835454    -0.17   0.866    -.1778503    .1496416
               25  |  -.0896047   .0832223    -1.08   0.282    -.2527174    .0735081
               26  |  -.2428726   .0838872    -2.90   0.004    -.4072884   -.0784568
               27  |  -.2075566   .0815182    -2.55   0.011    -.3673294   -.0477838
               28  |  -.1277427   .0836424    -1.53   0.127    -.2916788    .0361934
               29  |  -.0499957   .0846902    -0.59   0.555    -.2159854    .1159941
               30  |  -.1457022   .0833661    -1.75   0.081    -.3090967    .0176923
               31  |  -.1709412   .0849592    -2.01   0.044    -.3374582   -.0044243
               32  |  -.1358743   .0851637    -1.60   0.111    -.3027921    .0310436
               33  |    .124333   .0825407     1.51   0.132    -.0374438    .2861098
               34  |  -.0267701   .0846393    -0.32   0.752    -.1926601    .1391199
               35  |   .0501238   .0832053     0.60   0.547    -.1129556    .2132033
               36  |  -.1395578   .0837846    -1.67   0.096    -.3037725    .0246569
               37  |  -.2809234   .0844443    -3.33   0.001    -.4464311   -.1154156
               38  |   -.173214    .079294    -2.18   0.029    -.3286274   -.0178007
               39  |  -.0523889   .0837134    -0.63   0.531    -.2164641    .1116864
               40  |  -.1109947   .0835843    -1.33   0.184    -.2748168    .0528275
               41  |  -.0554196    .083592    -0.66   0.507    -.2192569    .1084176
               42  |  -.1015111   .0829853    -1.22   0.221    -.2641593     .061137
               43  |  -.2152012   .0837776    -2.57   0.010    -.3794023   -.0510001
               44  |  -.1399833   .0820632    -1.71   0.088    -.3008242    .0208577
               45  |  -.1431451   .0842249    -1.70   0.089    -.3082229    .0219326
               46  |  -.3104131   .0828294    -3.75   0.000    -.4727558   -.1480705
               47  |  -.2574432   .0848565    -3.03   0.002    -.4237588   -.0911276
               48  |  -.0669342   .0796533    -0.84   0.401    -.2230519    .0891834
               49  |  -.2245735   .0822436    -2.73   0.006     -.385768    -.063379
               50  |  -.2168823   .0833408    -2.60   0.009    -.3802273   -.0535373
               51  |  -.1499919   .0826314    -1.82   0.069    -.3119464    .0119626
                   |
             _cons |   6.202866   1.248091     4.97   0.000     3.756653    8.649079
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .1921501    .021426     8.97   0.000     .1501559    .2341443
           fin_lit |   .1835485   .0082236    22.32   0.000     .1674305    .1996666
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/MLP.tex
dir : seeout

.         
. *** financial market participation
. ***** without state dummies
. logit fin_par_dummy overconfidence_mlp fin_lit `household_X' i.year [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood = -41314.153  
Iteration 2:   log pseudolikelihood = -40915.587  
Iteration 3:   log pseudolikelihood = -40908.802  
Iteration 4:   log pseudolikelihood = -40908.798  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(13)     =    9464.98
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40908.798               Pseudo R2         =     0.1798

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .7087554   .1164607     6.09   0.000     .4804965    .9370143
           fin_lit |   1.377432    .046107    29.87   0.000     1.287064      1.4678
               age |  -.0803934   .0042631   -18.86   0.000    -.0887488    -.072038
              age2 |   .0009787   .0000442    22.16   0.000     .0008921    .0010653
         logincome |  -1.540884   .2832972    -5.44   0.000    -2.096137   -.9856319
        logincome2 |   .1192747   .0131539     9.07   0.000     .0934935    .1450559
      female_dummy |  -.2811898   .0202832   -13.86   0.000    -.3209441   -.2414355
    nonwhite_dummy |  -.0591623   .0239167    -2.47   0.013    -.1060382   -.0122864
     marital_dummy |  -.0131319   .0230988    -0.57   0.570    -.0584046    .0321409
 high_school_dummy |   .7095282   .0813289     8.72   0.000     .5501265      .86893
     college_dummy |   .4309111   .0215187    20.02   0.000     .3887351     .473087
                   |
              year |
             2015  |  -.2358358   .0248082    -9.51   0.000    -.2844591   -.1872125
             2018  |  -.1735901   .0255221    -6.80   0.000    -.2236124   -.1235677
                   |
             _cons |   1.639994     1.5347     1.07   0.285    -1.367962     4.64795
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .1202316   .0197618     6.08   0.000     .0814991    .1589641
           fin_lit |   .2336643   .0076438    30.57   0.000     .2186827    .2486459
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, No) ///
>         ctitle("Participation")
../outputs/tables/MLP.tex
dir : seeout

. 
. ***** with state dummies
. logit fin_par_dummy overconfidence_mlp fin_lit `household_X' i.year i.state_cate [pw=weights]

Iteration 0:   log pseudolikelihood = -49879.082  
Iteration 1:   log pseudolikelihood =  -41208.01  
Iteration 2:   log pseudolikelihood = -40803.512  
Iteration 3:   log pseudolikelihood = -40796.663  
Iteration 4:   log pseudolikelihood = -40796.659  
Iteration 5:   log pseudolikelihood = -40796.659  

Logistic regression                             Number of obs     =     80,164
                                                Wald chi2(63)     =    9664.07
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -40796.659               Pseudo R2         =     0.1821

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |    .709135   .1167704     6.07   0.000     .4802693    .9380007
           fin_lit |   1.371151   .0463532    29.58   0.000     1.280301    1.462002
               age |  -.0806954   .0042723   -18.89   0.000    -.0890689   -.0723219
              age2 |   .0009783   .0000443    22.10   0.000     .0008915    .0010651
         logincome |  -1.421828   .2835435    -5.01   0.000    -1.977563   -.8660933
        logincome2 |   .1130499   .0131757     8.58   0.000      .087226    .1388739
      female_dummy |  -.2871609   .0203533   -14.11   0.000    -.3270527   -.2472692
    nonwhite_dummy |  -.1129283   .0257314    -4.39   0.000     -.163361   -.0624956
     marital_dummy |    .001401    .023384     0.06   0.952    -.0444307    .0472327
 high_school_dummy |   .7059028   .0816355     8.65   0.000        .5459    .8659055
     college_dummy |   .4205245    .021664    19.41   0.000     .3780638    .4629852
                   |
              year |
             2015  |  -.2323634   .0248367    -9.36   0.000    -.2810426   -.1836843
             2018  |  -.1694494   .0255856    -6.62   0.000    -.2195964   -.1193025
                   |
        state_cate |
                2  |   .1599581   .0918199     1.74   0.081    -.0200057    .3399218
                3  |  -.0077202   .0937768    -0.08   0.934    -.1915194     .176079
                4  |   .0382758   .0949647     0.40   0.687    -.1478517    .2244033
                5  |   .2590211   .0915307     2.83   0.005     .0796242    .4384181
                6  |   .1173584   .0944561     1.24   0.214    -.0677722     .302489
                7  |   .2378936   .0919433     2.59   0.010      .057688    .4180991
                8  |   .1392081   .0921643     1.51   0.131    -.0414306    .3198468
                9  |   .2972259   .0933325     3.18   0.001     .1142977    .4801542
               10  |   .1858535    .095302     1.95   0.051     -.000935     .372642
               11  |   .1506633   .0946531     1.59   0.111    -.0348534      .33618
               12  |   .5806084   .0924239     6.28   0.000     .3994609     .761756
               13  |   .0508621   .0911806     0.56   0.577    -.1278485    .2295728
               14  |   .0700598   .0880422     0.80   0.426    -.1024997    .2426193
               15  |  -.0709938   .0944503    -0.75   0.452    -.2561129    .1141253
               16  |   .1684326   .0911997     1.85   0.065    -.0103156    .3471807
               17  |    .126713   .0927408     1.37   0.172    -.0550556    .3084816
               18  |   .0039784   .0942562     0.04   0.966    -.1807604    .1887171
               19  |   .0896395   .0943758     0.95   0.342    -.0953336    .2746126
               20  |   .1169729   .0932798     1.25   0.210    -.0658522    .2997981
               21  |   .0555965   .0938313     0.59   0.554    -.1283095    .2395026
               22  |   .1025781    .093257     1.10   0.271    -.0802022    .2853584
               23  |   .0192715   .0944323     0.20   0.838    -.1658123    .2043553
               24  |    .160335    .093163     1.72   0.085    -.0222612    .3429312
               25  |   .0405155   .0957182     0.42   0.672    -.1470887    .2281198
               26  |   .0714462   .0935243     0.76   0.445    -.1118579    .2547504
               27  |   .2394419   .0919871     2.60   0.009     .0591505    .4197332
               28  |   .1190539   .0917651     1.30   0.195    -.0608025    .2989102
               29  |   -.011836   .0949146    -0.12   0.901    -.1978651    .1741932
               30  |  -.0282662   .0919861    -0.31   0.759    -.2085557    .1520233
               31  |   .1710607   .0919496     1.86   0.063    -.0091572    .3512786
               32  |   .1072722   .0943278     1.14   0.255     -.077607    .2921513
               33  |   .3146724   .0900443     3.49   0.000     .1381888    .4911561
               34  |  -.0110498   .0935168    -0.12   0.906    -.1943394    .1722398
               35  |   .1586726   .0905007     1.75   0.080    -.0187054    .3360507
               36  |    .149453   .0935869     1.60   0.110     -.033974    .3328799
               37  |   .0161997   .0950784     0.17   0.865    -.1701505      .20255
               38  |   .1204663   .0881481     1.37   0.172    -.0523007    .2932333
               39  |   .1093542    .093623     1.17   0.243    -.0741435    .2928518
               40  |   .0674751   .0916282     0.74   0.461    -.1121129    .2470631
               41  |   .0528511   .0952425     0.55   0.579    -.1338207     .239523
               42  |   .2074749   .0904896     2.29   0.022     .0301187    .3848312
               43  |  -.0685632   .0953087    -0.72   0.472    -.2553649    .1182384
               44  |  -.0388444   .0919662    -0.42   0.673    -.2190948     .141406
               45  |  -.0020864   .0938228    -0.02   0.982    -.1859758     .181803
               46  |   .1635786   .0929612     1.76   0.078    -.0186219    .3457792
               47  |   .1510387   .0942254     1.60   0.109    -.0336396    .3357171
               48  |   .2106365   .0881481     2.39   0.017     .0378694    .3834035
               49  |  -.0583747   .0934838    -0.62   0.532    -.2415996    .1248501
               50  |    .193849   .0923674     2.10   0.036     .0128121    .3748858
               51  |   .1383246   .0919842     1.50   0.133     -.041961    .3186103
                   |
             _cons |   .9939862     1.5358     0.65   0.517    -2.016126    4.004099
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp fin_lit) post

Average marginal effects                        Number of obs     =     80,164
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp fin_lit

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .1198982   .0197478     6.07   0.000     .0811933    .1586032
           fin_lit |   .2318298   .0076708    30.22   0.000     .2167952    .2468644
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/MLP.tex
dir : seeout

.         
. * generate financial literacy indicators and intersactions
. summ fin_lit, d

                           fin_lit
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%     .2148639              0       Obs              80,164
25%     .4286817              0       Sum of Wgt.      80,164

50%     .6489536                      Mean            .603136
                        Largest       Std. Dev.      .2970519
75%     .8434286              1
90%            1              1       Variance       .0882398
95%            1              1       Skewness      -.4414944
99%            1              1       Kurtosis       2.215027

. gen fin_low_dummy = fin_lit == 0

. gen fin_high_dummy = fin_lit == 1

. 
. local household_X "age age2 logincome logincome2 female_dummy nonwhite_dummy marital_dummy high_
> school_dummy college_dummy"

. * heterogeneous effects with SVM
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_svm `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -2789.9313  
Iteration 1:   log pseudolikelihood = -2523.4958  
Iteration 2:   log pseudolikelihood = -2490.6582  
Iteration 3:   log pseudolikelihood = -2490.4484  
Iteration 4:   log pseudolikelihood = -2490.4484  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     393.81
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -2490.4484               Pseudo R2         =     0.1073

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .7739676   .1503303     5.15   0.000     .4793256     1.06861
               age |   .0140874    .017959     0.78   0.433    -.0211117    .0492864
              age2 |  -.0003846   .0002076    -1.85   0.064    -.0007914    .0000222
         logincome |  -1.672999   1.003347    -1.67   0.095    -3.639522    .2935244
        logincome2 |   .0992095   .0483463     2.05   0.040     .0044526    .1939665
      female_dummy |  -.2238818   .0916092    -2.44   0.015    -.4034326    -.044331
    nonwhite_dummy |   .1503955   .0947468     1.59   0.112    -.0353048    .3360957
     marital_dummy |   .5225525     .10175     5.14   0.000     .3231263    .7219788
 high_school_dummy |    .595603   .1933353     3.08   0.002     .2166727    .9745333
     college_dummy |   .4814059   .0989662     4.86   0.000     .2874357    .6753762
                   |
              year |
             2015  |   .1170562   .1171383     1.00   0.318    -.1125307    .3466431
             2018  |   .0724877   .1162815     0.62   0.533    -.1554198    .3003952
                   |
        state_cate |
                2  |    .145863   .3723517     0.39   0.695    -.5839329    .8756589
                3  |  -.5453679   .4013869    -1.36   0.174    -1.332072     .241336
                4  |  -.4420412    .373313    -1.18   0.236    -1.173721    .2896389
                5  |  -.2597584   .3052929    -0.85   0.395    -.8581215    .3386048
                6  |  -.5183322   .3762672    -1.38   0.168    -1.255802    .2191381
                7  |  -.3323804   .3656087    -0.91   0.363     -1.04896    .3841996
                8  |  -.2194603   .3863395    -0.57   0.570    -.9766718    .5377512
                9  |   .1146066   .3535738     0.32   0.746    -.5783854    .8075986
               10  |  -.0234205   .3383831    -0.07   0.945    -.6866393    .6397982
               11  |  -.5310593   .3337102    -1.59   0.112    -1.185119    .1230007
               12  |  -1.110257   .5120594    -2.17   0.030    -2.113875   -.1066394
               13  |  -1.154214   .6614067    -1.75   0.081    -2.450547    .1421192
               14  |  -.5396608    .333875    -1.62   0.106    -1.194044    .1147222
               15  |  -.5184133   .3929789    -1.32   0.187    -1.288638    .2518112
               16  |  -.5553717   .4149019    -1.34   0.181    -1.368564     .257821
               17  |   -.239818   .3932032    -0.61   0.542    -1.010482    .5308461
               18  |   .0214749   .3648424     0.06   0.953     -.693603    .7365528
               19  |  -.6226202   .3667435    -1.70   0.090    -1.341424    .0961839
               20  |   -.418799   .3958877    -1.06   0.290    -1.194725    .3571265
               21  |  -.5306773   .3712084    -1.43   0.153    -1.258232    .1968778
               22  |  -.0569725   .3623179    -0.16   0.875    -.7671025    .6531576
               23  |  -.1333938   .3324517    -0.40   0.688    -.7849872    .5181996
               24  |  -.6638552   .3851719    -1.72   0.085    -1.418778    .0910679
               25  |  -.6914424   .3498023    -1.98   0.048    -1.377042   -.0058425
               26  |  -.8491005   .3929139    -2.16   0.031    -1.619198   -.0790034
               27  |  -.1578985   .4050426    -0.39   0.697    -.9517673    .6359703
               28  |  -.7508538   .4439074    -1.69   0.091    -1.620896    .1191887
               29  |  -.1480375   .3621703    -0.41   0.683    -.8578781    .5618032
               30  |  -.1942793   .4136073    -0.47   0.639    -1.004935    .6163761
               31  |  -.5215421   .3378662    -1.54   0.123    -1.183748    .1406634
               32  |  -.1078117   .3937882    -0.27   0.784    -.8796225    .6639991
               33  |  -.2808776   .3064839    -0.92   0.359     -.881575    .3198197
               34  |  -.9552812   .3945167    -2.42   0.015     -1.72852   -.1820428
               35  |  -.0930161   .3715123    -0.25   0.802    -.8211668    .6351345
               36  |  -.7115414   .3954382    -1.80   0.072    -1.486586    .0635033
               37  |  -.4106119   .3666774    -1.12   0.263    -1.129286    .3080627
               38  |    -.55547   .3511891    -1.58   0.114    -1.243788     .132848
               39  |  -.6128855   .3515297    -1.74   0.081    -1.301871    .0761001
               40  |   -.947349   .4091988    -2.32   0.021    -1.749364   -.1453341
               41  |  -.4968628   .3625426    -1.37   0.171    -1.207433    .2137076
               42  |  -.2271335   .4223421    -0.54   0.591    -1.054909    .6006418
               43  |  -.1959383   .3719228    -0.53   0.598    -.9248935    .5330169
               44  |  -.5442095   .3234729    -1.68   0.092    -1.178205    .0897858
               45  |  -.7581171   .4382344    -1.73   0.084    -1.617041    .1008065
               46  |  -.4738922   .4180492    -1.13   0.257    -1.293254    .3454691
               47  |  -.0243301   .3372116    -0.07   0.942    -.6852527    .6365925
               48  |  -.3740306   .3231456    -1.16   0.247    -1.007384    .2593231
               49  |  -.2882712   .3819265    -0.75   0.450    -1.036833    .4602909
               50  |  -.5934886   .4104516    -1.45   0.148    -1.397959    .2109819
               51  |  -.1518541   .3999344    -0.38   0.704    -.9357111     .632003
                   |
             _cons |   3.846737   5.180303     0.74   0.458     -6.30647    13.99994
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_svm

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .0891389   .0173037     5.15   0.000     .0552242    .1230535
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM_het.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/SVM_het.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_svm `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =   -7639.91  
Iteration 1:   log pseudolikelihood = -6385.0227  
Iteration 2:   log pseudolikelihood = -6374.7023  
Iteration 3:   log pseudolikelihood = -6374.6849  
Iteration 4:   log pseudolikelihood = -6374.6849  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1610.17
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6374.6849               Pseudo R2         =     0.1656

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   23.50829   44.69885     0.53   0.599    -64.09985    111.1164
               age |   .2103864   .0128802    16.33   0.000     .1851417    .2356311
              age2 |  -.0026011   .0001267   -20.53   0.000    -.0028494   -.0023528
         logincome |  -1.656818    .713922    -2.32   0.020     -3.05608   -.2575566
        logincome2 |    .106338   .0326048     3.26   0.001     .0424338    .1702423
      female_dummy |  -.0246872   .0506076    -0.49   0.626    -.1238762    .0745018
    nonwhite_dummy |   .0997517    .070484     1.42   0.157    -.0383945    .2378978
     marital_dummy |  -.0350724   .0608763    -0.58   0.565    -.1543876    .0842429
 high_school_dummy |   .3073167    .394811     0.78   0.436    -.4664986    1.081132
     college_dummy |   .2923834   .0541788     5.40   0.000     .1861948    .3985719
                   |
              year |
             2015  |   .0246029    .058949     0.42   0.676     -.090935    .1401409
             2018  |   .0896111   .0622006     1.44   0.150    -.0322998    .2115221
                   |
        state_cate |
                2  |  -.0323737   .2135637    -0.15   0.880    -.4509508    .3862034
                3  |  -.1582828   .2259027    -0.70   0.484     -.601044    .2844784
                4  |  -.5110383   .2309006    -2.21   0.027    -.9635951   -.0584815
                5  |  -.3919976   .2216957    -1.77   0.077    -.8265131     .042518
                6  |  -.0985468    .221926    -0.44   0.657    -.5335138    .3364202
                7  |  -.0419608   .2167452    -0.19   0.846    -.4667736     .382852
                8  |  -.2908806   .2168102    -1.34   0.180    -.7158207    .1340596
                9  |  -.0939281   .2244949    -0.42   0.676      -.53393    .3460738
               10  |  -.4466735   .2529976    -1.77   0.077    -.9425398    .0491927
               11  |  -.3115312   .2326276    -1.34   0.181    -.7674729    .1444104
               12  |  -.3266794   .2101846    -1.55   0.120    -.7386336    .0852748
               13  |  -.2721757   .2194617    -1.24   0.215    -.7023127    .1579613
               14  |  -.0629177   .2128742    -0.30   0.768    -.4801434     .354308
               15  |   .2609201   .2258667     1.16   0.248    -.1817706    .7036108
               16  |  -.1077481   .2197713    -0.49   0.624    -.5384918    .3229957
               17  |  -.1888318   .2174206    -0.87   0.385    -.6149684    .2373048
               18  |    .050718   .2312318     0.22   0.826     -.402488    .5039239
               19  |  -.0501707   .2652049    -0.19   0.850    -.5699628    .4696214
               20  |   .2196808   .2149662     1.02   0.307    -.2016452    .6410068
               21  |  -.2170184   .2243985    -0.97   0.333    -.6568315    .2227946
               22  |  -.1297485   .2166253    -0.60   0.549    -.5543262    .2948293
               23  |  -.3254214   .2313477    -1.41   0.160    -.7788546    .1280119
               24  |  -.3602146   .2116891    -1.70   0.089    -.7751177    .0546885
               25  |  -.0107223   .2318257    -0.05   0.963    -.4650923    .4436477
               26  |  -.3444153   .2252351    -1.53   0.126    -.7858679    .0970373
               27  |   .1604813   .2100698     0.76   0.445     -.251248    .5722105
               28  |  -.0011779    .216581    -0.01   0.996    -.4256689     .423313
               29  |  -.3122474    .232291    -1.34   0.179    -.7675294    .1430345
               30  |  -.1856214   .2100246    -0.88   0.377    -.5972621    .2260193
               31  |  -.3332388   .2276522    -1.46   0.143     -.779429    .1129513
               32  |  -.5181139   .2267439    -2.29   0.022    -.9625238   -.0737039
               33  |  -.1040539    .222812    -0.47   0.640    -.5407575    .3326497
               34  |  -.0888807   .2241072    -0.40   0.692    -.5281227    .3503613
               35  |   .2386663    .216544     1.10   0.270    -.1857522    .6630849
               36  |  -.1751828   .2330965    -0.75   0.452    -.6320435    .2816779
               37  |  -.2036641   .2192717    -0.93   0.353    -.6334287    .2261006
               38  |  -.1067231   .2104908    -0.51   0.612    -.5192776    .3058313
               39  |  -.1912508   .2306326    -0.83   0.407    -.6432823    .2607807
               40  |   -.386785   .2183833    -1.77   0.077    -.8148084    .0412384
               41  |  -.3308056   .2306397    -1.43   0.151    -.7828511      .12124
               42  |   .0059793   .2105065     0.03   0.977    -.4066058    .4185645
               43  |  -.1543325   .2350879    -0.66   0.512    -.6150964    .3064315
               44  |   -.439959   .2292545    -1.92   0.055    -.8892896    .0093717
               45  |   .1561533   .2149169     0.73   0.467    -.2650761    .5773828
               46  |  -.2351487   .2104302    -1.12   0.264    -.6475844     .177287
               47  |  -.3357507   .2207562    -1.52   0.128    -.7684249    .0969235
               48  |  -.3351389   .2125064    -1.58   0.115    -.7516438    .0813661
               49  |   .1887294   .2306981     0.82   0.413    -.2634307    .6408894
               50  |  -.1897932   .2153226    -0.88   0.378    -.6118177    .2322313
               51  |   .2203659   .2110356     1.04   0.296    -.1932563     .633988
                   |
             _cons |   1.280345   3.937349     0.33   0.745    -6.436718    8.997407
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_svm

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   4.571753    8.69171     0.53   0.599    -12.46369    21.60719
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/SVM_het.tex
dir : seeout

.         
. *** precautionary saving
. ***** low true literacy subgroup
. logit precaution_dummy overconfidence_svm `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -3717.9486  
Iteration 1:   log pseudolikelihood = -3392.2648  
Iteration 2:   log pseudolikelihood = -3378.3449  
Iteration 3:   log pseudolikelihood = -3378.2828  
Iteration 4:   log pseudolikelihood = -3378.2828  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     412.46
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3378.2828               Pseudo R2         =     0.0914

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .8409267   .1158745     7.26   0.000     .6138169    1.068036
               age |  -.0962719   .0138303    -6.96   0.000    -.1233787   -.0691651
              age2 |   .0010887   .0001557     6.99   0.000     .0007836    .0013938
         logincome |  -1.797202   .8337212    -2.16   0.031    -3.431265   -.1631379
        logincome2 |   .1084284   .0405283     2.68   0.007     .0289943    .1878625
      female_dummy |  -.1274553   .0769039    -1.66   0.097    -.2781842    .0232736
    nonwhite_dummy |  -.0363413   .0813041    -0.45   0.655    -.1956945    .1230118
     marital_dummy |   .2107295   .0825989     2.55   0.011     .0488387    .3726204
 high_school_dummy |   .4069285   .1391718     2.92   0.003     .1341568    .6797002
     college_dummy |   .3840695    .086529     4.44   0.000     .2144759    .5536631
                   |
              year |
             2015  |   .0396936   .0960226     0.41   0.679    -.1485072    .2278945
             2018  |    .071096   .0935965     0.76   0.447    -.1123498    .2545418
                   |
        state_cate |
                2  |   .1962623   .3404072     0.58   0.564    -.4709235    .8634481
                3  |  -.2786184   .3193811    -0.87   0.383    -.9045938    .3473571
                4  |  -.4986284   .3040652    -1.64   0.101    -1.094585    .0973285
                5  |     -.2269   .2686454    -0.84   0.398    -.7534353    .2996353
                6  |  -.4390563   .3241758    -1.35   0.176    -1.074429    .1963167
                7  |  -.5894005   .3277518    -1.80   0.072    -1.231782    .0529812
                8  |  -.4209808   .3399477    -1.24   0.216    -1.087266    .2453045
                9  |  -.0555609   .3082654    -0.18   0.857      -.65975    .5486283
               10  |  -.4301655   .2913101    -1.48   0.140    -1.001123    .1407918
               11  |  -.3788219   .2871185    -1.32   0.187    -.9415637    .1839199
               12  |  -.3478092   .3426916    -1.01   0.310    -1.019472    .3238539
               13  |   -.229742    .341548    -0.67   0.501    -.8991638    .4396799
               14  |    -.10587   .2827581    -0.37   0.708    -.6600658    .4483258
               15  |  -.7889915   .3384171    -2.33   0.020    -1.452277   -.1257061
               16  |  -.4756703   .3448013    -1.38   0.168    -1.151468    .2001277
               17  |  -.1308186   .3107224    -0.42   0.674    -.7398232    .4781861
               18  |  -.2767767   .3088771    -0.90   0.370    -.8821646    .3286112
               19  |  -.3193746   .3026095    -1.06   0.291    -.9124784    .2737291
               20  |  -.5810172   .3411237    -1.70   0.089    -1.249607     .087573
               21  |  -.8435813    .313011    -2.70   0.007    -1.457072    -.230091
               22  |  -.5855097   .3232493    -1.81   0.070    -1.219067    .0480472
               23  |   -.372412   .2876185    -1.29   0.195    -.9361339    .1913099
               24  |  -.3012543   .3015697    -1.00   0.318    -.8923201    .2898114
               25  |  -.4042341   .2846747    -1.42   0.156    -.9621863    .1537181
               26  |   -.550323   .3132521    -1.76   0.079    -1.164286    .0636399
               27  |  -1.123535   .4220851    -2.66   0.008    -1.950807   -.2962635
               28  |  -.1169387   .3316834    -0.35   0.724    -.7670261    .5331488
               29  |  -.4841083   .3138347    -1.54   0.123    -1.099213    .1309963
               30  |   .1749273    .327779     0.53   0.594    -.4675079    .8173624
               31  |  -1.046307   .2986844    -3.50   0.000    -1.631718   -.4608965
               32  |  -.1363803   .3399462    -0.40   0.688    -.8026627     .529902
               33  |  -.2352018   .2588243    -0.91   0.363    -.7424881    .2720846
               34  |  -.0712045    .278185    -0.26   0.798    -.6164371    .4740281
               35  |   .3865355    .323988     1.19   0.233    -.2484693     1.02154
               36  |  -.2091297   .2999124    -0.70   0.486    -.7969471    .3786878
               37  |  -.8710222   .3324552    -2.62   0.009    -1.522622    -.219422
               38  |  -.3155941   .3032304    -1.04   0.298    -.9099148    .2787265
               39  |  -.7446706   .2985369    -2.49   0.013    -1.329792   -.1595491
               40  |  -.5890007   .3190141    -1.85   0.065    -1.214257    .0362556
               41  |  -.2839091   .2972806    -0.96   0.340    -.8665683    .2987501
               42  |  -.7520186   .3753021    -2.00   0.045    -1.487597   -.0164401
               43  |  -.2374697   .3033443    -0.78   0.434    -.8320136    .3570742
               44  |  -.1491279   .2708881    -0.55   0.582    -.6800589     .381803
               45  |   -.734127   .3591487    -2.04   0.041    -1.438045   -.0302085
               46  |  -.5597993   .3637421    -1.54   0.124    -1.272721    .1531221
               47  |  -.4055114   .3151183    -1.29   0.198    -1.023132    .2121091
               48  |  -.4762669   .2830967    -1.68   0.093    -1.031126    .0785924
               49  |  -.7722544   .3142178    -2.46   0.014     -1.38811   -.1563988
               50  |  -.7951302   .3395116    -2.34   0.019    -1.460561   -.1296996
               51  |  -.8563438   .3737413    -2.29   0.022    -1.588863   -.1238243
                   |
             _cons |   6.904204   4.268348     1.62   0.106    -1.461603    15.27001
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_svm

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .1420772   .0192702     7.37   0.000     .1043083    .1798461
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/SVM_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit precaution_dummy overconfidence_svm `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -6836.5088  
Iteration 1:   log pseudolikelihood = -5975.4256  
Iteration 2:   log pseudolikelihood = -5952.0346  
Iteration 3:   log pseudolikelihood = -5951.9234  
Iteration 4:   log pseudolikelihood = -5951.9234  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1075.11
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -5951.9234               Pseudo R2         =     0.1294

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |  -47.36356   62.22034    -0.76   0.447    -169.3132    74.58606
               age |  -.1099329    .013493    -8.15   0.000    -.1363787   -.0834871
              age2 |   .0014243   .0001346    10.58   0.000     .0011605     .001688
         logincome |  -.6332955   .7603158    -0.83   0.405    -2.123487    .8568962
        logincome2 |   .0704456   .0350853     2.01   0.045     .0016797    .1392115
      female_dummy |   .0328891   .0531579     0.62   0.536    -.0712984    .1370767
    nonwhite_dummy |  -.2390482   .0726195    -3.29   0.001    -.3813798   -.0967165
     marital_dummy |   -.035109   .0607196    -0.58   0.563    -.1541171    .0838991
 high_school_dummy |   .8633354   .3236124     2.67   0.008     .2290669    1.497604
     college_dummy |    .379635   .0562084     6.75   0.000     .2694685    .4898014
                   |
              year |
             2015  |   .3143199   .0606343     5.18   0.000      .195479    .4331609
             2018  |    .361954   .0648606     5.58   0.000     .2348295    .4890785
                   |
        state_cate |
                2  |   .1214433   .2387213     0.51   0.611    -.3464419    .5893285
                3  |    .166625   .2378879     0.70   0.484    -.2996268    .6328768
                4  |    .237472   .2533834     0.94   0.349    -.2591504    .7340943
                5  |   .0385267   .2399042     0.16   0.872     -.431677    .5087304
                6  |   .3091501   .2387693     1.29   0.195    -.1588291    .7771293
                7  |   .2634272   .2485258     1.06   0.289    -.2236745    .7505289
                8  |   .2758575   .2532586     1.09   0.276    -.2205202    .7722352
                9  |  -.0950966   .2379304    -0.40   0.689    -.5614317    .3712384
               10  |   .2356184   .2703132     0.87   0.383    -.2941856    .7654224
               11  |   .0100026   .2629921     0.04   0.970    -.5054525    .5254578
               12  |   .3310795   .2412438     1.37   0.170    -.1417496    .8039085
               13  |   .0010967   .2366056     0.00   0.996    -.4626417    .4648352
               14  |   .2598896   .2362628     1.10   0.271     -.203177    .7229563
               15  |   .0976108   .2523643     0.39   0.699    -.3970141    .5922357
               16  |    .310301   .2414093     1.29   0.199    -.1628526    .7834547
               17  |   .2104771   .2392606     0.88   0.379    -.2584651    .6794192
               18  |   .1990445   .2571817     0.77   0.439    -.3050225    .7031114
               19  |   .0583721   .2647375     0.22   0.825    -.4605038     .577248
               20  |  -.2657797   .2392011    -1.11   0.267    -.7346052    .2030457
               21  |  -.0704283   .2348921    -0.30   0.764    -.5308083    .3899517
               22  |    .412419    .249782     1.65   0.099    -.0771447    .9019828
               23  |    .154553   .2541225     0.61   0.543     -.343518    .6526241
               24  |   .2243713   .2390718     0.94   0.348    -.2442009    .6929434
               25  |  -.1264413   .2560733    -0.49   0.621    -.6283358    .3754531
               26  |   .1738317   .2475161     0.70   0.482    -.3112909    .6589543
               27  |   .3110476   .2324297     1.34   0.181    -.1445062    .7666014
               28  |    .049323   .2348811     0.21   0.834    -.4110355    .5096816
               29  |    .207248   .2546394     0.81   0.416    -.2918361     .706332
               30  |  -.0604042   .2272516    -0.27   0.790    -.5058091    .3850007
               31  |    .032894    .245941     0.13   0.894    -.4491416    .5149295
               32  |    .186382   .2440249     0.76   0.445    -.2918979     .664662
               33  |   .1961368   .2482099     0.79   0.429    -.2903457    .6826193
               34  |   .0734052   .2499451     0.29   0.769    -.4164782    .5632887
               35  |   .2896336   .2371308     1.22   0.222    -.1751342    .7544013
               36  |  -.0427341   .2502784    -0.17   0.864    -.5332708    .4478025
               37  |  -.0025788   .2471211    -0.01   0.992    -.4869273    .4817696
               38  |  -.0545651   .2350212    -0.23   0.816    -.5151982    .4060679
               39  |   .1142336   .2459479     0.46   0.642    -.3678155    .5962827
               40  |   .1327355   .2406508     0.55   0.581    -.3389314    .6044023
               41  |   .0317085    .257183     0.12   0.902    -.4723609    .5357778
               42  |   .4589432    .236812     1.94   0.053    -.0051999    .9230862
               43  |  -.0351536   .2587137    -0.14   0.892    -.5422231    .4719159
               44  |   .0790404   .2491669     0.32   0.751    -.4093177    .5673985
               45  |  -.0286677   .2373479    -0.12   0.904    -.4938612    .4365257
               46  |   .0075827   .2331661     0.03   0.974    -.4494143    .4645798
               47  |  -.0552901   .2465223    -0.22   0.823     -.538465    .4278847
               48  |   .3136056   .2375776     1.32   0.187    -.1520379    .7792491
               49  |   .3099085   .2652126     1.17   0.243    -.2098987    .8297157
               50  |  -.1080944   .2335882    -0.46   0.644    -.5659189    .3497301
               51  |   .2346683   .2360417     0.99   0.320    -.2279649    .6973015
                   |
             _cons |  -.7034266   4.125589    -0.17   0.865    -8.789432    7.382579
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_svm

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |  -8.442329   11.09044    -0.76   0.447     -30.1792    13.29454
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/SVM_het.tex
dir : seeout

.         
. *** financial market participation
. ***** low true literacy subgroup
. logit fin_par_dummy overconfidence_svm `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =  -2155.857  
Iteration 1:   log pseudolikelihood = -1905.0814  
Iteration 2:   log pseudolikelihood = -1804.7657  
Iteration 3:   log pseudolikelihood = -1801.6322  
Iteration 4:   log pseudolikelihood = -1801.6139  
Iteration 5:   log pseudolikelihood = -1801.6139  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     484.52
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1801.6139               Pseudo R2         =     0.1643

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .6985886   .1943768     3.59   0.000      .317617     1.07956
               age |  -.0813318   .0196093    -4.15   0.000    -.1197654   -.0428983
              age2 |   .0010278   .0002178     4.72   0.000     .0006009    .0014547
         logincome |   .4815857   1.292626     0.37   0.709    -2.051916    3.015087
        logincome2 |   .0185394   .0609902     0.30   0.761    -.1009991     .138078
      female_dummy |  -.3996318   .1083021    -3.69   0.000    -.6119001   -.1873635
    nonwhite_dummy |  -.2432336   .1228418    -1.98   0.048     -.483999   -.0024681
     marital_dummy |   .1376393   .1221896     1.13   0.260    -.1018479    .3771264
 high_school_dummy |    .977413   .2616343     3.74   0.000     .4646193    1.490207
     college_dummy |   .4539965   .1194555     3.80   0.000      .219868     .688125
                   |
              year |
             2015  |  -.1365816   .1342471    -1.02   0.309    -.3997011    .1265379
             2018  |  -.3070853    .134461    -2.28   0.022     -.570624   -.0435465
                   |
        state_cate |
                2  |   .2329018   .4654798     0.50   0.617    -.6794218    1.145225
                3  |  -.2170578   .4808413    -0.45   0.652    -1.159489    .7253739
                4  |  -.3266028   .4950448    -0.66   0.509    -1.296873    .6436671
                5  |   .2387141   .4029435     0.59   0.554    -.5510406    1.028469
                6  |   .1097956   .4751292     0.23   0.817    -.8214405    1.041032
                7  |   -.163166   .4958091    -0.33   0.742    -1.134934    .8086021
                8  |  -.2909707   .5460296    -0.53   0.594    -1.361169    .7792277
                9  |   .5801738   .4299833     1.35   0.177     -.262578    1.422926
               10  |     -.1384   .4667588    -0.30   0.767     -1.05323    .7764304
               11  |     -.1864   .4745254    -0.39   0.694    -1.116453    .7436527
               12  |  -.7491941   .6908011    -1.08   0.278    -2.103139    .6047511
               13  |  -1.028697   .6104911    -1.69   0.092    -2.225237    .1678436
               14  |  -.2272504    .416894    -0.55   0.586    -1.044348    .5898469
               15  |  -1.472881   .6796587    -2.17   0.030    -2.804988   -.1407747
               16  |  -.2743002   .5364458    -0.51   0.609    -1.325715    .7771142
               17  |  -.1689321   .5069988    -0.33   0.739    -1.162631    .8247673
               18  |   .0660344    .463135     0.14   0.887    -.8416936    .9737624
               19  |  -.6641061   .5437067    -1.22   0.222    -1.729752    .4015394
               20  |   .0935581   .5106583     0.18   0.855    -.9073138     1.09443
               21  |   .3282411   .4439903     0.74   0.460    -.5419639    1.198446
               22  |  -.5053212   .5346484    -0.95   0.345    -1.553213    .5425703
               23  |   .2316924    .431807     0.54   0.592    -.6146338    1.078018
               24  |  -.1978958   .4933374    -0.40   0.688    -1.164819    .7690277
               25  |  -.4537652   .4823087    -0.94   0.347    -1.399073    .4915425
               26  |   .2351686   .4508618     0.52   0.602    -.6485042    1.118841
               27  |   .4113289   .5106439     0.81   0.421    -.5895147    1.412173
               28  |   .8657124   .4532664     1.91   0.056    -.0226735    1.754098
               29  |   .0215255   .4828555     0.04   0.964    -.9248539    .9679049
               30  |   -.032263   .4776706    -0.07   0.946    -.9684802    .9039541
               31  |  -.6291405    .460464    -1.37   0.172    -1.531633    .2733524
               32  |  -.0733819   .5527107    -0.13   0.894    -1.156675    1.009911
               33  |   .3446542   .3899155     0.88   0.377    -.4195661    1.108874
               34  |  -.1874565   .4753709    -0.39   0.693    -1.119166    .7442534
               35  |   .4015105    .442252     0.91   0.364    -.4652874    1.268308
               36  |  -.1773783    .482976    -0.37   0.713    -1.123994    .7692374
               37  |   .1386774   .4638672     0.30   0.765    -.7704856     1.04784
               38  |   .3904325   .4615946     0.85   0.398    -.5142763    1.295141
               39  |   .0844025   .4307076     0.20   0.845    -.7597689    .9285739
               40  |   -.485852   .5003094    -0.97   0.331     -1.46644    .4947364
               41  |   .3144611   .4460298     0.71   0.481    -.5597412    1.188663
               42  |  -.1567137     .51839    -0.30   0.762    -1.172739     .859312
               43  |  -.0195754   .5055342    -0.04   0.969    -1.010404    .9712534
               44  |  -.2648033   .4252204    -0.62   0.533     -1.09822    .5686133
               45  |  -.1369765   .5994645    -0.23   0.819    -1.311905    1.037952
               46  |   .3077501   .4883898     0.63   0.529    -.6494763    1.264977
               47  |  -.1784045   .4861835    -0.37   0.714    -1.131307    .7744977
               48  |   .1649456   .4220003     0.39   0.696    -.6621599     .992051
               49  |  -.3227345   .4822359    -0.67   0.503    -1.267899    .6224304
               50  |  -.4799845   .5289394    -0.91   0.364    -1.516687    .5567176
               51  |   .3492267   .5294627     0.66   0.510    -.6885011    1.386954
                   |
             _cons |  -9.116505    6.85163    -1.33   0.183    -22.54545    4.312442
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_svm

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |   .0553843   .0154457     3.59   0.000     .0251113    .0856572
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/SVM_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit fin_par_dummy overconfidence_svm `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -7436.5574  
Iteration 1:   log pseudolikelihood = -6650.7799  
Iteration 2:   log pseudolikelihood = -6646.7758  
Iteration 3:   log pseudolikelihood = -6646.7745  
Iteration 4:   log pseudolikelihood = -6646.7745  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =     981.09
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6646.7745               Pseudo R2         =     0.1062

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |  -4.743731   52.77793    -0.09   0.928    -108.1866    98.69911
               age |  -.0596334   .0128029    -4.66   0.000    -.0847266   -.0345401
              age2 |    .000825   .0001254     6.58   0.000     .0005791    .0010708
         logincome |  -.7447146   .7687559    -0.97   0.333    -2.251448    .7620192
        logincome2 |   .0747248   .0350811     2.13   0.033     .0059672    .1434825
      female_dummy |  -.1146071   .0486414    -2.36   0.018    -.2099426   -.0192717
    nonwhite_dummy |  -.0503135   .0693147    -0.73   0.468    -.1861679    .0855408
     marital_dummy |  -.0293794   .0562881    -0.52   0.602    -.1397021    .0809432
 high_school_dummy |   .8948998    .381459     2.35   0.019     .1472539    1.642546
     college_dummy |   .3827907    .052042     7.36   0.000     .2807902    .4847911
                   |
              year |
             2015  |  -.2303916   .0567654    -4.06   0.000    -.3416498   -.1191334
             2018  |  -.1851528   .0604318    -3.06   0.002     -.303597   -.0667087
                   |
        state_cate |
                2  |   .3849476   .2075155     1.86   0.064    -.0217753    .7916704
                3  |   .4077006   .2088021     1.95   0.051    -.0015439    .8169452
                4  |   .4646308   .2202895     2.11   0.035     .0328712    .8963904
                5  |   .3234067   .2077777     1.56   0.120    -.0838301    .7306435
                6  |   .4494629   .2121742     2.12   0.034     .0336092    .8653167
                7  |   .7301799   .2174233     3.36   0.001      .304038    1.156322
                8  |    .476246    .216351     2.20   0.028     .0522059    .9002862
                9  |   .4286011   .2186996     1.96   0.050    -.0000422    .8572445
               10  |    .552281    .243266     2.27   0.023     .0754885    1.029074
               11  |   .3519642   .2341406     1.50   0.133     -.106943    .8108713
               12  |   .9028789   .2169947     4.16   0.000     .4775771    1.328181
               13  |     .44012   .2106985     2.09   0.037     .0271586    .8530815
               14  |   .4671001   .2052922     2.28   0.023     .0647348    .8694654
               15  |   .2997281   .2196316     1.36   0.172     -.130742    .7301981
               16  |   .5638821   .2086898     2.70   0.007     .1548577    .9729066
               17  |    .562551   .2134192     2.64   0.008      .144257     .980845
               18  |   .2754178   .2241845     1.23   0.219    -.1639757    .7148113
               19  |   .2694211   .2460153     1.10   0.273    -.2127601    .7516023
               20  |   .2374204   .2096333     1.13   0.257    -.1734532    .6482941
               21  |   .2912827   .2164928     1.35   0.178    -.1330354    .7156009
               22  |   .4998384   .2166602     2.31   0.021     .0751923    .9244845
               23  |   .1805189   .2192117     0.82   0.410     -.249128    .6101659
               24  |   .1341415   .2078243     0.65   0.519    -.2731867    .5414698
               25  |   .0643526   .2327752     0.28   0.782    -.3918785    .5205836
               26  |   .3058625    .215095     1.42   0.155     -.115716     .727441
               27  |   .4338829   .2053833     2.11   0.035     .0313391    .8364267
               28  |   .2217725   .2047486     1.08   0.279    -.1795274    .6230723
               29  |   .2903756   .2193513     1.32   0.186     -.139545    .7202962
               30  |   .0523272   .1987677     0.26   0.792    -.3372503    .4419047
               31  |   .8031179   .2205115     3.64   0.000     .3709233    1.235312
               32  |   .1933978   .2166723     0.89   0.372     -.231272    .6180676
               33  |   .3749575    .213321     1.76   0.079     -.043144     .793059
               34  |   .5745094   .2227519     2.58   0.010     .1379237    1.011095
               35  |   .4239645   .2070872     2.05   0.041     .0180811    .8298478
               36  |    .353863   .2242995     1.58   0.115     -.085756     .793482
               37  |   .1328651    .218471     0.61   0.543    -.2953302    .5610604
               38  |   .2894399   .2033809     1.42   0.155    -.1091794    .6880591
               39  |   .5223832   .2199214     2.38   0.018     .0913452    .9534211
               40  |   .3915177   .2081088     1.88   0.060    -.0163682    .7994035
               41  |   .0252221   .2197174     0.11   0.909    -.4054161    .4558603
               42  |   .6065832   .2079798     2.92   0.004     .1989502    1.014216
               43  |   .1892941   .2237495     0.85   0.398    -.2492469    .6278351
               44  |    .030846   .2168575     0.14   0.887    -.3941869    .4558788
               45  |   .1419775   .2075231     0.68   0.494    -.2647604    .5487153
               46  |   .2369896   .2072748     1.14   0.253    -.1692616    .6432407
               47  |   .3926984   .2133074     1.84   0.066    -.0253764    .8107733
               48  |   .5493511   .2088026     2.63   0.009     .1401055    .9585967
               49  |   .2738641   .2273956     1.20   0.228    -.1718231    .7195512
               50  |   .4502098   .2093106     2.15   0.031     .0399685     .860451
               51  |   .2910017   .2056893     1.41   0.157     -.112142    .6941454
                   |
             _cons |  -1.241433   4.274257    -0.29   0.771    -9.618822    7.135957
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_svm) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_svm

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_svm |  -.9727424   10.82264    -0.09   0.928    -22.18472    20.23924
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/SVM_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/SVM_het.tex
dir : seeout

. 
. * heterogeneous effects with random forest
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_forest `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -2789.9313  
Iteration 1:   log pseudolikelihood = -2475.3895  
Iteration 2:   log pseudolikelihood = -2436.6106  
Iteration 3:   log pseudolikelihood = -2436.3326  
Iteration 4:   log pseudolikelihood = -2436.3325  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     447.29
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -2436.3325               Pseudo R2         =     0.1267

---------------------------------------------------------------------------------------
                      |               Robust
         retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   1.995012   .1981491    10.07   0.000     1.606647    2.383377
                  age |   .0201082   .0182775     1.10   0.271     -.015715    .0559314
                 age2 |  -.0004564   .0002118    -2.16   0.031    -.0008714   -.0000413
            logincome |  -1.573368   1.007137    -1.56   0.118    -3.547321    .4005855
           logincome2 |   .0931244   .0485983     1.92   0.055    -.0021266    .1883753
         female_dummy |  -.1501362   .0925789    -1.62   0.105    -.3315875    .0313151
       nonwhite_dummy |   .1650713   .0961631     1.72   0.086     -.023405    .3535475
        marital_dummy |   .4948536   .1029978     4.80   0.000     .2929817    .6967255
    high_school_dummy |   .5310203   .1928055     2.75   0.006     .1531284    .9089123
        college_dummy |   .4354846   .1009152     4.32   0.000     .2376944    .6332748
                      |
                 year |
                2015  |   .0682308   .1182838     0.58   0.564    -.1636013    .3000628
                2018  |   .0781069   .1170461     0.67   0.505    -.1512992    .3075131
                      |
           state_cate |
                   2  |   .2997258   .3725667     0.80   0.421    -.4304916    1.029943
                   3  |  -.4089175   .4009993    -1.02   0.308    -1.194862    .3770267
                   4  |  -.4151119   .3819491    -1.09   0.277    -1.163718    .3334946
                   5  |  -.1430423   .3061863    -0.47   0.640    -.7431564    .4570719
                   6  |  -.3646074   .3807724    -0.96   0.338    -1.110908    .3816927
                   7  |  -.2404619   .3733265    -0.64   0.520    -.9721685    .4912447
                   8  |  -.2330289   .3873787    -0.60   0.547    -.9922772    .5262195
                   9  |    .081578   .3550963     0.23   0.818    -.6143979    .7775539
                  10  |   .0491897   .3344554     0.15   0.883    -.6063308    .7047102
                  11  |  -.4444469   .3396429    -1.31   0.191    -1.110135    .2212409
                  12  |  -1.038583   .5420628    -1.92   0.055    -2.101007    .0238403
                  13  |  -1.112481   .6906156    -1.61   0.107    -2.466063    .2411001
                  14  |  -.3921558    .337746    -1.16   0.246    -1.054126    .2698143
                  15  |  -.5145014    .400888    -1.28   0.199    -1.300228    .2712247
                  16  |  -.4443595   .4143492    -1.07   0.284    -1.256469    .3677499
                  17  |  -.2391268   .4034393    -0.59   0.553    -1.029853    .5515998
                  18  |   .1156745   .3644711     0.32   0.751    -.5986757    .8300246
                  19  |  -.5413063     .37441    -1.45   0.148    -1.275137    .1925239
                  20  |  -.3470419   .4012842    -0.86   0.387    -1.133544    .4394606
                  21  |  -.4391981   .3761086    -1.17   0.243    -1.176358    .2979613
                  22  |   .0772842     .37017     0.21   0.835    -.6482357    .8028041
                  23  |  -.0784406   .3325601    -0.24   0.814    -.7302464    .5733652
                  24  |  -.5381401     .37985    -1.42   0.157    -1.282632    .2063523
                  25  |  -.5528938   .3592742    -1.54   0.124    -1.257058    .1512707
                  26  |  -.7908922    .396642    -1.99   0.046    -1.568296   -.0134881
                  27  |    -.09936   .4229749    -0.23   0.814    -.9283755    .7296555
                  28  |  -.7100172   .4444146    -1.60   0.110    -1.581054    .1610194
                  29  |  -.0728924   .3621866    -0.20   0.840    -.7827652    .6369803
                  30  |  -.1141491   .4303516    -0.27   0.791    -.9576228    .7293246
                  31  |  -.3121018   .3363258    -0.93   0.353    -.9712884    .3470847
                  32  |   -.032269   .3985642    -0.08   0.935    -.8134406    .7489025
                  33  |  -.3625046   .3099053    -1.17   0.242    -.9699078    .2448986
                  34  |  -.9263591   .3921302    -2.36   0.018     -1.69492    -.157798
                  35  |   .0354094   .3771291     0.09   0.925      -.70375    .7745687
                  36  |  -.6225687   .3961255    -1.57   0.116     -1.39896     .153823
                  37  |  -.3516251   .3778147    -0.93   0.352    -1.092128    .3888781
                  38  |  -.5266497   .3599293    -1.46   0.143    -1.232098    .1787988
                  39  |  -.6090867   .3660405    -1.66   0.096    -1.326513    .1083396
                  40  |  -.8008969    .407099    -1.97   0.049    -1.598796   -.0029974
                  41  |    -.35499   .3528296    -1.01   0.314    -1.046523    .3365433
                  42  |  -.1430676   .4339654    -0.33   0.742    -.9936243     .707489
                  43  |  -.1487127   .3690274    -0.40   0.687    -.8719932    .5745677
                  44  |   -.474535    .330949    -1.43   0.152    -1.123183    .1741131
                  45  |  -.6349807   .4604501    -1.38   0.168    -1.537446     .267485
                  46  |  -.3296871   .4171243    -0.79   0.429    -1.147236    .4878615
                  47  |    -.04707   .3427589    -0.14   0.891     -.718865    .6247251
                  48  |   -.256064   .3275233    -0.78   0.434    -.8979978    .3858698
                  49  |  -.0918944   .3804823    -0.24   0.809    -.8376261    .6538372
                  50  |   -.503077   .4255737    -1.18   0.237    -1.337186    .3310321
                  51  |  -.0474477   .3988383    -0.12   0.905    -.8291564    .7342611
                      |
                _cons |   2.798025   5.203018     0.54   0.591    -7.399703    12.99575
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_forest

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .2240655    .021605    10.37   0.000     .1817205    .2664105
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest_het.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/Forest_het.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_forest `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =   -7639.91  
Iteration 1:   log pseudolikelihood = -6348.6023  
Iteration 2:   log pseudolikelihood = -6336.7917  
Iteration 3:   log pseudolikelihood = -6336.7667  
Iteration 4:   log pseudolikelihood = -6336.7667  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1635.44
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6336.7667               Pseudo R2         =     0.1706

---------------------------------------------------------------------------------------
                      |               Robust
         retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |  -9.816392   1.378115    -7.12   0.000    -12.51745   -7.115337
                  age |   .1996205   .0129492    15.42   0.000     .1742405    .2250004
                 age2 |  -.0025303    .000127   -19.93   0.000    -.0027791   -.0022815
            logincome |  -1.864495   .7057494    -2.64   0.008    -3.247738   -.4812512
           logincome2 |    .112555   .0322531     3.49   0.000       .04934    .1757699
         female_dummy |   .0286454   .0511859     0.56   0.576     -.071677    .1289679
       nonwhite_dummy |   .1491855    .071077     2.10   0.036     .0098771     .288494
        marital_dummy |  -.0453676   .0609682    -0.74   0.457     -.164863    .0741278
    high_school_dummy |   .1541677   .4034458     0.38   0.702    -.6365714    .9449069
        college_dummy |   .2258308   .0547579     4.12   0.000     .1185072    .3331544
                      |
                 year |
                2015  |   .0167751   .0591703     0.28   0.777    -.0991967    .1327468
                2018  |     .09143   .0623771     1.47   0.143     -.030827    .2136869
                      |
           state_cate |
                   2  |   .0109401   .2159402     0.05   0.960    -.4122948     .434175
                   3  |  -.1212485   .2300591    -0.53   0.598     -.572156     .329659
                   4  |  -.5169526   .2346054    -2.20   0.028    -.9767707   -.0571344
                   5  |  -.3339494   .2239005    -1.49   0.136    -.7727864    .1048876
                   6  |  -.0820522   .2239419    -0.37   0.714    -.5209703    .3568658
                   7  |  -.0291122   .2198913    -0.13   0.895    -.4600912    .4018667
                   8  |  -.2775808   .2177714    -1.27   0.202     -.704405    .1492434
                   9  |   -.073197   .2264227    -0.32   0.746    -.5169773    .3705832
                  10  |  -.4338553   .2541109    -1.71   0.088    -.9319035    .0641929
                  11  |  -.3063866   .2364466    -1.30   0.195    -.7698134    .1570403
                  12  |  -.2960729   .2137015    -1.39   0.166    -.7149202    .1227744
                  13  |   -.276441   .2232257    -1.24   0.216    -.7139553    .1610733
                  14  |  -.0426934   .2163617    -0.20   0.844    -.4667546    .3813677
                  15  |    .249295   .2297669     1.08   0.278    -.2010398    .6996298
                  16  |  -.0863134   .2216901    -0.39   0.697     -.520818    .3481911
                  17  |  -.1735066   .2198865    -0.79   0.430    -.6044762    .2574631
                  18  |   .0783477   .2337193     0.34   0.737    -.3797337    .5364291
                  19  |  -.0115894   .2687252    -0.04   0.966    -.5382812    .5151023
                  20  |   .2450724   .2176882     1.13   0.260    -.1815885    .6717334
                  21  |  -.1772161   .2276172    -0.78   0.436    -.6233375    .2689054
                  22  |  -.1251882   .2184594    -0.57   0.567    -.5533607    .3029843
                  23  |  -.2878082   .2348197    -1.23   0.220    -.7480465      .17243
                  24  |  -.3506149   .2134732    -1.64   0.101    -.7690147    .0677849
                  25  |   .0104395   .2320849     0.04   0.964    -.4444385    .4653176
                  26  |  -.3350907   .2291866    -1.46   0.144    -.7842881    .1141067
                  27  |   .1915826   .2122999     0.90   0.367    -.2245177    .6076828
                  28  |   .0031915   .2185094     0.01   0.988    -.4250791    .4314622
                  29  |   -.310013   .2357616    -1.31   0.189    -.7720972    .1520713
                  30  |  -.1788392   .2117534    -0.84   0.398    -.5938681    .2361898
                  31  |  -.3280144    .229789    -1.43   0.153    -.7783926    .1223638
                  32  |   -.531613   .2284337    -2.33   0.020    -.9793348   -.0838912
                  33  |  -.0834698   .2253216    -0.37   0.711     -.525092    .3581524
                  34  |  -.0618008   .2275537    -0.27   0.786    -.5077978    .3841963
                  35  |    .255777   .2198443     1.16   0.245    -.1751099     .686664
                  36  |  -.1570926      .2363    -0.66   0.506    -.6202321    .3060469
                  37  |  -.1852682   .2209307    -0.84   0.402    -.6182844    .2477481
                  38  |  -.0522842    .213213    -0.25   0.806     -.470174    .3656056
                  39  |  -.2023348    .232082    -0.87   0.383    -.6572072    .2525375
                  40  |  -.3674258   .2200999    -1.67   0.095    -.7988137    .0639621
                  41  |  -.3203835   .2343486    -1.37   0.172    -.7796983    .1389313
                  42  |   .0161563   .2132973     0.08   0.940    -.4018987    .4342113
                  43  |  -.1422134    .236381    -0.60   0.547    -.6055116    .3210848
                  44  |  -.3678122    .230295    -1.60   0.110    -.8191822    .0835578
                  45  |   .2061948   .2178341     0.95   0.344    -.2207521    .6331418
                  46  |   -.203054   .2121974    -0.96   0.339    -.6189533    .2128453
                  47  |  -.3083515   .2218445    -1.39   0.165    -.7431587    .1264558
                  48  |  -.3072364   .2145502    -1.43   0.152     -.727747    .1132742
                  49  |   .2129233   .2319457     0.92   0.359    -.2416819    .6675285
                  50  |  -.1549555    .217882    -0.71   0.477    -.5819964    .2720854
                  51  |   .2180175   .2117164     1.03   0.303    -.1969391    .6329741
                      |
                _cons |   3.504827   3.891332     0.90   0.368    -4.122045     11.1317
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_forest

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |  -1.894822   .2625123    -7.22   0.000    -2.409337   -1.380308
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/Forest_het.tex
dir : seeout

.         
. *** precautionary saving
. ***** low true literacy subgroup
. logit precaution_dummy overconfidence_forest `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -3717.9486  
Iteration 1:   log pseudolikelihood = -3339.3215  
Iteration 2:   log pseudolikelihood = -3325.4509  
Iteration 3:   log pseudolikelihood = -3325.3851  
Iteration 4:   log pseudolikelihood = -3325.3851  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     480.52
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3325.3851               Pseudo R2         =     0.1056

---------------------------------------------------------------------------------------
                      |               Robust
     precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   1.892674   .1657637    11.42   0.000     1.567783    2.217565
                  age |  -.0939123   .0139961    -6.71   0.000    -.1213442   -.0664804
                 age2 |   .0010629   .0001578     6.74   0.000     .0007536    .0013722
            logincome |  -1.669384   .8353742    -2.00   0.046    -3.306688   -.0320811
           logincome2 |   .1014491   .0406364     2.50   0.013     .0218031    .1810951
         female_dummy |  -.0734893   .0781591    -0.94   0.347    -.2266783    .0796996
       nonwhite_dummy |  -.0242011   .0824018    -0.29   0.769    -.1857056    .1373035
        marital_dummy |   .1881839   .0834309     2.26   0.024     .0246624    .3517054
    high_school_dummy |   .3702556   .1378245     2.69   0.007     .1001245    .6403868
        college_dummy |   .3413216   .0882179     3.87   0.000     .1684176    .5142256
                      |
                 year |
                2015  |   .0022487   .0974355     0.02   0.982    -.1887213    .1932188
                2018  |    .075828   .0943953     0.80   0.422    -.1091834    .2608393
                      |
           state_cate |
                   2  |   .3179701   .3455682     0.92   0.358    -.3593311    .9952712
                   3  |   -.165382   .3327644    -0.50   0.619    -.8175883    .4868243
                   4  |  -.4604767    .304555    -1.51   0.131    -1.057394    .1364401
                   5  |   -.115363    .276069    -0.42   0.676    -.6564482    .4257223
                   6  |  -.2994194   .3283617    -0.91   0.362    -.9429965    .3441576
                   7  |  -.5076189   .3358939    -1.51   0.131    -1.165959    .1507211
                   8  |  -.4485449   .3446492    -1.30   0.193    -1.124045    .2269552
                   9  |  -.1028434   .3138387    -0.33   0.743     -.717956    .5122692
                  10  |  -.3588743   .2982474    -1.20   0.229    -.9434284    .2256798
                  11  |  -.2950877   .2958709    -1.00   0.319    -.8749839    .2848086
                  12  |    -.25866   .3434465    -0.75   0.451    -.9318027    .4144827
                  13  |  -.1840178   .3546413    -0.52   0.604     -.879102    .5110665
                  14  |   .0180275   .2886632     0.06   0.950    -.5477419     .583797
                  15  |  -.7677651   .3459942    -2.22   0.026    -1.445901    -.089629
                  16  |  -.3730739   .3446337    -1.08   0.279    -1.048544    .3023956
                  17  |  -.1127198   .3212274    -0.35   0.726     -.742314    .5168743
                  18  |  -.2057529   .3128447    -0.66   0.511    -.8189173    .4074115
                  19  |  -.2301087   .3039402    -0.76   0.449    -.8258206    .3656033
                  20  |  -.5266506   .3367019    -1.56   0.118    -1.186574    .1332729
                  21  |  -.7762086   .3217167    -2.41   0.016    -1.406762   -.1456553
                  22  |  -.4713641   .3280712    -1.44   0.151    -1.114372    .1716436
                  23  |  -.3236362   .2972816    -1.09   0.276    -.9062974     .259025
                  24  |   -.196108   .3147051    -0.62   0.533    -.8129187    .4207027
                  25  |  -.2613692   .2923009    -0.89   0.371    -.8342684      .31153
                  26  |  -.4956681   .3145681    -1.58   0.115     -1.11221    .1208742
                  27  |  -1.101057   .4430067    -2.49   0.013    -1.969334   -.2327798
                  28  |  -.0557815    .338489    -0.16   0.869    -.7192078    .6076448
                  29  |  -.4162472   .3180095    -1.31   0.191    -1.039534      .20704
                  30  |   .2384561   .3232249     0.74   0.461     -.395053    .8719651
                  31  |  -.8687563   .3008656    -2.89   0.004    -1.458442   -.2790706
                  32  |   -.084855   .3535307    -0.24   0.810    -.7777625    .6080526
                  33  |  -.2847474   .2672019    -1.07   0.287    -.8084535    .2389588
                  34  |  -.0139291   .2829802    -0.05   0.961    -.5685601    .5407019
                  35  |   .5093844   .3277309     1.55   0.120    -.1329565    1.151725
                  36  |  -.1352302   .3093989    -0.44   0.662    -.7416409    .4711804
                  37  |  -.8240401   .3395102    -2.43   0.015    -1.489468   -.1586123
                  38  |  -.2880193   .3158038    -0.91   0.362    -.9069835    .3309448
                  39  |  -.7450696   .3082955    -2.42   0.016    -1.349318   -.1408215
                  40  |  -.4660642   .3207664    -1.45   0.146    -1.094755    .1626264
                  41  |  -.1681139   .3001956    -0.56   0.575    -.7564865    .4202587
                  42  |  -.6770455   .3753488    -1.80   0.071    -1.412716    .0586247
                  43  |  -.2138924     .29895    -0.72   0.474    -.7998237    .3720389
                  44  |  -.0782135   .2759535    -0.28   0.777    -.6190724    .4626454
                  45  |  -.5981305   .3757717    -1.59   0.111    -1.334629    .1383685
                  46  |  -.4456954   .3628147    -1.23   0.219    -1.156799    .2654083
                  47  |  -.4267911   .3170546    -1.35   0.178    -1.048207    .1946245
                  48  |  -.3771083   .2907898    -1.30   0.195    -.9470458    .1928293
                  49  |  -.6155179   .3218641    -1.91   0.056     -1.24636    .0153242
                  50  |  -.7129492   .3458204    -2.06   0.039    -1.390745   -.0351537
                  51  |  -.7913704   .3793628    -2.09   0.037    -1.534908    -.047833
                      |
                _cons |   5.840412   4.276094     1.37   0.172    -2.540578     14.2214
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_forest

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .3130962   .0261947    11.95   0.000     .2617555     .364437
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/Forest_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit precaution_dummy overconfidence_forest `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -6836.5088  
Iteration 1:   log pseudolikelihood = -5924.5432  
Iteration 2:   log pseudolikelihood = -5900.4482  
Iteration 3:   log pseudolikelihood = -5900.3585  
Iteration 4:   log pseudolikelihood = -5900.3585  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1128.52
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -5900.3585               Pseudo R2         =     0.1369

---------------------------------------------------------------------------------------
                      |               Robust
     precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |  -11.27277   1.332048    -8.46   0.000    -13.88354   -8.662004
                  age |  -.1229549   .0137828    -8.92   0.000    -.1499687   -.0959411
                 age2 |   .0015178   .0001367    11.10   0.000     .0012498    .0017857
            logincome |   -.734722    .756477    -0.97   0.331     -2.21739    .7479456
           logincome2 |   .0708114   .0349081     2.03   0.043     .0023927    .1392301
         female_dummy |   .0956493   .0542543     1.76   0.078     -.010687    .2019857
       nonwhite_dummy |  -.1878196   .0736315    -2.55   0.011    -.3321347   -.0435044
        marital_dummy |  -.0516529   .0611873    -0.84   0.399    -.1715777     .068272
    high_school_dummy |   .6991928   .3173372     2.20   0.028     .0772234    1.321162
        college_dummy |   .3012457   .0572254     5.26   0.000      .189086    .4134054
                      |
                 year |
                2015  |   .3093931    .061006     5.07   0.000     .1898235    .4289626
                2018  |   .3671446   .0651659     5.63   0.000     .2394218    .4948673
                      |
           state_cate |
                   2  |   .1777108   .2382894     0.75   0.456    -.2893279    .6447494
                   3  |   .2087492   .2376805     0.88   0.380     -.257096    .6745943
                   4  |   .2386791   .2539926     0.94   0.347    -.2591372    .7364954
                   5  |   .1198906   .2382668     0.50   0.615    -.3471037    .5868849
                   6  |   .3255937   .2372611     1.37   0.170    -.1394295    .7906168
                   7  |   .2783667   .2483563     1.12   0.262    -.2084027    .7651362
                   8  |   .2863799   .2516739     1.14   0.255     -.206892    .7796517
                   9  |  -.0701399   .2363525    -0.30   0.767    -.5333822    .3931024
                  10  |   .2757496   .2730302     1.01   0.313    -.2593797    .8108789
                  11  |   .0156313   .2593319     0.06   0.952    -.4926499    .5239125
                  12  |   .3785924   .2429828     1.56   0.119    -.0976452      .85483
                  13  |  -.0029497   .2348496    -0.01   0.990    -.4632464    .4573469
                  14  |   .2849998   .2347073     1.21   0.225    -.1750181    .7450177
                  15  |   .0828223   .2525895     0.33   0.743    -.4122441    .5778886
                  16  |   .3348699   .2406953     1.39   0.164    -.1368842     .806624
                  17  |   .2266645   .2404406     0.94   0.346    -.2445904    .6979194
                  18  |   .2217488   .2574301     0.86   0.389    -.2828049    .7263026
                  19  |   .1076842   .2619397     0.41   0.681    -.4057082    .6210765
                  20  |  -.2486027   .2389404    -1.04   0.298    -.7169173    .2197118
                  21  |  -.0214302   .2345368    -0.09   0.927     -.481114    .4382536
                  22  |   .4113834   .2485801     1.65   0.098    -.0758245    .8985914
                  23  |   .2131398   .2520048     0.85   0.398    -.2807805    .7070601
                  24  |   .2456368   .2392112     1.03   0.304    -.2232085     .714482
                  25  |  -.1180064   .2566245    -0.46   0.646    -.6209813    .3849684
                  26  |   .1897823   .2471368     0.77   0.443    -.2945969    .6741615
                  27  |   .3387739    .231318     1.46   0.143     -.114601    .7921487
                  28  |   .0443189   .2344098     0.19   0.850    -.4151159    .5037537
                  29  |   .2018251     .25691     0.79   0.432    -.3017092    .7053594
                  30  |  -.0501508   .2255298    -0.22   0.824    -.4921812    .3918795
                  31  |   .0447837   .2423261     0.18   0.853    -.4301668    .5197342
                  32  |   .1704587   .2427904     0.70   0.483    -.3054017     .646319
                  33  |   .2279332   .2506395     0.91   0.363    -.2633112    .7191776
                  34  |   .1098273   .2505073     0.44   0.661    -.3811579    .6008124
                  35  |   .3070672   .2355599     1.30   0.192    -.1546217     .768756
                  36  |  -.0273401   .2504835    -0.11   0.913    -.5182788    .4635986
                  37  |  -.0007925   .2470734    -0.00   0.997    -.4850473    .4834624
                  38  |  -.0009937   .2361026    -0.00   0.997    -.4637462    .4617589
                  39  |   .1043858   .2423093     0.43   0.667    -.3705318    .5793033
                  40  |   .1568896   .2411174     0.65   0.515    -.3156919    .6294711
                  41  |    .046894    .256072     0.18   0.855    -.4549979    .5487858
                  42  |   .4597152   .2361578     1.95   0.052    -.0031455    .9225759
                  43  |   -.017841   .2601889    -0.07   0.945    -.5278019    .4921198
                  44  |   .1389478   .2494863     0.56   0.578    -.3500364     .627932
                  45  |   .0201689   .2381033     0.08   0.932     -.446505    .4868427
                  46  |    .040713   .2317496     0.18   0.861    -.4135079     .494934
                  47  |  -.0208412   .2467807    -0.08   0.933    -.5045226    .4628402
                  48  |   .3455324   .2402212     1.44   0.150    -.1252924    .8163573
                  49  |   .3386216   .2642539     1.28   0.200    -.1793066    .8565498
                  50  |  -.0633619   .2329156    -0.27   0.786    -.5198681    .3931443
                  51  |   .2225435   .2355893     0.94   0.345    -.2392031    .6842901
                      |
                _cons |   1.155775   4.105135     0.28   0.778    -6.890142    9.201692
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_forest

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |  -1.986493   .2310554    -8.60   0.000    -2.439354   -1.533633
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/Forest_het.tex
dir : seeout

.         
. *** financial market participation
. ***** low true literacy subgroup
. logit fin_par_dummy overconfidence_forest `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =  -2155.857  
Iteration 1:   log pseudolikelihood = -1876.7716  
Iteration 2:   log pseudolikelihood = -1767.9429  
Iteration 3:   log pseudolikelihood = -1764.3106  
Iteration 4:   log pseudolikelihood = -1764.2862  
Iteration 5:   log pseudolikelihood = -1764.2862  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     548.65
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1764.2862               Pseudo R2         =     0.1816

---------------------------------------------------------------------------------------
                      |               Robust
        fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   1.880565   .2305222     8.16   0.000      1.42875     2.33238
                  age |   -.074413   .0199277    -3.73   0.000    -.1134706   -.0353554
                 age2 |   .0009551   .0002222     4.30   0.000     .0005197    .0013906
            logincome |   .5636194   1.290018     0.44   0.662     -1.96477    3.092009
           logincome2 |   .0133869   .0609377     0.22   0.826    -.1060488    .1328226
         female_dummy |  -.3364116   .1094828    -3.07   0.002    -.5509939   -.1218292
       nonwhite_dummy |  -.2270784   .1243131    -1.83   0.068    -.4707276    .0165708
        marital_dummy |   .0922947   .1229422     0.75   0.453    -.1486676    .3332569
    high_school_dummy |   .9245211   .2692974     3.43   0.001     .3967079    1.452334
        college_dummy |   .4042863   .1219347     3.32   0.001     .1652988    .6432739
                      |
                 year |
                2015  |  -.1885093   .1367377    -1.38   0.168    -.4565104    .0794917
                2018  |  -.3010881   .1358959    -2.22   0.027    -.5674392    -.034737
                      |
           state_cate |
                   2  |    .343484   .4615679     0.74   0.457    -.5611725    1.248141
                   3  |  -.1007374   .4757178    -0.21   0.832    -1.033127    .8316524
                   4  |  -.3309875   .4954799    -0.67   0.504     -1.30211    .6401353
                   5  |   .3371809   .4027802     0.84   0.403    -.4522538    1.126616
                   6  |   .2455511   .4838727     0.51   0.612    -.7028219    1.193924
                   7  |  -.0759886   .4782231    -0.16   0.874    -1.013289    .8613115
                   8  |    -.29316   .5468784    -0.54   0.592    -1.365022    .7787019
                   9  |   .5335606   .4193565     1.27   0.203     -.288363    1.355484
                  10  |  -.0626342   .4659898    -0.13   0.893    -.9759575    .8506891
                  11  |  -.1225966   .4726624    -0.26   0.795    -1.048998    .8038047
                  12  |   -.681132   .7050737    -0.97   0.334    -2.063051    .7007871
                  13  |  -1.083757   .6199909    -1.75   0.080    -2.298916    .1314032
                  14  |  -.0844319   .4163867    -0.20   0.839    -.9005349    .7316711
                  15  |  -1.496947   .6872649    -2.18   0.029    -2.843962   -.1499329
                  16  |  -.1445555   .5301181    -0.27   0.785    -1.183568    .8944569
                  17  |  -.1789583   .5090551    -0.35   0.725    -1.176688    .8187714
                  18  |   .1250341   .4621191     0.27   0.787    -.7807027    1.030771
                  19  |  -.5817604   .5459279    -1.07   0.287    -1.651759    .4882387
                  20  |   .1851262   .5153499     0.36   0.719    -.8249411    1.195193
                  21  |   .4185025   .4389083     0.95   0.340    -.4417419    1.278747
                  22  |  -.4124891   .5296548    -0.78   0.436    -1.450593    .6256152
                  23  |   .2884798   .4375106     0.66   0.510    -.5690252    1.145985
                  24  |  -.0734154   .4777905    -0.15   0.878    -1.009868    .8630368
                  25  |  -.3267492   .4866458    -0.67   0.502    -1.280558     .627059
                  26  |   .2884174   .4478736     0.64   0.520    -.5893989    1.166234
                  27  |   .4649792   .5159028     0.90   0.367    -.5461718     1.47613
                  28  |   .9482354   .4629575     2.05   0.041     .0408555    1.855615
                  29  |   .0640754   .4943048     0.13   0.897    -.9047442    1.032895
                  30  |   .0542781   .4715633     0.12   0.908     -.869969    .9785251
                  31  |  -.4078727   .4525226    -0.90   0.367    -1.294801    .4790554
                  32  |  -.0826245   .5736351    -0.14   0.885    -1.206929    1.041679
                  33  |    .259807   .3882035     0.67   0.503    -.5010578    1.020672
                  34  |  -.1479475   .4695702    -0.32   0.753    -1.068288    .7723932
                  35  |    .478367   .4482248     1.07   0.286    -.4001375    1.356871
                  36  |  -.0938226   .4650901    -0.20   0.840    -1.005382    .8177372
                  37  |   .1774145   .4640938     0.38   0.702    -.7321927    1.087022
                  38  |   .4250024   .4717038     0.90   0.368      -.49952    1.349525
                  39  |   .0853464   .4360342     0.20   0.845    -.7692649    .9399576
                  40  |  -.3917825   .4974247    -0.79   0.431    -1.366717    .5831519
                  41  |   .4381103   .4371188     1.00   0.316    -.4186267    1.294847
                  42  |  -.0316607   .5085933    -0.06   0.950    -1.028485     .965164
                  43  |   .0160474    .507399     0.03   0.975    -.9784364    1.010531
                  44  |  -.2055981   .4202893    -0.49   0.625     -1.02935    .6181538
                  45  |   .0018221    .609465     0.00   0.998    -1.192707    1.196352
                  46  |    .447942   .4759467     0.94   0.347    -.4848965     1.38078
                  47  |  -.2090456   .4795406    -0.44   0.663    -1.148928    .7308368
                  48  |   .2977755   .4198359     0.71   0.478    -.5250878    1.120639
                  49  |  -.1461171   .4830537    -0.30   0.762    -1.092885    .8006507
                  50  |  -.4050063   .5330772    -0.76   0.447    -1.449818    .6398058
                  51  |   .4279807   .5434598     0.79   0.431    -.6371809    1.493142
                      |
                _cons |  -10.10369   6.850407    -1.47   0.140    -23.53024    3.322863
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_forest

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |   .1457323   .0177159     8.23   0.000     .1110097    .1804549
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/Forest_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit fin_par_dummy overconfidence_forest `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -7436.5574  
Iteration 1:   log pseudolikelihood =  -6606.722  
Iteration 2:   log pseudolikelihood = -6602.7616  
Iteration 3:   log pseudolikelihood = -6602.7603  
Iteration 4:   log pseudolikelihood = -6602.7603  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =     991.51
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6602.7603               Pseudo R2         =     0.1121

---------------------------------------------------------------------------------------
                      |               Robust
        fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |  -10.03932   1.291792    -7.77   0.000    -12.57118   -7.507451
                  age |   -.070616   .0130702    -5.40   0.000    -.0962332   -.0449988
                 age2 |   .0009015   .0001275     7.07   0.000     .0006515    .0011514
            logincome |  -.9272341   .7611802    -1.22   0.223     -2.41912    .5646516
           logincome2 |   .0794376   .0347446     2.29   0.022     .0113395    .1475358
         female_dummy |  -.0618195    .049587    -1.25   0.213    -.1590082    .0353693
       nonwhite_dummy |  -.0030042   .0704298    -0.04   0.966    -.1410441    .1350356
        marital_dummy |  -.0406854   .0566167    -0.72   0.472    -.1516521    .0702813
    high_school_dummy |   .7526419   .3740454     2.01   0.044     .0195264    1.485757
        college_dummy |   .3145611   .0529619     5.94   0.000     .2107577    .4183645
                      |
                 year |
                2015  |  -.2392135   .0571523    -4.19   0.000      -.35123    -.127197
                2018  |  -.1856814   .0606312    -3.06   0.002    -.3045164   -.0668464
                      |
           state_cate |
                   2  |   .4265384   .2079649     2.05   0.040     .0189347     .834142
                   3  |   .4415199   .2072078     2.13   0.033     .0354001    .8476396
                   4  |   .4629216   .2194124     2.11   0.035     .0328812    .8929619
                   5  |    .391085   .2064697     1.89   0.058    -.0135882    .7957583
                   6  |   .4585967   .2100026     2.18   0.029     .0469991    .8701942
                   7  |   .7393312   .2162875     3.42   0.001     .3154154    1.163247
                   8  |   .4837352   .2139878     2.26   0.024     .0643269    .9031435
                   9  |   .4493343    .216071     2.08   0.038      .025843    .8728257
                  10  |   .5816181   .2454988     2.37   0.018     .1004493    1.062787
                  11  |   .3546489     .23332     1.52   0.129    -.1026498    .8119476
                  12  |   .9409889   .2199638     4.28   0.000     .5098678     1.37211
                  13  |   .4339189   .2103843     2.06   0.039     .0215732    .8462645
                  14  |   .4845021   .2052684     2.36   0.018     .0821834    .8868208
                  15  |   .2819616   .2199029     1.28   0.200    -.1490401    .7129634
                  16  |   .5759714   .2076875     2.77   0.006     .1689113    .9830315
                  17  |   .5736739   .2141272     2.68   0.007     .1539923    .9933555
                  18  |   .2911456   .2225703     1.31   0.191    -.1450841    .7273753
                  19  |   .3047229   .2450891     1.24   0.214    -.1756428    .7850887
                  20  |   .2488819   .2089832     1.19   0.234    -.1607175    .6584814
                  21  |   .3262415   .2174586     1.50   0.134    -.0999696    .7524525
                  22  |   .4963776   .2154999     2.30   0.021     .0740056    .9187496
                  23  |   .2191826   .2183246     1.00   0.315    -.2087258    .6470909
                  24  |   .1441353   .2071502     0.70   0.487    -.2618717    .5501423
                  25  |   .0658824   .2311081     0.29   0.776    -.3870812     .518846
                  26  |   .3148666   .2144554     1.47   0.142    -.1054582    .7351915
                  27  |   .4510394   .2049878     2.20   0.028     .0492707    .8528082
                  28  |   .2128415   .2044397     1.04   0.298    -.1878529     .613536
                  29  |   .2804437   .2193259     1.28   0.201    -.1494271    .7103146
                  30  |   .0551644   .1982219     0.28   0.781    -.3333433    .4436721
                  31  |   .8136944   .2190657     3.71   0.000     .3843335    1.243055
                  32  |   .1763702   .2146283     0.82   0.411    -.2442934    .5970339
                  33  |   .3933432   .2143612     1.83   0.067     -.026797    .8134834
                  34  |   .6004024   .2246633     2.67   0.008     .1600705    1.040734
                  35  |   .4385052   .2063261     2.13   0.034     .0341135    .8428969
                  36  |   .3664138   .2230771     1.64   0.100    -.0708093    .8036369
                  37  |   .1273092   .2181572     0.58   0.560     -.300271    .5548895
                  38  |   .3289474   .2045847     1.61   0.108    -.0720312    .7299259
                  39  |   .5146215   .2167183     2.37   0.018     .0898614    .9393816
                  40  |   .4089934   .2082145     1.96   0.049     .0009004    .8170864
                  41  |   .0317988   .2200552     0.14   0.885    -.3995015    .4630991
                  42  |    .605748   .2071984     2.92   0.003     .1996466    1.011849
                  43  |   .1978648   .2252706     0.88   0.380    -.2436575     .639387
                  44  |   .0834331   .2161448     0.39   0.699     -.340203    .5070692
                  45  |   .1721668   .2080438     0.83   0.408    -.2355916    .5799251
                  46  |   .2599077   .2061606     1.26   0.207    -.1441595     .663975
                  47  |   .4146284   .2120865     1.95   0.051    -.0010535    .8303102
                  48  |   .5731425   .2085093     2.75   0.006     .1644719    .9818132
                  49  |   .2945631   .2253678     1.31   0.191    -.1471496    .7362758
                  50  |   .4894627   .2086006     2.35   0.019      .080613    .8983124
                  51  |    .279991    .204321     1.37   0.171    -.1204707    .6804528
                      |
                _cons |   .8832905   4.229112     0.21   0.835    -7.405618    9.172199
---------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_forest) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_forest

---------------------------------------------------------------------------------------
                      |            Delta-method
                      |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
----------------------+----------------------------------------------------------------
overconfidence_forest |  -2.040672   .2583983    -7.90   0.000    -2.547123   -1.534221
---------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Forest_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/Forest_het.tex
dir : seeout

. 
. * heterogeneous effects with logistic
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_logit `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -2789.9313  
Iteration 1:   log pseudolikelihood = -2490.3841  
Iteration 2:   log pseudolikelihood = -2452.1474  
Iteration 3:   log pseudolikelihood = -2451.8604  
Iteration 4:   log pseudolikelihood = -2451.8603  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     421.09
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -2451.8603               Pseudo R2         =     0.1212

--------------------------------------------------------------------------------------
                     |               Robust
        retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   1.328602   .1482538     8.96   0.000     1.038029    1.619174
                 age |   .0551943   .0193391     2.85   0.004     .0172904    .0930982
                age2 |  -.0006861   .0002199    -3.12   0.002    -.0011172   -.0002551
           logincome |  -2.246126   1.021281    -2.20   0.028    -4.247799   -.2444533
          logincome2 |   .1330577   .0494004     2.69   0.007     .0362347    .2298808
        female_dummy |  -.1883468   .0920618    -2.05   0.041    -.3687847   -.0079089
      nonwhite_dummy |   .1669255   .0961196     1.74   0.082    -.0214655    .3553165
       marital_dummy |   .5025883   .1030153     4.88   0.000      .300682    .7044947
   high_school_dummy |   .5709891   .1940823     2.94   0.003     .1905949    .9513834
       college_dummy |   .4781606   .1004398     4.76   0.000     .2813021    .6750191
                     |
                year |
               2015  |   .0728449   .1182405     0.62   0.538    -.1589023    .3045921
               2018  |   .0626927   .1172459     0.53   0.593     -.167105    .2924904
                     |
          state_cate |
                  2  |   .1777672   .3728123     0.48   0.633    -.5529314    .9084658
                  3  |  -.4548463   .3984414    -1.14   0.254    -1.235777    .3260845
                  4  |  -.4396549   .3807606    -1.15   0.248    -1.185932    .3066222
                  5  |  -.2070045   .3082597    -0.67   0.502    -.8111824    .3971733
                  6  |  -.4189843   .3767273    -1.11   0.266    -1.157356    .3193876
                  7  |  -.2867248   .3700326    -0.77   0.438    -1.011975    .4385257
                  8  |  -.2386758   .3873353    -0.62   0.538    -.9978391    .5204876
                  9  |   .0717451    .359352     0.20   0.842    -.6325719    .7760622
                 10  |  -.0000909   .3379077    -0.00   1.000    -.6623778     .662196
                 11  |  -.4835566    .344529    -1.40   0.160    -1.158821    .1917079
                 12  |  -1.120281   .5466897    -2.05   0.040    -2.191774   -.0487893
                 13  |  -1.240278   .6952822    -1.78   0.074    -2.603006    .1224499
                 14  |  -.4436981   .3379047    -1.31   0.189    -1.105979    .2185829
                 15  |  -.5545013   .4008749    -1.38   0.167    -1.340202     .231199
                 16  |   -.518928   .4176726    -1.24   0.214    -1.337551    .2996952
                 17  |  -.2938835   .4077232    -0.72   0.471    -1.093006    .5052392
                 18  |   .0627576   .3648418     0.17   0.863    -.6523191    .7778343
                 19  |  -.5971266   .3752134    -1.59   0.112    -1.332531    .1382781
                 20  |  -.3931348   .4018203    -0.98   0.328    -1.180688    .3944186
                 21  |  -.4828291   .3719031    -1.30   0.194    -1.211746    .2460876
                 22  |   .0042708   .3664787     0.01   0.991    -.7140143    .7225559
                 23  |  -.1223646   .3333267    -0.37   0.714     -.775673    .5309438
                 24  |  -.6035472   .3800452    -1.59   0.112    -1.348422    .1413277
                 25  |  -.6569219   .3599134    -1.83   0.068    -1.362339    .0484953
                 26  |  -.7970302   .3970126    -2.01   0.045    -1.575161   -.0188997
                 27  |  -.1980177   .4330006    -0.46   0.647    -1.046683    .6506479
                 28  |  -.7568605   .4448071    -1.70   0.089    -1.628666    .1149454
                 29  |  -.1371949   .3649337    -0.38   0.707    -.8524519    .5780621
                 30  |  -.1832521   .4265919    -0.43   0.668    -1.019357    .6528526
                 31  |     -.3734   .3385154    -1.10   0.270    -1.036878     .290078
                 32  |  -.1302609   .4017252    -0.32   0.746    -.9176279    .6571061
                 33  |  -.3384235   .3164717    -1.07   0.285    -.9586967    .2818497
                 34  |    -.94507   .3938209    -2.40   0.016    -1.716945   -.1731951
                 35  |  -.0845037   .3771921    -0.22   0.823    -.8237866    .6547792
                 36  |  -.6593822   .3995208    -1.65   0.099    -1.442429    .1236643
                 37  |  -.3867187   .3767161    -1.03   0.305    -1.125069    .3516313
                 38  |  -.5668524   .3633341    -1.56   0.119    -1.278974    .1452694
                 39  |  -.6076032   .3665094    -1.66   0.097    -1.325949    .1107421
                 40  |  -.8789504     .40327    -2.18   0.029    -1.669345   -.0885557
                 41  |  -.4321184   .3558137    -1.21   0.225      -1.1295    .2652637
                 42  |  -.1424486   .4291253    -0.33   0.740    -.9835187    .6986215
                 43  |  -.1535328   .3734875    -0.41   0.681    -.8855549    .5784893
                 44  |  -.5105701   .3306561    -1.54   0.123    -1.158644    .1375039
                 45  |  -.6988391   .4487814    -1.56   0.119    -1.578434    .1807563
                 46  |   -.451232   .4219549    -1.07   0.285    -1.278248    .3757845
                 47  |  -.0297699    .345402    -0.09   0.931    -.7067453    .6472055
                 48  |  -.3071396   .3291711    -0.93   0.351    -.9523031    .3380239
                 49  |  -.1861356   .3848487    -0.48   0.629    -.9404252     .568154
                 50  |  -.5879246   .4248657    -1.38   0.166    -1.420646    .2447968
                 51  |  -.1291636   .4017347    -0.32   0.748    -.9165492    .6582219
                     |
               _cons |   4.957186   5.239217     0.95   0.344    -5.311492    15.22586
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_logit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |     .15026   .0164521     9.13   0.000     .1180145    .1825055
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit_het.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/Logit_het.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_logit `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =   -7639.91  
Iteration 1:   log pseudolikelihood = -6382.2866  
Iteration 2:   log pseudolikelihood = -6372.2604  
Iteration 3:   log pseudolikelihood = -6372.2433  
Iteration 4:   log pseudolikelihood = -6372.2433  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1616.86
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6372.2433               Pseudo R2         =     0.1659

--------------------------------------------------------------------------------------
                     |               Robust
        retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |  -.5964871   .3380396    -1.76   0.078    -1.259033    .0660584
                 age |   .1984382   .0143869    13.79   0.000     .1702404    .2266359
                age2 |  -.0025023   .0001373   -18.23   0.000    -.0027714   -.0022333
           logincome |  -1.795316    .718311    -2.50   0.012     -3.20318   -.3874525
          logincome2 |   .1115473    .032731     3.41   0.001     .0473957    .1756988
        female_dummy |  -.0209651   .0505882    -0.41   0.679    -.1201162     .078186
      nonwhite_dummy |    .103585   .0705985     1.47   0.142    -.0347856    .2419555
       marital_dummy |  -.0334499   .0609211    -0.55   0.583    -.1528531    .0859532
   high_school_dummy |   .3001139   .3927838     0.76   0.445    -.4697282    1.069956
       college_dummy |   .2867698   .0541588     5.29   0.000     .1806205    .3929191
                     |
                year |
               2015  |    .022607    .059004     0.38   0.702    -.0930387    .1382527
               2018  |   .0892571    .062245     1.43   0.152    -.0327409    .2112551
                     |
          state_cate |
                  2  |   -.027123   .2138324    -0.13   0.899    -.4462267    .3919807
                  3  |  -.1550762   .2262578    -0.69   0.493    -.5985333    .2883808
                  4  |  -.5152261   .2315588    -2.23   0.026    -.9690731   -.0613791
                  5  |  -.3936556   .2219134    -1.77   0.076    -.8285978    .0412866
                  6  |  -.0996896   .2223705    -0.45   0.654    -.5355279    .3361486
                  7  |  -.0388683   .2173325    -0.18   0.858    -.4648321    .3870955
                  8  |  -.2934543   .2167653    -1.35   0.176    -.7183065    .1313978
                  9  |  -.0997822   .2244403    -0.44   0.657    -.5396771    .3401126
                 10  |  -.4513809    .253132    -1.78   0.075    -.9475104    .0447486
                 11  |  -.3149725   .2329711    -1.35   0.176    -.7715875    .1416425
                 12  |  -.3192713   .2106226    -1.52   0.130     -.732084    .0935415
                 13  |  -.2729253    .220009    -1.24   0.215     -.704135    .1582844
                 14  |  -.0639555   .2129936    -0.30   0.764    -.4814152    .3535043
                 15  |    .247659   .2260395     1.10   0.273    -.1953703    .6906883
                 16  |   -.102169   .2199008    -0.46   0.642    -.5331666    .3288286
                 17  |  -.1909712   .2173214    -0.88   0.380    -.6169133     .234971
                 18  |    .057155   .2313112     0.25   0.805    -.3962067    .5105167
                 19  |  -.0493917    .266639    -0.19   0.853    -.5719945     .473211
                 20  |   .2291263   .2153519     1.06   0.287    -.1929558    .6512083
                 21  |  -.2091286   .2252581    -0.93   0.353    -.6506264    .2323693
                 22  |  -.1294785   .2166572    -0.60   0.550    -.5541188    .2951619
                 23  |  -.3246116   .2318053    -1.40   0.161    -.7789417    .1297184
                 24  |  -.3612708   .2116838    -1.71   0.088    -.7761634    .0536218
                 25  |  -.0072372   .2313777    -0.03   0.975    -.4607291    .4462548
                 26  |  -.3468386   .2257791    -1.54   0.124    -.7893575    .0956804
                 27  |   .1598425   .2102486     0.76   0.447    -.2522372    .5719223
                 28  |   .0028254     .21682     0.01   0.990     -.422134    .4277848
                 29  |  -.3136459   .2324369    -1.35   0.177    -.7692139     .141922
                 30  |  -.1872809   .2099022    -0.89   0.372    -.5986817    .2241199
                 31  |  -.3350871   .2279066    -1.47   0.141    -.7817758    .1116015
                 32  |  -.5217741   .2267989    -2.30   0.021    -.9662918   -.0772563
                 33  |  -.0985974   .2234694    -0.44   0.659    -.5365893    .3393945
                 34  |  -.0901719   .2244107    -0.40   0.688    -.5300088    .3496651
                 35  |   .2405149    .216586     1.11   0.267    -.1839858    .6650157
                 36  |  -.1748225   .2328573    -0.75   0.453    -.6312145    .2815695
                 37  |   -.197708   .2193405    -0.90   0.367    -.6276074    .2321915
                 38  |   -.098356   .2104041    -0.47   0.640    -.5107403    .3140284
                 39  |  -.2028226   .2305968    -0.88   0.379    -.6547841     .249139
                 40  |  -.3807686   .2183038    -1.74   0.081    -.8086362     .047099
                 41  |  -.3294361   .2307486    -1.43   0.153     -.781695    .1228228
                 42  |    .009323     .21075     0.04   0.965    -.4037394    .4223854
                 43  |  -.1571003   .2345348    -0.67   0.503      -.61678    .3025794
                 44  |  -.4309156   .2286753    -1.88   0.060    -.8791109    .0172797
                 45  |    .169149   .2155727     0.78   0.433    -.2533657    .5916638
                 46  |  -.2322203   .2106533    -1.10   0.270    -.6450931    .1806525
                 47  |  -.3309008   .2208768    -1.50   0.134    -.7638114    .1020099
                 48  |  -.3320998   .2126255    -1.56   0.118    -.7488381    .0846384
                 49  |   .1893415   .2302264     0.82   0.411    -.2618941     .640577
                 50  |  -.1945335   .2151979    -0.90   0.366    -.6163136    .2272465
                 51  |   .2207091    .210599     1.05   0.295    -.1920573    .6334756
                     |
               _cons |   2.547109   4.017675     0.63   0.526    -5.327388    10.42161
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_logit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |  -.1159212   .0656066    -1.77   0.077    -.2445079    .0126654
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/Logit_het.tex
dir : seeout

.         
. *** precautionary saving
. ***** low true literacy subgroup
. logit precaution_dummy overconfidence_logit `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -3717.9486  
Iteration 1:   log pseudolikelihood = -3354.1863  
Iteration 2:   log pseudolikelihood = -3341.8282  
Iteration 3:   log pseudolikelihood = -3341.7754  
Iteration 4:   log pseudolikelihood = -3341.7754  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     454.09
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3341.7754               Pseudo R2         =     0.1012

--------------------------------------------------------------------------------------
                     |               Robust
    precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   1.281021   .1235835    10.37   0.000     1.038802     1.52324
                 age |  -.0606457   .0144366    -4.20   0.000    -.0889409   -.0323504
                age2 |   .0008678   .0001601     5.42   0.000     .0005541    .0011815
           logincome |  -2.389704   .8468509    -2.82   0.005    -4.049502   -.7299072
          logincome2 |   .1432019   .0412785     3.47   0.001     .0622975    .2241063
        female_dummy |  -.1050395   .0776982    -1.35   0.176    -.2573252    .0472462
      nonwhite_dummy |   -.022547   .0821685    -0.27   0.784    -.1835944    .1385004
       marital_dummy |   .1926725   .0837884     2.30   0.021     .0284502    .3568947
   high_school_dummy |   .4012831    .138967     2.89   0.004     .1289128    .6736534
       college_dummy |   .3852764   .0877905     4.39   0.000     .2132102    .5573426
                     |
                year |
               2015  |   .0096342   .0975609     0.10   0.921    -.1815816      .20085
               2018  |    .064571   .0945044     0.68   0.494    -.1206541    .2497962
                     |
          state_cate |
                  2  |   .2262217   .3453243     0.66   0.512    -.4506015    .9030449
                  3  |   -.207429   .3228834    -0.64   0.521    -.8402689    .4254109
                  4  |  -.4823993   .3035844    -1.59   0.112    -1.077414    .1126152
                  5  |    -.18132   .2723143    -0.67   0.506    -.7150463    .3524063
                  6  |  -.3456453    .324502    -1.07   0.287    -.9816574    .2903669
                  7  |  -.5565744   .3342128    -1.67   0.096    -1.211619    .0984706
                  8  |  -.4591255   .3399536    -1.35   0.177    -1.125422    .2071712
                  9  |  -.1024891   .3123811    -0.33   0.743    -.7147448    .5097666
                 10  |  -.4017396   .2924744    -1.37   0.170    -.9749789    .1714997
                 11  |  -.3377283   .2923267    -1.16   0.248    -.9106782    .2352215
                 12  |  -.3250019   .3460777    -0.94   0.348    -1.003302     .353298
                 13  |  -.2670359   .3537294    -0.75   0.450    -.9603328     .426261
                 14  |  -.0291909   .2862283    -0.10   0.919     -.590188    .5318062
                 15  |  -.8037953   .3437727    -2.34   0.019    -1.477577   -.1300133
                 16  |  -.4524974   .3443927    -1.31   0.189    -1.127495    .2224999
                 17  |  -.1509963   .3189393    -0.47   0.636    -.7761057    .4741132
                 18  |     -.2442   .3117399    -0.78   0.433     -.855199     .366799
                 19  |  -.2833207   .3063538    -0.92   0.355    -.8837632    .3171218
                 20  |  -.5738212   .3384399    -1.70   0.090    -1.237151    .0895088
                 21  |  -.8101766   .3166241    -2.56   0.011    -1.430749   -.1896047
                 22  |  -.5436074   .3254292    -1.67   0.095    -1.181437    .0942222
                 23  |  -.3595465   .2958381    -1.22   0.224    -.9393785    .2202855
                 24  |  -.2648027    .312391    -0.85   0.397    -.8770779    .3474724
                 25  |  -.3579915   .2938858    -1.22   0.223    -.9339971    .2180141
                 26  |  -.5093004   .3147931    -1.62   0.106    -1.126284    .1076827
                 27  |  -1.196438   .4624508    -2.59   0.010    -2.102825   -.2900509
                 28  |  -.1088281   .3374731    -0.32   0.747    -.7702632     .552607
                 29  |  -.4669578   .3201709    -1.46   0.145    -1.094481    .1605657
                 30  |   .1842638   .3224735     0.57   0.568    -.4477725    .8163002
                 31  |  -.9204402   .3001277    -3.07   0.002     -1.50868   -.3322007
                 32  |  -.1798747   .3577312    -0.50   0.615     -.881015    .5212656
                 33  |  -.2663254   .2670641    -1.00   0.319    -.7897614    .2571106
                 34  |  -.0388395   .2827797    -0.14   0.891    -.5930775    .5153985
                 35  |   .3986674    .324614     1.23   0.219    -.2375643    1.034899
                 36  |  -.1654696   .3053689    -0.54   0.588    -.7639817    .4330425
                 37  |  -.8511879   .3386249    -2.51   0.012     -1.51488   -.1874953
                 38  |  -.3197873   .3161907    -1.01   0.312    -.9395096     .299935
                 39  |  -.7392834   .3067441    -2.41   0.016    -1.340491   -.1380759
                 40  |  -.5479003   .3161442    -1.73   0.083    -1.167532    .0717309
                 41  |  -.2477753   .2958998    -0.84   0.402    -.8277283    .3321777
                 42  |  -.6832088   .3725485    -1.83   0.067     -1.41339    .0469728
                 43  |  -.2275426   .3020897    -0.75   0.451    -.8196275    .3645423
                 44  |  -.1194875   .2728692    -0.44   0.661    -.6543012    .4153262
                 45  |  -.6721674   .3696326    -1.82   0.069    -1.396634    .0522993
                 46  |  -.5486762   .3639853    -1.51   0.132    -1.262074    .1647217
                 47  |  -.4057445    .314268    -1.29   0.197    -1.021698    .2102096
                 48  |  -.4170156   .2889662    -1.44   0.149    -.9833789    .1493478
                 49  |  -.6940699   .3221016    -2.15   0.031    -1.325377   -.0627624
                 50  |  -.7923752   .3443863    -2.30   0.021     -1.46736   -.1173903
                 51  |   -.847403   .3796321    -2.23   0.026    -1.591468   -.1033378
                     |
               _cons |   8.272495   4.307146     1.92   0.055    -.1693568    16.71435
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_logit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   .2129741   .0198276    10.74   0.000     .1741128    .2518354
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/Logit_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit precaution_dummy overconfidence_logit `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -6836.5088  
Iteration 1:   log pseudolikelihood = -5973.9286  
Iteration 2:   log pseudolikelihood = -5950.9262  
Iteration 3:   log pseudolikelihood = -5950.7945  
Iteration 4:   log pseudolikelihood = -5950.7945  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1078.08
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -5950.7945               Pseudo R2         =     0.1296

--------------------------------------------------------------------------------------
                     |               Robust
    precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |  -.4851914   .3258313    -1.49   0.136    -1.123809    .1534263
                 age |  -.1190488   .0150323    -7.92   0.000    -.1485116   -.0895861
                age2 |   .0014966   .0001448    10.33   0.000     .0012128    .0017805
           logincome |   -.670957    .761662    -0.88   0.378    -2.163787     .821873
          logincome2 |   .0711514   .0351308     2.03   0.043     .0022964    .1400064
        female_dummy |   .0333236   .0531875     0.63   0.531    -.0709219    .1375691
      nonwhite_dummy |  -.2382348   .0726754    -3.28   0.001    -.3806759   -.0957936
       marital_dummy |  -.0346641   .0607556    -0.57   0.568    -.1537429    .0844147
   high_school_dummy |     .85863   .3222426     2.66   0.008     .2270461    1.490214
       college_dummy |   .3768678   .0562284     6.70   0.000     .2666622    .4870735
                     |
                year |
               2015  |   .3129376   .0606736     5.16   0.000     .1940194    .4318557
               2018  |   .3605815   .0647934     5.57   0.000     .2335887    .4875742
                     |
          state_cate |
                  2  |   .1247438    .238798     0.52   0.601    -.3432917    .5927794
                  3  |   .1651503    .237927     0.69   0.488     -.301178    .6314787
                  4  |   .2324316   .2537229     0.92   0.360    -.2648562    .7297194
                  5  |   .0371515   .2400731     0.15   0.877     -.433383     .507686
                  6  |   .3074314   .2386396     1.29   0.198    -.1602937    .7751565
                  7  |   .2657794   .2487918     1.07   0.285    -.2218435    .7534024
                  8  |    .272275   .2529225     1.08   0.282     -.223444     .767994
                  9  |  -.1015519   .2377368    -0.43   0.669    -.5675074    .3644036
                 10  |   .2329828   .2699942     0.86   0.388    -.2961961    .7621617
                 11  |   .0073837   .2625431     0.03   0.978    -.5071913    .5219587
                 12  |   .3374315   .2416696     1.40   0.163    -.1362323    .8110953
                 13  |  -.0004679   .2366393    -0.00   0.998    -.4642724    .4633366
                 14  |   .2577913    .236043     1.09   0.275    -.2048444     .720427
                 15  |   .0857436   .2521573     0.34   0.734    -.4084756    .5799629
                 16  |   .3144479    .241936     1.30   0.194    -.1597381    .7886338
                 17  |   .2063632   .2395991     0.86   0.389    -.2632424    .6759689
                 18  |   .2020358   .2582502     0.78   0.434    -.3041253    .7081968
                 19  |   .0576612   .2644657     0.22   0.827    -.4606821    .5760046
                 20  |  -.2602117   .2396169    -1.09   0.278    -.7298521    .2094287
                 21  |  -.0644917   .2352033    -0.27   0.784    -.5254816    .3964983
                 22  |    .412255   .2502218     1.65   0.099    -.0781707    .9026806
                 23  |   .1531758   .2543909     0.60   0.547    -.3454211    .6517727
                 24  |    .223734   .2396033     0.93   0.350    -.2458799    .6933479
                 25  |  -.1260654   .2564734    -0.49   0.623     -.628744    .3766132
                 26  |   .1694735   .2479688     0.68   0.494    -.3165364    .6554834
                 27  |   .3085557   .2323696     1.33   0.184    -.1468804    .7639918
                 28  |    .050811   .2349838     0.22   0.829    -.4097489    .5113708
                 29  |   .2049661   .2553919     0.80   0.422    -.2955928     .705525
                 30  |  -.0618843   .2271379    -0.27   0.785    -.5070664    .3832977
                 31  |    .033139   .2453494     0.14   0.893     -.447737     .514015
                 32  |   .1827055   .2438058     0.75   0.454    -.2951451     .660556
                 33  |   .2006716   .2487465     0.81   0.420    -.2868626    .6882058
                 34  |   .0710265   .2496671     0.28   0.776    -.4183121    .5603651
                 35  |   .2892048   .2371337     1.22   0.223    -.1755687    .7539783
                 36  |  -.0439259   .2506321    -0.18   0.861    -.5351558    .4473039
                 37  |   .0010568   .2470508     0.00   0.997    -.4831538    .4852675
                 38  |  -.0501689   .2350526    -0.21   0.831    -.5108635    .4105258
                 39  |   .1034363   .2451201     0.42   0.673    -.3769904    .5838629
                 40  |   .1363896   .2410798     0.57   0.572    -.3361181    .6088973
                 41  |   .0324018    .257358     0.13   0.900    -.4720106    .5368142
                 42  |   .4613107   .2372555     1.94   0.052    -.0037015    .9263229
                 43  |  -.0382175   .2587664    -0.15   0.883    -.5453902    .4689553
                 44  |   .0628171   .2478506     0.25   0.800    -.4229612    .5485954
                 45  |  -.0207572   .2380167    -0.09   0.931    -.4872613    .4457469
                 46  |   .0084021   .2335883     0.04   0.971    -.4494226    .4662268
                 47  |  -.0510089    .246627    -0.21   0.836     -.534389    .4323712
                 48  |   .3143235   .2378462     1.32   0.186    -.1518464    .7804934
                 49  |   .3094402   .2653937     1.17   0.244    -.2107218    .8296022
                 50  |  -.1136961   .2339885    -0.49   0.627     -.572305    .3449129
                 51  |   .2334884   .2359128     0.99   0.322    -.2288922     .695869
                     |
               _cons |  -.0829342   4.152836    -0.02   0.984    -8.222342    8.056474
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_logit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |  -.0864328   .0579773    -1.49   0.136    -.2000662    .0272006
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/Logit_het.tex
dir : seeout

.         
. *** financial market participation
. ***** low true literacy subgroup
. logit fin_par_dummy overconfidence_logit `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =  -2155.857  
Iteration 1:   log pseudolikelihood = -1888.2241  
Iteration 2:   log pseudolikelihood = -1775.8457  
Iteration 3:   log pseudolikelihood = -1771.9217  
Iteration 4:   log pseudolikelihood = -1771.9114  
Iteration 5:   log pseudolikelihood = -1771.9114  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     529.46
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1771.9114               Pseudo R2         =     0.1781

--------------------------------------------------------------------------------------
                     |               Robust
       fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   1.198717   .1533408     7.82   0.000     .8981745     1.49926
                 age |  -.0465706   .0206082    -2.26   0.024    -.0869619   -.0061793
                age2 |   .0007834   .0002281     3.44   0.001     .0003364    .0012304
           logincome |   .0425919   1.305888     0.03   0.974    -2.516902    2.602086
          logincome2 |   .0445807   .0617795     0.72   0.471     -.076505    .1656664
        female_dummy |  -.3709436   .1096312    -3.38   0.001    -.5858167   -.1560705
      nonwhite_dummy |  -.2236753   .1248204    -1.79   0.073    -.4683189    .0209682
       marital_dummy |   .1069299   .1241343     0.86   0.389    -.1363688    .3502287
   high_school_dummy |   .9726099   .2751872     3.53   0.000      .433253    1.511967
       college_dummy |   .4514215   .1215685     3.71   0.000     .2131517    .6896914
                     |
                year |
               2015  |  -.1833232   .1371158    -1.34   0.181    -.4520652    .0854188
               2018  |  -.3097967   .1363652    -2.27   0.023    -.5770677   -.0425258
                     |
          state_cate |
                  2  |   .2497005   .4680239     0.53   0.594    -.6676095    1.167011
                  3  |  -.1122804   .4808238    -0.23   0.815    -1.054678     .830117
                  4  |  -.3322289   .5013967    -0.66   0.508    -1.314948    .6504905
                  5  |   .2785119   .4078793     0.68   0.495    -.5209169    1.077941
                  6  |   .2029094   .4820822     0.42   0.674    -.7419545    1.147773
                  7  |  -.1056583   .4858534    -0.22   0.828    -1.057913    .8465968
                  8  |  -.2857805   .5457561    -0.52   0.601    -1.355443    .7838819
                  9  |   .5374938   .4307107     1.25   0.212    -.3066837    1.381671
                 10  |  -.1050417   .4705182    -0.22   0.823     -1.02724     .817157
                 11  |   -.145977   .4744454    -0.31   0.758    -1.075873    .7839189
                 12  |  -.7437513   .7124306    -1.04   0.297     -2.14009     .652587
                 13  |  -1.226436   .6329359    -1.94   0.053    -2.466968    .0140955
                 14  |  -.1321452   .4234524    -0.31   0.755    -.9620965    .6978062
                 15  |  -1.509773   .6870871    -2.20   0.028    -2.856439   -.1631071
                 16  |  -.2375241   .5397711    -0.44   0.660    -1.295456    .8204078
                 17  |   -.230684   .5162827    -0.45   0.655     -1.24258    .7812115
                 18  |   .0793823   .4672502     0.17   0.865    -.8364113    .9951759
                 19  |  -.6332651   .5483984    -1.15   0.248    -1.708106    .4415761
                 20  |   .1511576   .5086732     0.30   0.766    -.8458236    1.148139
                 21  |   .3943063   .4427643     0.89   0.373    -.4734958    1.262108
                 22  |  -.4506227   .5326508    -0.85   0.398    -1.494599    .5933536
                 23  |   .2521249   .4423093     0.57   0.569    -.6147854    1.119035
                 24  |  -.1239569   .4835503    -0.26   0.798    -1.071698    .8237843
                 25  |  -.4304901   .4957187    -0.87   0.385    -1.402081    .5411006
                 26  |    .288797   .4557751     0.63   0.526    -.6045057      1.1821
                 27  |   .3982477    .526814     0.76   0.450    -.6342888    1.430784
                 28  |   .9014324   .4651722     1.94   0.053    -.0102884    1.813153
                 29  |   .0080286   .5003594     0.02   0.987    -.9726578     .988715
                 30  |   .0175038   .4739089     0.04   0.971    -.9113407    .9463482
                 31  |  -.4635824   .4588482    -1.01   0.312    -1.362908    .4357436
                 32  |  -.1773623   .5817956    -0.30   0.760    -1.317661    .9629362
                 33  |   .2932202   .3970501     0.74   0.460    -.4849838    1.071424
                 34  |  -.1595132   .4715506    -0.34   0.735    -1.083735    .7647091
                 35  |   .3908996   .4520488     0.86   0.387    -.4950997    1.276899
                 36  |  -.1050671   .4761303    -0.22   0.825    -1.038265    .8281311
                 37  |   .1597995   .4729185     0.34   0.735    -.7671036    1.086703
                 38  |    .399639   .4799311     0.83   0.405    -.5410087    1.340287
                 39  |   .1027727   .4422681     0.23   0.816    -.7640569    .9696023
                 40  |  -.4531551   .4985154    -0.91   0.363    -1.430227    .5239172
                 41  |   .3821709   .4396743     0.87   0.385    -.4795748    1.243917
                 42  |  -.0153579   .5111336    -0.03   0.976    -1.017161    .9864455
                 43  |   .0262443   .5134777     0.05   0.959    -.9801535    1.032642
                 44  |  -.2216345   .4247236    -0.52   0.602    -1.054078    .6108085
                 45  |  -.0489541   .6021131    -0.08   0.935    -1.229074    1.131166
                 46  |   .3479566   .4824438     0.72   0.471    -.5976159    1.293529
                 47  |  -.1767558   .4923095    -0.36   0.720    -1.141665    .7881531
                 48  |   .2599167   .4259687     0.61   0.542    -.5749667      1.0948
                 49  |  -.2163228   .4911168    -0.44   0.660    -1.178894    .7462484
                 50  |  -.4772893   .5428439    -0.88   0.379    -1.541244    .5866651
                 51  |   .3870842   .5392654     0.72   0.473    -.6698566    1.444025
                     |
               _cons |  -8.402699   6.920661    -1.21   0.225    -21.96694    5.161546
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_logit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   .0929301   .0117728     7.89   0.000     .0698558    .1160044
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/Logit_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit fin_par_dummy overconfidence_logit `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -7436.5574  
Iteration 1:   log pseudolikelihood = -6649.5522  
Iteration 2:   log pseudolikelihood = -6645.6997  
Iteration 3:   log pseudolikelihood = -6645.6986  
Iteration 4:   log pseudolikelihood = -6645.6986  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =     978.57
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6645.6986               Pseudo R2         =     0.1063

--------------------------------------------------------------------------------------
                     |               Robust
       fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |  -.3884601   .3521446    -1.10   0.270    -1.078651    .3017306
                 age |  -.0668434   .0140991    -4.74   0.000     -.094477   -.0392097
                age2 |   .0008827   .0001339     6.59   0.000     .0006202    .0011452
           logincome |  -.7899518    .771535    -1.02   0.306    -2.302133     .722229
          logincome2 |   .0760849   .0351681     2.16   0.031     .0071566    .1450131
        female_dummy |  -.1133104   .0486784    -2.33   0.020    -.2087182   -.0179025
      nonwhite_dummy |  -.0487313   .0694042    -0.70   0.483     -.184761    .0872984
       marital_dummy |  -.0288697    .056332    -0.51   0.608    -.1392783     .081539
   high_school_dummy |   .8902557   .3803579     2.34   0.019     .1447678    1.635744
       college_dummy |   .3798729   .0520252     7.30   0.000     .2779054    .4818404
                     |
                year |
               2015  |   -.231778      .0568    -4.08   0.000    -.3431039    -.120452
               2018  |  -.1859418   .0604072    -3.08   0.002    -.3043376   -.0675459
                     |
          state_cate |
                  2  |   .3861606   .2073647     1.86   0.063    -.0202668    .7925879
                  3  |   .4065784   .2084656     1.95   0.051    -.0020067    .8151634
                  4  |   .4601113   .2202844     2.09   0.037     .0283618    .8918608
                  5  |   .3210319    .207589     1.55   0.122    -.0858351     .727899
                  6  |   .4468612   .2118689     2.11   0.035     .0316059    .8621166
                  7  |   .7304765   .2171645     3.36   0.001      .304842    1.156111
                  8  |   .4733513   .2159434     2.19   0.028       .05011    .8965926
                  9  |   .4229097   .2180439     1.94   0.052    -.0044486    .8502679
                 10  |   .5488384   .2428994     2.26   0.024     .0727643    1.024912
                 11  |   .3488044   .2341884     1.49   0.136    -.1101963    .8078051
                 12  |   .9065939   .2171851     4.17   0.000     .4809189    1.332269
                 13  |   .4380289    .210535     2.08   0.037     .0253879    .8506698
                 14  |   .4646588    .205101     2.27   0.023     .0626683    .8666494
                 15  |   .2902718   .2194914     1.32   0.186    -.1399234     .720467
                 16  |   .5658394   .2086367     2.71   0.007     .1569188    .9747599
                 17  |   .5588661   .2131468     2.62   0.009     .1411061    .9766262
                 18  |   .2765084   .2240108     1.23   0.217    -.1625447    .7155616
                 19  |   .2677181     .24619     1.09   0.277    -.2148054    .7502417
                 20  |   .2403728   .2097214     1.15   0.252    -.1706736    .6514191
                 21  |   .2941088   .2165457     1.36   0.174    -.1303129    .7185306
                 22  |   .4982834    .216382     2.30   0.021     .0741825    .9223843
                 23  |   .1790009    .219266     0.82   0.414    -.2507526    .6087544
                 24  |   .1317402   .2078315     0.63   0.526    -.2756021    .5390825
                 25  |   .0631998   .2328054     0.27   0.786    -.3930904      .51949
                 26  |   .3019736   .2150019     1.40   0.160    -.1194223    .7233695
                 27  |   .4317558    .205193     2.10   0.035      .029585    .8339267
                 28  |   .2217524   .2046706     1.08   0.279    -.1793946    .6228994
                 29  |   .2875944   .2194866     1.31   0.190    -.1425914    .7177802
                 30  |   .0504798   .1986228     0.25   0.799    -.3388137    .4397733
                 31  |   .8019553   .2202062     3.64   0.000     .3703591    1.233552
                 32  |   .1901276   .2161904     0.88   0.379    -.2335978    .6138529
                 33  |   .3765333   .2134349     1.76   0.078    -.0417914     .794858
                 34  |   .5720098   .2227881     2.57   0.010     .1353533    1.008666
                 35  |   .4231668   .2068035     2.05   0.041     .0178394    .8284942
                 36  |   .3526575   .2241791     1.57   0.116    -.0867254    .7920404
                 37  |    .133548   .2182511     0.61   0.541    -.2942163    .5613123
                 38  |   .2920521   .2034094     1.44   0.151    -.1066229    .6907271
                 39  |   .5139018   .2191446     2.35   0.019     .0843863    .9434174
                 40  |     .39336   .2080391     1.89   0.059    -.0143891     .801109
                 41  |   .0245393   .2198916     0.11   0.911    -.4064404    .4555189
                 42  |   .6065148   .2079821     2.92   0.004     .1988773    1.014152
                 43  |   .1868055   .2234436     0.84   0.403     -.251136     .624747
                 44  |   .0283199   .2159902     0.13   0.896    -.3950131    .4516529
                 45  |   .1455389   .2078602     0.70   0.484    -.2618596    .5529374
                 46  |   .2373263   .2071383     1.15   0.252    -.1686572    .6433098
                 47  |   .3945987   .2130491     1.85   0.064    -.0229698    .8121673
                 48  |   .5497192   .2085801     2.64   0.008     .1409098    .9585286
                 49  |   .2729066   .2271057     1.20   0.229    -.1722124    .7180256
                 50  |   .4450496   .2093717     2.13   0.034     .0346886    .8554105
                 51  |   .2900238   .2053859     1.41   0.158    -.1125251    .6925727
                     |
               _cons |  -.6756069   4.322165    -0.16   0.876    -9.146895    7.795681
--------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_logit) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_logit

--------------------------------------------------------------------------------------
                     |            Delta-method
                     |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
---------------------+----------------------------------------------------------------
overconfidence_logit |   -.079636   .0721576    -1.10   0.270    -.2210623    .0617904
--------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/Logit_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation") 
../outputs/tables/Logit_het.tex
dir : seeout

.         
. * heterogeneous effects with Bernoulli NB
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_bnb `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -2789.9313  
Iteration 1:   log pseudolikelihood = -2498.6395  
Iteration 2:   log pseudolikelihood = -2459.4245  
Iteration 3:   log pseudolikelihood = -2459.0311  
Iteration 4:   log pseudolikelihood = -2459.0307  
Iteration 5:   log pseudolikelihood = -2459.0307  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     439.69
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -2459.0307               Pseudo R2         =     0.1186

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   1.198446   .1377043     8.70   0.000     .9285507    1.468342
               age |   .0198325   .0181724     1.09   0.275    -.0157848    .0554499
              age2 |   -.000448   .0002112    -2.12   0.034     -.000862   -.0000341
         logincome |   -1.23592     1.0084    -1.23   0.220    -3.212349     .740508
        logincome2 |   .0781187   .0486676     1.61   0.108     -.017268    .1735053
      female_dummy |  -.3130714     .09287    -3.37   0.001    -.4950932   -.1310496
    nonwhite_dummy |  -.0062377   .0984694    -0.06   0.949    -.1992342    .1867587
     marital_dummy |   .6406854   .1033887     6.20   0.000     .4380472    .8433235
 high_school_dummy |   .8341516   .1932785     4.32   0.000     .4553327     1.21297
     college_dummy |   .6630901   .1015652     6.53   0.000      .464026    .8621542
                   |
              year |
             2015  |   .0755598   .1185279     0.64   0.524    -.1567505    .3078702
             2018  |   .0643844   .1168354     0.55   0.582    -.1646088    .2933777
                   |
        state_cate |
                2  |   .3527894   .3791073     0.93   0.352    -.3902473    1.095826
                3  |  -.4119853   .4024546    -1.02   0.306    -1.200782    .3768112
                4  |  -.4678605   .3839869    -1.22   0.223    -1.220461    .2847399
                5  |  -.2748099   .3087269    -0.89   0.373    -.8799035    .3302836
                6  |  -.3076383   .3890491    -0.79   0.429     -1.07016    .4548839
                7  |  -.1726397   .3769137    -0.46   0.647    -.9113769    .5660975
                8  |  -.1690707   .3888716    -0.43   0.664     -.931245    .5931035
                9  |   .0491088   .3594322     0.14   0.891    -.6553654    .7535831
               10  |  -.0877722   .3345242    -0.26   0.793    -.7434276    .5678832
               11  |   -.518599   .3403853    -1.52   0.128    -1.185742    .1485439
               12  |  -.9334686   .5443053    -1.71   0.086    -2.000287    .1333502
               13  |  -1.082204    .694365    -1.56   0.119    -2.443135    .2787263
               14  |  -.3883698   .3409073    -1.14   0.255    -1.056536    .2797962
               15  |  -.5393208   .4045079    -1.33   0.182    -1.332142    .2535001
               16  |  -.3788655   .4214747    -0.90   0.369    -1.204941    .4472098
               17  |  -.2389891   .4082808    -0.59   0.558    -1.039205    .5612265
               18  |    .098701   .3652038     0.27   0.787    -.6170853    .8144873
               19  |  -.6427597   .3753031    -1.71   0.087     -1.37834    .0928209
               20  |  -.3197132   .4048981    -0.79   0.430    -1.113299    .4738726
               21  |  -.4257737   .3737279    -1.14   0.255    -1.158267    .3067195
               22  |    .066987   .3728106     0.18   0.857    -.6637084    .7976824
               23  |  -.1673707   .3326085    -0.50   0.615    -.8192714      .48453
               24  |  -.5103936   .3832788    -1.33   0.183    -1.261606     .240819
               25  |   -.634865   .3573264    -1.78   0.076    -1.335212     .065482
               26  |  -.8372849   .3966474    -2.11   0.035      -1.6147   -.0598701
               27  |  -.0957273    .434802    -0.22   0.826    -.9479236    .7564689
               28  |  -.6648802   .4472916    -1.49   0.137    -1.541556    .2117953
               29  |  -.1105295   .3625415    -0.30   0.760    -.8210979    .6000388
               30  |   -.016734   .4396226    -0.04   0.970    -.8783784    .8449104
               31  |  -.2460434   .3415832    -0.72   0.471    -.9155341    .4234473
               32  |   .0086712   .4008572     0.02   0.983    -.7769943    .7943368
               33  |  -.4580131   .3120455    -1.47   0.142    -1.069611    .1535849
               34  |  -.9711169   .3931764    -2.47   0.014    -1.741728   -.2005054
               35  |   .0456214    .385071     0.12   0.906    -.7091039    .8003467
               36  |  -.6208985   .3963766    -1.57   0.117    -1.397782    .1559852
               37  |  -.4188113   .3814115    -1.10   0.272    -1.166364    .3287415
               38  |  -.5852907   .3665919    -1.60   0.110    -1.303798    .1332162
               39  |  -.6434651   .3687336    -1.75   0.081     -1.36617    .0792395
               40  |  -.7252153   .4087271    -1.77   0.076    -1.526306    .0758752
               41  |  -.3480067   .3551688    -0.98   0.327    -1.044125    .3481112
               42  |    -.08397   .4403374    -0.19   0.849    -.9470154    .7790754
               43  |  -.1641024   .3700269    -0.44   0.657    -.8893419     .561137
               44  |  -.6174761   .3329475    -1.85   0.064    -1.270041     .035089
               45  |   -.620809   .4623105    -1.34   0.179    -1.526921     .285303
               46  |  -.2851465   .4226947    -0.67   0.500    -1.113613    .5433199
               47  |  -.0651626   .3431441    -0.19   0.849    -.7377126    .6073874
               48  |  -.3094846    .334858    -0.92   0.355    -.9657942     .346825
               49  |  -.1184206   .3816032    -0.31   0.756    -.8663491    .6295079
               50  |  -.5344711   .4296821    -1.24   0.214    -1.376632    .3076903
               51  |   .0100646   .4074904     0.02   0.980    -.7886019    .8087311
                   |
             _cons |   1.336462   5.208583     0.26   0.797    -8.872172     11.5451
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .1354903   .0152429     8.89   0.000     .1056147    .1653659
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB_het.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/BNB_het.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_bnb `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =   -7639.91  
Iteration 1:   log pseudolikelihood = -6361.6215  
Iteration 2:   log pseudolikelihood = -6350.2548  
Iteration 3:   log pseudolikelihood = -6350.2317  
Iteration 4:   log pseudolikelihood = -6350.2317  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1619.08
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6350.2317               Pseudo R2         =     0.1688

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |  -1.531155    .297177    -5.15   0.000    -2.113611   -.9486986
               age |   .2086881   .0130151    16.03   0.000     .1831789    .2341972
              age2 |  -.0025958   .0001278   -20.31   0.000    -.0028463   -.0023453
         logincome |   -1.76198   .7108694    -2.48   0.013    -3.155259   -.3687018
        logincome2 |   .1101458   .0324816     3.39   0.001      .046483    .1738086
      female_dummy |   .0540741   .0516003     1.05   0.295    -.0470607    .1552089
    nonwhite_dummy |   .2149963   .0738315     2.91   0.004     .0702892    .3597035
     marital_dummy |  -.0932893   .0614783    -1.52   0.129    -.2137845     .027206
 high_school_dummy |   .0070623   .4137891     0.02   0.986    -.8039495     .818074
     college_dummy |   .1701136   .0570215     2.98   0.003     .0583536    .2818737
                   |
              year |
             2015  |   .0213879   .0590091     0.36   0.717    -.0942677    .1370435
             2018  |   .0966231   .0622819     1.55   0.121    -.0254473    .2186934
                   |
        state_cate |
                2  |  -.1008363   .2162172    -0.47   0.641    -.5246142    .3229416
                3  |  -.2043364   .2298316    -0.89   0.374     -.654798    .2461252
                4  |  -.5532101    .234239    -2.36   0.018     -1.01231     -.09411
                5  |  -.3542503   .2248207    -1.58   0.115    -.7948906    .0863901
                6  |  -.1596813   .2243087    -0.71   0.477    -.5993182    .2799557
                7  |  -.0835137   .2205358    -0.38   0.705    -.5157559    .3487285
                8  |  -.3367498   .2186479    -1.54   0.124    -.7652918    .0917922
                9  |  -.1228674   .2264879    -0.54   0.587    -.5667755    .3210406
               10  |  -.4547168   .2552237    -1.78   0.075    -.9549462    .0455125
               11  |  -.3238705   .2371043    -1.37   0.172    -.7885864    .1408454
               12  |  -.4341078   .2136609    -2.03   0.042    -.8528754   -.0153402
               13  |  -.3395458   .2228364    -1.52   0.128    -.7762972    .0972056
               14  |  -.0930006   .2162003    -0.43   0.667    -.5167453    .3307441
               15  |   .2163129   .2293262     0.94   0.346    -.2331583    .6657841
               16  |  -.1763117   .2221481    -0.79   0.427    -.6117139    .2590905
               17  |  -.2288554   .2199333    -1.04   0.298    -.6599167     .202206
               18  |   .0261903    .233205     0.11   0.911     -.430883    .4832636
               19  |  -.0351094   .2686555    -0.13   0.896    -.5616645    .4914457
               20  |   .1657189   .2173623     0.76   0.446    -.2603034    .5917413
               21  |   -.248424   .2275206    -1.09   0.275    -.6943562    .1975082
               22  |  -.1844575   .2189121    -0.84   0.399    -.6135173    .2446023
               23  |   -.314473    .234993    -1.34   0.181    -.7750509    .1461048
               24  |  -.4174909   .2142127    -1.95   0.051      -.83734    .0023581
               25  |  -.0417899   .2332288    -0.18   0.858    -.4989099      .41533
               26  |   -.377893   .2293301    -1.65   0.099    -.8273717    .0715857
               27  |   .1029112   .2125198     0.48   0.628    -.3136199    .5194423
               28  |  -.0624984   .2194528    -0.28   0.776    -.4926179    .3676211
               29  |  -.3527478   .2365729    -1.49   0.136    -.8164221    .1109266
               30  |  -.2579752   .2126936    -1.21   0.225     -.674847    .1588967
               31  |   -.418016   .2304073    -1.81   0.070     -.869606     .033574
               32  |  -.5948936   .2294679    -2.59   0.010    -1.044642   -.1451447
               33  |   -.073138   .2245731    -0.33   0.745    -.5132932    .3670172
               34  |  -.0910349   .2273316    -0.40   0.689    -.5365967    .3545269
               35  |   .1899452   .2195806     0.87   0.387    -.2404249    .6203153
               36  |  -.2176065   .2364398    -0.92   0.357    -.6810201     .245807
               37  |  -.2435516   .2214707    -1.10   0.271    -.6776261     .190523
               38  |  -.1287041   .2142681    -0.60   0.548    -.5486619    .2912536
               39  |  -.2272055   .2322683    -0.98   0.328     -.682443    .2280321
               40  |  -.4545743   .2204962    -2.06   0.039    -.8867389   -.0224096
               41  |   -.372779   .2336827    -1.60   0.111    -.8307887    .0852307
               42  |  -.0654719   .2133724    -0.31   0.759    -.4836741    .3527304
               43  |  -.1690946   .2371112    -0.71   0.476     -.633824    .2956348
               44  |  -.3903022   .2310326    -1.69   0.091    -.8431178    .0625135
               45  |   .0929895   .2176276     0.43   0.669    -.3335527    .5195317
               46  |  -.2923201   .2132197    -1.37   0.170     -.710223    .1255828
               47  |  -.3298171   .2223861    -1.48   0.138    -.7656859    .1060516
               48  |  -.3763238   .2159572    -1.74   0.081    -.7995921    .0469445
               49  |   .1626608   .2330501     0.70   0.485    -.2941089    .6194305
               50  |  -.2414151   .2174781    -1.11   0.267    -.6676644    .1848343
               51  |   .1363216   .2132722     0.64   0.523    -.2816842    .5543274
                   |
             _cons |   2.544458   3.922883     0.65   0.517    -5.144251    10.23317
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |  -.2963391   .0569947    -5.20   0.000    -.4080467   -.1846315
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/BNB_het.tex
dir : seeout

.         
. *** precautionary saving
. ***** low true literacy subgroup
. logit precaution_dummy overconfidence_bnb `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -3717.9486  
Iteration 1:   log pseudolikelihood =  -3371.331  
Iteration 2:   log pseudolikelihood = -3359.7709  
Iteration 3:   log pseudolikelihood = -3359.7279  
Iteration 4:   log pseudolikelihood = -3359.7279  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     445.49
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3359.7279               Pseudo R2         =     0.0963

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   1.126196   .1218799     9.24   0.000     .8873161    1.365077
               age |  -.0941058   .0138889    -6.78   0.000    -.1213275   -.0668841
              age2 |   .0010709   .0001568     6.83   0.000     .0007636    .0013782
         logincome |   -1.38179   .8334796    -1.66   0.097     -3.01538    .2518003
        logincome2 |   .0887282   .0405485     2.19   0.029     .0092546    .1682018
      female_dummy |  -.2353665   .0784547    -3.00   0.003    -.3891349    -.081598
    nonwhite_dummy |  -.2040332   .0844004    -2.42   0.016    -.3694549   -.0386115
     marital_dummy |   .3322096   .0838626     3.96   0.000     .1678419    .4965774
 high_school_dummy |   .6541591   .1390021     4.71   0.000     .3817199    .9265983
     college_dummy |   .5707158   .0897861     6.36   0.000     .3947383    .7466932
                   |
              year |
             2015  |   .0105888   .0969751     0.11   0.913     -.179479    .2006566
             2018  |   .0615256   .0938063     0.66   0.512    -.1223314    .2453827
                   |
        state_cate |
                2  |   .3918324   .3477207     1.13   0.260    -.2896877    1.073352
                3  |  -.1665251   .3265176    -0.51   0.610    -.8064879    .4734377
                4  |  -.4968756   .3016678    -1.65   0.100    -1.088134    .0943823
                5  |  -.2437974   .2713328    -0.90   0.369    -.7755999    .2880052
                6  |  -.2304875   .3291151    -0.70   0.484    -.8755413    .4145663
                7  |  -.4415513   .3328463    -1.33   0.185    -1.093918    .2108154
                8  |  -.3729845   .3415484    -1.09   0.275    -1.042407    .2964381
                9  |  -.1218377    .306905    -0.40   0.691    -.7233604     .479685
               10  |  -.4843705   .2937432    -1.65   0.099    -1.060097    .0913557
               11  |  -.3656903   .2916355    -1.25   0.210    -.9372854    .2059049
               12  |  -.1473538    .347031    -0.42   0.671    -.8275221    .5328145
               13  |  -.1414654   .3537293    -0.40   0.689     -.834762    .5518313
               14  |   .0205241   .2866157     0.07   0.943    -.5412324    .5822806
               15  |  -.7843807    .343173    -2.29   0.022    -1.456987    -.111774
               16  |  -.3113715   .3444246    -0.90   0.366    -.9864313    .3636883
               17  |  -.0993769   .3191081    -0.31   0.755    -.7248172    .5260634
               18  |  -.2229678   .3088655    -0.72   0.470    -.8283331    .3823976
               19  |  -.3339414   .3024846    -1.10   0.270    -.9268004    .2589176
               20  |  -.4920948   .3360818    -1.46   0.143    -1.150803    .1666134
               21  |  -.7571587   .3158096    -2.40   0.017    -1.376134   -.1381832
               22  |  -.4736592   .3268149    -1.45   0.147    -1.114205    .1668863
               23  |   -.407483   .2937556    -1.39   0.165    -.9832333    .1682674
               24  |  -.1633481   .3105658    -0.53   0.599    -.7720459    .4453496
               25  |   -.340385   .2869447    -1.19   0.236    -.9027863    .2220162
               26  |  -.5356421    .311185    -1.72   0.085    -1.145553    .0742692
               27  |  -1.091522   .4558621    -2.39   0.017    -1.984995   -.1980484
               28  |   .0068706   .3379008     0.02   0.984    -.6554028    .6691441
               29  |  -.4385944   .3164823    -1.39   0.166    -1.058888    .1816994
               30  |   .3605002   .3254246     1.11   0.268    -.2773203    .9983207
               31  |  -.7999946    .300973    -2.66   0.008    -1.389891   -.2100984
               32  |  -.0322354   .3488604    -0.09   0.926    -.7159893    .6515185
               33  |  -.3857745   .2641346    -1.46   0.144    -.9034688    .1319197
               34  |   -.049023   .2811746    -0.17   0.862    -.6001151    .5020691
               35  |   .5320538   .3247069     1.64   0.101    -.1043601    1.168468
               36  |   -.131448   .3047652    -0.43   0.666    -.7287769    .4658808
               37  |   -.883132   .3358134    -2.63   0.009    -1.541314   -.2249499
               38  |  -.3293444   .3127273    -1.05   0.292    -.9422786    .2835897
               39  |  -.7716238   .3050057    -2.53   0.011    -1.369424   -.1738236
               40  |  -.3880646   .3186681    -1.22   0.223    -1.012643    .2365134
               41  |  -.1663133   .2959025    -0.56   0.574    -.7462716     .413645
               42  |  -.6032393   .3771706    -1.60   0.110     -1.34248    .1360015
               43  |  -.2328414   .2981764    -0.78   0.435    -.8172564    .3515737
               44  |  -.2053046   .2731801    -0.75   0.452    -.7407278    .3301186
               45  |  -.5806346    .377643    -1.54   0.124    -1.320801    .1595322
               46  |  -.3838392   .3619768    -1.06   0.289    -1.093301    .3256223
               47  |  -.4355813   .3136117    -1.39   0.165    -1.050249    .1790863
               48  |  -.4114651   .2905204    -1.42   0.157    -.9808747    .1579445
               49  |  -.6405092   .3195455    -2.00   0.045    -1.266807   -.0142116
               50  |  -.7370653   .3430819    -2.15   0.032    -1.409494   -.0646371
               51  |  -.7213089   .3820894    -1.89   0.059     -1.47019    .0275725
                   |
             _cons |   4.626672   4.265319     1.08   0.278      -3.7332    12.98654
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .1883458   .0197576     9.53   0.000     .1496215    .2270701
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/BNB_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit precaution_dummy overconfidence_bnb `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -6836.5088  
Iteration 1:   log pseudolikelihood = -5937.1014  
Iteration 2:   log pseudolikelihood = -5914.1866  
Iteration 3:   log pseudolikelihood = -5914.1011  
Iteration 4:   log pseudolikelihood = -5914.1011  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1091.22
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -5914.1011               Pseudo R2         =     0.1349

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   -1.86691   .2806613    -6.65   0.000    -2.416996   -1.316824
               age |  -.1117907   .0136346    -8.20   0.000    -.1385141   -.0850673
              age2 |   .0014327   .0001358    10.55   0.000     .0011666    .0016988
         logincome |  -.6632499   .7656713    -0.87   0.386    -2.163938    .8374382
        logincome2 |    .070561   .0353227     2.00   0.046     .0013299    .1397922
      female_dummy |   .1444087   .0559028     2.58   0.010     .0348411    .2539763
    nonwhite_dummy |  -.0952331   .0774845    -1.23   0.219    -.2470999    .0566337
     marital_dummy |  -.1184078   .0621458    -1.91   0.057    -.2402113    .0033956
 high_school_dummy |    .520859   .3273406     1.59   0.112    -.1207169    1.162435
     college_dummy |   .2200118    .061042     3.60   0.000     .1003716    .3396519
                   |
              year |
             2015  |   .3124048   .0608386     5.13   0.000     .1931634    .4316462
             2018  |   .3718273   .0653156     5.69   0.000     .2438111    .4998435
                   |
        state_cate |
                2  |   .0215789   .2391829     0.09   0.928     -.447211    .4903688
                3  |   .0983185   .2393584     0.41   0.681    -.3708153    .5674524
                4  |   .1857645   .2539483     0.73   0.464    -.3119652    .6834941
                5  |   .1006037   .2421114     0.42   0.678     -.373926    .5751334
                6  |    .215779    .239054     0.90   0.367    -.2527583    .6843163
                7  |   .1995015    .248767     0.80   0.423    -.2880729     .687076
                8  |   .2028787   .2536404     0.80   0.424    -.2942475    .7000048
                9  |  -.1328834   .2386723    -0.56   0.578    -.6006725    .3349057
               10  |   .2626343   .2769689     0.95   0.343    -.2802147    .8054833
               11  |   -.003542   .2634878    -0.01   0.989    -.5199687    .5128846
               12  |   .1847513   .2424958     0.76   0.446    -.2905317    .6600342
               13  |  -.0906908   .2362325    -0.38   0.701     -.553698    .3723163
               14  |   .2160595   .2370591     0.91   0.362    -.2485678    .6806868
               15  |   .0355035   .2548915     0.14   0.889    -.4640746    .5350815
               16  |   .2061653   .2409165     0.86   0.392    -.2660224    .6783529
               17  |   .1498371   .2405367     0.62   0.533    -.3216062    .6212803
               18  |   .1547095   .2564843     0.60   0.546    -.3479905    .6574095
               19  |   .0785568   .2649151     0.30   0.767    -.4406672    .5977808
               20  |  -.3484029   .2391465    -1.46   0.145    -.8171214    .1203156
               21  |  -.1200022   .2360554    -0.51   0.611    -.5826622    .3426578
               22  |   .3259221   .2506085     1.30   0.193    -.1652615    .8171057
               23  |   .1767394   .2553736     0.69   0.489    -.3237837    .6772625
               24  |   .1477921    .239868     0.62   0.538    -.3223406    .6179248
               25  |  -.1848409   .2578095    -0.72   0.473    -.6901382    .3204564
               26  |   .1290262   .2489324     0.52   0.604    -.3588724    .6169247
               27  |   .2211667   .2329277     0.95   0.342    -.2353633    .6776966
               28  |  -.0412024     .23594    -0.17   0.861    -.5036364    .4212315
               29  |   .1459165   .2597628     0.56   0.574    -.3632092    .6550421
               30  |  -.1691905   .2278527    -0.74   0.458    -.6157737    .2773927
               31  |    -.08074   .2450688    -0.33   0.742     -.561066     .399586
               32  |    .078733    .245356     0.32   0.748     -.402156     .559622
               33  |   .2502923   .2559208     0.98   0.328    -.2513033    .7518879
               34  |   .0695014   .2520371     0.28   0.783    -.4244823    .5634851
               35  |   .2144644    .237514     0.90   0.367    -.2510545    .6799833
               36  |  -.1045125   .2512302    -0.42   0.677    -.5969148    .3878897
               37  |  -.0692111   .2479661    -0.28   0.780    -.5552157    .4167935
               38  |  -.1005456   .2376244    -0.42   0.672    -.5662809    .3651896
               39  |    .063641   .2447638     0.26   0.795    -.4160872    .5433691
               40  |   .0335913   .2414626     0.14   0.889    -.4396667    .5068493
               41  |   -.031671   .2577599    -0.12   0.902    -.5368711     .473529
               42  |   .3460402   .2370332     1.46   0.144    -.1185363    .8106166
               43  |  -.0544431   .2631219    -0.21   0.836    -.5701526    .4612664
               44  |   .1060073   .2517422     0.42   0.674    -.3873984     .599413
               45  |  -.1225997   .2370158    -0.52   0.605    -.5871421    .3419427
               46  |   -.084009   .2339098    -0.36   0.719    -.5424638    .3744459
               47  |  -.0481156   .2501193    -0.19   0.847    -.5383405    .4421093
               48  |    .255234   .2416027     1.06   0.291    -.2182986    .7287665
               49  |   .2701404    .264888     1.02   0.308    -.2490304    .7893113
               50  |  -.1821863   .2335149    -0.78   0.435    -.6398671    .2754945
               51  |   .1111847   .2362425     0.47   0.638    -.3518421    .5742115
                   |
             _cons |   .2771577   4.157928     0.07   0.947    -7.872232    8.426548
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |    -.32996   .0489298    -6.74   0.000    -.4258606   -.2340594
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/BNB_het.tex
dir : seeout

.         
. *** financial market participation
. ***** low true literacy subgroup
. logit fin_par_dummy overconfidence_bnb `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =  -2155.857  
Iteration 1:   log pseudolikelihood = -1894.2416  
Iteration 2:   log pseudolikelihood = -1778.2325  
Iteration 3:   log pseudolikelihood = -1774.3699  
Iteration 4:   log pseudolikelihood = -1774.3602  
Iteration 5:   log pseudolikelihood = -1774.3602  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     546.98
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1774.3602               Pseudo R2         =     0.1770

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   1.142936   .1518863     7.52   0.000     .8452447    1.440628
               age |  -.0761354   .0198416    -3.84   0.000    -.1150243   -.0372465
              age2 |   .0009794   .0002213     4.43   0.000     .0005457    .0014131
         logincome |   .8794049   1.293332     0.68   0.497    -1.655479    3.414289
        logincome2 |  -.0005752   .0610902    -0.01   0.992    -.1203098    .1191594
      female_dummy |  -.4762429   .1108485    -4.30   0.000    -.6935019   -.2589839
    nonwhite_dummy |  -.3831952   .1258604    -3.04   0.002    -.6298772   -.1365133
     marital_dummy |   .2199481   .1245236     1.77   0.077    -.0241135    .4640098
 high_school_dummy |   1.193868   .2641973     4.52   0.000     .6760511    1.711686
     college_dummy |     .60417   .1216756     4.97   0.000     .3656902    .8426498
                   |
              year |
             2015  |  -.1778837   .1366372    -1.30   0.193    -.4456876    .0899203
             2018  |   -.303508    .135413    -2.24   0.025    -.5689126   -.0381033
                   |
        state_cate |
                2  |   .3664431   .4741369     0.77   0.440    -.5628482    1.295734
                3  |  -.0987631   .4841324    -0.20   0.838    -1.047645    .8501189
                4  |  -.3751763   .5023606    -0.75   0.455    -1.359785    .6094324
                5  |   .2148906    .409804     0.52   0.600    -.5883104    1.018092
                6  |   .2937478   .4946699     0.59   0.553    -.6757874    1.263283
                7  |  -.0225545   .4838838    -0.05   0.963    -.9709493    .9258404
                8  |   -.248497   .5565463    -0.45   0.655    -1.339308    .8423137
                9  |   .5154725   .4275677     1.21   0.228    -.3225448     1.35349
               10  |  -.1942067   .4751706    -0.41   0.683    -1.125524    .7371106
               11  |  -.1937733   .4774285    -0.41   0.685    -1.129516    .7419694
               12  |  -.5864078   .7109112    -0.82   0.409    -1.979768    .8069526
               13  |  -1.088902   .6349062    -1.72   0.086    -2.333295    .1554915
               14  |  -.0904169   .4260426    -0.21   0.832    -.9254451    .7446112
               15  |  -1.532081   .6952773    -2.20   0.028      -2.8948   -.1693627
               16  |  -.1122513   .5386167    -0.21   0.835    -1.167921    .9434181
               17  |  -.1957599   .5150187    -0.38   0.704    -1.205178    .8136581
               18  |   .1018517   .4685034     0.22   0.828    -.8163981    1.020102
               19  |  -.6852552   .5514504    -1.24   0.214    -1.766078    .3955677
               20  |    .199402   .5179843     0.38   0.700    -.8158286    1.214633
               21  |   .4248867   .4434687     0.96   0.338     -.444296    1.294069
               22  |  -.4300135   .5365147    -0.80   0.423    -1.481563     .621536
               23  |   .1973646    .443537     0.44   0.656     -.671952    1.066681
               24  |  -.0579791   .4878208    -0.12   0.905     -1.01409    .8981321
               25  |  -.4031675   .4910422    -0.82   0.412    -1.365593    .5592574
               26  |    .243622   .4527904     0.54   0.591    -.6438308    1.131075
               27  |   .4746819   .5333375     0.89   0.373    -.5706405    1.520004
               28  |   .9913239   .4709175     2.11   0.035     .0683426    1.914305
               29  |    .026252   .4871742     0.05   0.957    -.9285919    .9810958
               30  |   .1420875   .4824083     0.29   0.768    -.8034153     1.08759
               31  |  -.3581525   .4600175    -0.78   0.436     -1.25977    .5434652
               32  |  -.0239831    .572785    -0.04   0.967    -1.146621    1.098655
               33  |   .1676084   .3953329     0.42   0.672    -.6072298    .9424466
               34  |  -.1980464   .4770718    -0.42   0.678     -1.13309    .7369971
               35  |   .4892716   .4599675     1.06   0.287     -.412248    1.390791
               36  |  -.0929898   .4715757    -0.20   0.844    -1.017261    .8312816
               37  |   .1125324    .468916     0.24   0.810    -.8065261    1.031591
               38  |   .3653883   .4804826     0.76   0.447    -.5763403    1.307117
               39  |   .0499577    .440878     0.11   0.910    -.8141474    .9140627
               40  |  -.3264883   .5031729    -0.65   0.516    -1.312689    .6597125
               41  |   .4384698   .4439938     0.99   0.323    -.4317421    1.308682
               42  |   .0223949    .519746     0.04   0.966    -.9962885    1.041078
               43  |   .0032458   .5106598     0.01   0.995     -.997629    1.004121
               44  |  -.3361702   .4286962    -0.78   0.433    -1.176399    .5040588
               45  |   .0074148   .6184743     0.01   0.990    -1.204773    1.219602
               46  |   .4893094   .4838337     1.01   0.312    -.4589872    1.437606
               47  |  -.2234568   .4900528    -0.46   0.648    -1.183943     .737029
               48  |   .2472568   .4305514     0.57   0.566    -.5966084    1.091122
               49  |  -.1761428   .4913751    -0.36   0.720     -1.13922    .7869347
               50  |  -.4299026   .5446414    -0.79   0.430     -1.49738     .637575
               51  |   .4678485   .5603455     0.83   0.404    -.6304085    1.566106
                   |
             _cons |  -11.43989   6.868511    -1.67   0.096    -24.90192    2.022145
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |   .0886977   .0116725     7.60   0.000     .0658201    .1115754
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/BNB_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit fin_par_dummy overconfidence_bnb `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -7436.5574  
Iteration 1:   log pseudolikelihood = -6627.2765  
Iteration 2:   log pseudolikelihood = -6623.5353  
Iteration 3:   log pseudolikelihood = -6623.5343  
Iteration 4:   log pseudolikelihood = -6623.5343  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =     977.56
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6623.5343               Pseudo R2         =     0.1093

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |  -1.411701   .2655993    -5.32   0.000    -1.932266   -.8911357
               age |  -.0611522   .0128756    -4.75   0.000    -.0863878   -.0359165
              age2 |   .0008315    .000126     6.60   0.000     .0005845    .0010785
         logincome |   -.791628    .770618    -1.03   0.304    -2.302011    .7187554
        logincome2 |   .0759012   .0351711     2.16   0.031     .0069671    .1448352
      female_dummy |  -.0389413   .0505728    -0.77   0.441    -.1380623    .0601797
    nonwhite_dummy |   .0553579   .0734093     0.75   0.451    -.0885216    .1992374
     marital_dummy |  -.0865101   .0569973    -1.52   0.129    -.1982227    .0252026
 high_school_dummy |   .6427205   .3861006     1.66   0.096    -.1140227    1.399464
     college_dummy |   .2683068   .0556646     4.82   0.000     .1592063    .3774074
                   |
              year |
             2015  |  -.2341066    .056955    -4.11   0.000    -.3457364   -.1224769
             2018  |  -.1805896   .0606096    -2.98   0.003    -.2993822   -.0617969
                   |
        state_cate |
                2  |   .3164922   .2083544     1.52   0.129     -.091875    .7248594
                3  |   .3612671   .2088249     1.73   0.084    -.0480222    .7705564
                4  |   .4307038   .2202273     1.96   0.050    -.0009338    .8623414
                5  |   .3693726   .2095087     1.76   0.078     -.041257    .7800021
                6  |   .3857734   .2114803     1.82   0.068    -.0287203    .8002671
                7  |   .6863348   .2174968     3.16   0.002     .2600489    1.112621
                8  |   .4285899   .2161865     1.98   0.047     .0048721    .8523077
                9  |   .4044817   .2178205     1.86   0.063    -.0224386    .8314019
               10  |   .5701014   .2469631     2.31   0.021     .0860625     1.05414
               11  |   .3430902   .2368279     1.45   0.147     -.121084    .8072645
               12  |   .7996451   .2187032     3.66   0.000     .3709947    1.228296
               13  |   .3766641   .2105216     1.79   0.074    -.0359507    .7892789
               14  |   .4363206    .206975     2.11   0.035      .030657    .8419842
               15  |   .2553841   .2212825     1.15   0.248    -.1783216    .6890897
               16  |   .4912093   .2083741     2.36   0.018     .0828037     .899615
               17  |   .5214379      .2141     2.44   0.015     .1018096    .9410663
               18  |   .2470463   .2234115     1.11   0.269    -.1908322    .6849248
               19  |   .2820189   .2473737     1.14   0.254    -.2028246    .7668623
               20  |   .1807678   .2093079     0.86   0.388    -.2294681    .5910037
               21  |    .255514    .218363     1.17   0.242    -.1724697    .6834977
               22  |   .4400226   .2172624     2.03   0.043     .0141961     .865849
               23  |   .1912027   .2202103     0.87   0.385    -.2404016     .622807
               24  |   .0811152   .2077055     0.39   0.696    -.3259801    .4882104
               25  |   .0234263   .2323895     0.10   0.920    -.4320488    .4789014
               26  |   .2739121    .215721     1.27   0.204    -.1488934    .6967175
               27  |   .3721254   .2057078     1.81   0.070    -.0310545    .7753054
               28  |   .1574215   .2059521     0.76   0.445    -.2462372    .5610803
               29  |   .2440626   .2210803     1.10   0.270    -.1892469    .6773721
               30  |  -.0196881   .1990701    -0.10   0.921    -.4098583    .3704821
               31  |   .7213057   .2206517     3.27   0.001     .2888364    1.153775
               32  |   .1187306   .2163458     0.55   0.583    -.3052993    .5427605
               33  |   .4078675   .2163056     1.89   0.059    -.0160836    .8318186
               34  |   .5724742   .2257835     2.54   0.011     .1299467    1.015002
               35  |   .3746385   .2074831     1.81   0.071    -.0320209     .781298
               36  |   .3116071    .224394     1.39   0.165    -.1281971    .7514113
               37  |   .0854434   .2194428     0.39   0.697    -.3446567    .5155435
               38  |   .2577425   .2050849     1.26   0.209    -.1442166    .6597015
               39  |   .4897222   .2189968     2.24   0.025     .0604963    .9189481
               40  |   .3251169   .2083349     1.56   0.119    -.0832121    .7334458
               41  |  -.0147225   .2203125    -0.07   0.947    -.4465271     .417082
               42  |    .531168   .2076838     2.56   0.011     .1241152    .9382209
               43  |   .1729199   .2265591     0.76   0.445    -.2711277    .6169675
               44  |   .0568585   .2174913     0.26   0.794    -.3694166    .4831335
               45  |   .0778451   .2073502     0.38   0.707    -.3285538    .4842441
               46  |   .1761433   .2072859     0.85   0.395    -.2301296    .5824162
               47  |   .3964504   .2152145     1.84   0.065    -.0253623    .8182631
               48  |   .5088991   .2105714     2.42   0.016     .0961868    .9216115
               49  |   .2492465   .2272351     1.10   0.273    -.1961262    .6946191
               50  |   .4006248   .2091684     1.92   0.055    -.0093377    .8105874
               51  |   .2105914   .2056659     1.02   0.306    -.1925063    .6136891
                   |
             _cons |  -.3714567   4.286256    -0.09   0.931    -8.772365    8.029451
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_bnb) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_bnb

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_bnb |  -.2881489   .0537407    -5.36   0.000    -.3934787   -.1828191
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/BNB_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/BNB_het.tex
dir : seeout

.         
. * heterogeneous effects with KNN
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_knn `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -2789.9313  
Iteration 1:   log pseudolikelihood = -2497.3152  
Iteration 2:   log pseudolikelihood = -2460.1484  
Iteration 3:   log pseudolikelihood = -2459.8244  
Iteration 4:   log pseudolikelihood = -2459.8244  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     429.25
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -2459.8244               Pseudo R2         =     0.1183

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   1.250517   .1469492     8.51   0.000     .9625022    1.538533
               age |   .0245087   .0184546     1.33   0.184    -.0116616    .0606791
              age2 |  -.0004349   .0002122    -2.05   0.040    -.0008508    -.000019
         logincome |  -2.490043   1.017394    -2.45   0.014    -4.484099   -.4959871
        logincome2 |   .1406648   .0491282     2.86   0.004     .0443753    .2369543
      female_dummy |  -.1796596   .0923311    -1.95   0.052    -.3606252     .001306
    nonwhite_dummy |   .1807406   .0959874     1.88   0.060    -.0073914    .3688725
     marital_dummy |   .5257983   .1027616     5.12   0.000     .3243892    .7272074
 high_school_dummy |   .5773693   .1921044     3.01   0.003     .2008516     .953887
     college_dummy |   .4739684   .1002244     4.73   0.000     .2775322    .6704046
                   |
              year |
             2015  |   .0740949   .1181147     0.63   0.530    -.1574056    .3055955
             2018  |   .0698815   .1169761     0.60   0.550    -.1593874    .2991504
                   |
        state_cate |
                2  |   .1644053   .3764057     0.44   0.662    -.5733363    .9021468
                3  |  -.4858655   .4022338    -1.21   0.227    -1.274229    .3024983
                4  |  -.5231244   .3807903    -1.37   0.170     -1.26946    .2232109
                5  |  -.2556377   .3080998    -0.83   0.407    -.8595022    .3482268
                6  |  -.4573261   .3801499    -1.20   0.229    -1.202406     .287754
                7  |    -.30584   .3734287    -0.82   0.413    -1.037747    .4260668
                8  |  -.3088222   .3881796    -0.80   0.426     -1.06964    .4519959
                9  |   .0421504   .3574721     0.12   0.906     -.658482    .7427829
               10  |  -.0472635   .3370871    -0.14   0.888    -.7079421    .6134151
               11  |  -.5320156   .3423607    -1.55   0.120     -1.20303    .1389991
               12  |  -1.162799   .5449611    -2.13   0.033    -2.230903   -.0946945
               13  |   -1.26416   .6937956    -1.82   0.068    -2.623974    .0956546
               14  |  -.4894151   .3406111    -1.44   0.151    -1.157001    .1781704
               15  |    -.59631   .3994165    -1.49   0.135    -1.379152    .1865319
               16  |  -.5440083   .4102432    -1.33   0.185     -1.34807    .2600535
               17  |  -.3401024   .4047036    -0.84   0.401    -1.133307    .4531021
               18  |   .0299368   .3650375     0.08   0.935    -.6855235     .745397
               19  |  -.6394279   .3756106    -1.70   0.089    -1.375611    .0967554
               20  |  -.4371245   .4011724    -1.09   0.276    -1.223408     .349159
               21  |  -.5130448   .3745786    -1.37   0.171    -1.247205    .2211158
               22  |   -.040571    .371362    -0.11   0.913    -.7684271    .6872851
               23  |  -.1705777   .3337017    -0.51   0.609     -.824621    .4834656
               24  |  -.6444245   .3812245    -1.69   0.091    -1.391611    .1027617
               25  |  -.6658277   .3595301    -1.85   0.064    -1.370494    .0388385
               26  |  -.8906705   .3969822    -2.24   0.025    -1.668741   -.1125996
               27  |  -.2259432   .4245685    -0.53   0.595    -1.058082    .6061958
               28  |    -.78308   .4426894    -1.77   0.077    -1.650735    .0845752
               29  |  -.1901135    .365184    -0.52   0.603     -.905861     .525634
               30  |  -.2313656   .4276842    -0.54   0.589    -1.069611    .6068801
               31  |  -.4235941   .3390112    -1.25   0.211    -1.088044    .2408556
               32  |   -.134092   .4001538    -0.34   0.738    -.9183791     .650195
               33  |  -.3952283   .3137064    -1.26   0.208    -1.010082     .219625
               34  |  -.9747707   .3927445    -2.48   0.013    -1.744536   -.2050057
               35  |  -.0901799   .3763256    -0.24   0.811    -.8277645    .6474046
               36  |  -.6964107   .3977239    -1.75   0.080    -1.475935    .0831138
               37  |  -.4541554   .3769659    -1.20   0.228    -1.192995    .2846842
               38  |  -.6090669   .3617513    -1.68   0.092    -1.318087    .0999527
               39  |  -.6582941    .367579    -1.79   0.073    -1.378736    .0621475
               40  |   -.919133   .4063089    -2.26   0.024    -1.715484   -.1227823
               41  |  -.4475579   .3582455    -1.25   0.212    -1.149706    .2545904
               42  |  -.2175229   .4298522    -0.51   0.613    -1.060018     .624972
               43  |  -.1876837   .3695585    -0.51   0.612     -.912005    .5366376
               44  |  -.5578982   .3309219    -1.69   0.092    -1.206493    .0906969
               45  |  -.7224413   .4524198    -1.60   0.110    -1.609168    .1642852
               46  |  -.4914096   .4178955    -1.18   0.240     -1.31047    .3276506
               47  |  -.0839449   .3440531    -0.24   0.807    -.7582766    .5903868
               48  |  -.3819871   .3314079    -1.15   0.249    -1.031535    .2675604
               49  |  -.2343401   .3815046    -0.61   0.539    -.9820753    .5133951
               50  |  -.6238656   .4196535    -1.49   0.137    -1.446371    .1986401
               51  |  -.1580063   .4037385    -0.39   0.696    -.9493192    .6333066
                   |
             _cons |    7.55321   5.240002     1.44   0.149    -2.717005    17.82343
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_knn

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .1416691   .0162831     8.70   0.000     .1097548    .1735834
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN_het.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/KNN_het.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_knn `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =   -7639.91  
Iteration 1:   log pseudolikelihood = -6375.5119  
Iteration 2:   log pseudolikelihood = -6365.6071  
Iteration 3:   log pseudolikelihood = -6365.5909  
Iteration 4:   log pseudolikelihood = -6365.5909  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1631.47
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6365.5909               Pseudo R2         =     0.1668

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |  -1.592743   .4716061    -3.38   0.001    -2.517074   -.6684122
               age |   .1969091   .0133378    14.76   0.000     .1707675    .2230506
              age2 |   -.002491   .0001297   -19.21   0.000    -.0027451   -.0022368
         logincome |  -2.228105   .7315378    -3.05   0.002    -3.661893   -.7943174
        logincome2 |   .1294947   .0332091     3.90   0.000      .064406    .1945834
      female_dummy |  -.0156456   .0506878    -0.31   0.758    -.1149918    .0837007
    nonwhite_dummy |   .1079649   .0706902     1.53   0.127    -.0305854    .2465152
     marital_dummy |  -.0390997   .0609652    -0.64   0.521    -.1585893      .08039
 high_school_dummy |   .2842262   .3913911     0.73   0.468    -.4828863    1.051339
     college_dummy |   .2812361   .0542557     5.18   0.000      .174897    .3875752
                   |
              year |
             2015  |   .0210262   .0591034     0.36   0.722    -.0948143    .1368667
             2018  |    .088688   .0622918     1.42   0.155    -.0334016    .2107776
                   |
        state_cate |
                2  |  -.0266341   .2139719    -0.12   0.901    -.4460113    .3927432
                3  |  -.1648551   .2274466    -0.72   0.469    -.6106423    .2809321
                4  |   -.515951   .2327382    -2.22   0.027    -.9721095   -.0597925
                5  |  -.3994415   .2222375    -1.80   0.072    -.8350191     .036136
                6  |  -.1075786   .2227709    -0.48   0.629    -.5442015    .3290444
                7  |  -.0446057   .2179498    -0.20   0.838    -.4717795    .3825681
                8  |  -.2997388   .2168361    -1.38   0.167    -.7247298    .1252522
                9  |  -.0974755   .2249663    -0.43   0.665    -.5384013    .3434503
               10  |  -.4557386   .2536657    -1.80   0.072    -.9529143     .041437
               11  |   -.328022   .2331406    -1.41   0.159    -.7849691    .1289251
               12  |  -.3239017    .211108    -1.53   0.125    -.7376658    .0898625
               13  |  -.2854587   .2206276    -1.29   0.196    -.7178808    .1469634
               14  |  -.0699286   .2137659    -0.33   0.744    -.4889021    .3490449
               15  |   .2388174    .227125     1.05   0.293    -.2063394    .6839743
               16  |  -.1014392   .2198964    -0.46   0.645    -.5324282    .3295499
               17  |  -.1921883   .2172353    -0.88   0.376    -.6179616     .233585
               18  |   .0522197   .2317422     0.23   0.822    -.4019867    .5064261
               19  |  -.0618896   .2673016    -0.23   0.817    -.5857912    .4620119
               20  |   .2247644   .2156606     1.04   0.297    -.1979226    .6474514
               21  |   -.213249   .2263732    -0.94   0.346    -.6569323    .2304344
               22  |  -.1379745   .2170047    -0.64   0.525    -.5632958    .2873469
               23  |  -.3297551   .2322935    -1.42   0.156    -.7850419    .1255318
               24  |  -.3666401   .2117392    -1.73   0.083    -.7816413     .048361
               25  |   -.010896   .2305351    -0.05   0.962    -.4627364    .4409445
               26  |  -.3512933   .2267118    -1.55   0.121    -.7956402    .0930536
               27  |   .1553915   .2109546     0.74   0.461     -.258072     .568855
               28  |  -.0002642   .2173767    -0.00   0.999    -.4263148    .4257863
               29  |  -.3206325   .2326447    -1.38   0.168    -.7766078    .1353428
               30  |  -.1916215   .2103952    -0.91   0.362    -.6039886    .2207456
               31  |  -.3350677    .228693    -1.47   0.143    -.7832978    .1131623
               32  |  -.5358533   .2276134    -2.35   0.019    -.9819674   -.0897392
               33  |  -.1079999   .2242606    -0.48   0.630    -.5475427    .3315429
               34  |  -.0857009   .2248069    -0.38   0.703    -.5263144    .3549126
               35  |   .2322933   .2166914     1.07   0.284     -.192414    .6570005
               36  |  -.1887312    .233396    -0.81   0.419    -.6461789    .2687165
               37  |  -.1948947   .2196189    -0.89   0.375    -.6253398    .2355503
               38  |  -.0896592   .2112309    -0.42   0.671    -.5036641    .3243457
               39  |  -.2152161   .2307083    -0.93   0.351    -.6673959    .2369638
               40  |  -.3856375   .2178372    -1.77   0.077    -.8125906    .0413156
               41  |  -.3324581   .2311623    -1.44   0.150    -.7855278    .1206116
               42  |   .0067266   .2110239     0.03   0.975    -.4068727    .4203259
               43  |   -.169784   .2355717    -0.72   0.471     -.631496     .291928
               44  |  -.4280176   .2297113    -1.86   0.062    -.8782434    .0222082
               45  |   .1714962   .2158193     0.79   0.427    -.2515018    .5944943
               46  |  -.2388565   .2111681    -1.13   0.258    -.6527383    .1750254
               47  |  -.3254471   .2212082    -1.47   0.141    -.7590072    .1081129
               48  |  -.3432103   .2122945    -1.62   0.106    -.7592999    .0728794
               49  |   .1857263   .2307756     0.80   0.421    -.2665856    .6380382
               50  |  -.2122079   .2154516    -0.98   0.325    -.6344853    .2100696
               51  |   .2159437   .2104601     1.03   0.305    -.1965506     .628438
                   |
             _cons |   5.224509   4.094618     1.28   0.202    -2.800795    13.24981
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_knn

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   -.309041   .0911879    -3.39   0.001    -.4877659    -.130316
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/KNN_het.tex
dir : seeout

.         
. *** precautionary saving
. ***** low true literacy subgroup
. logit precaution_dummy overconfidence_knn `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -3717.9486  
Iteration 1:   log pseudolikelihood = -3362.9587  
Iteration 2:   log pseudolikelihood =  -3351.227  
Iteration 3:   log pseudolikelihood = -3351.1849  
Iteration 4:   log pseudolikelihood = -3351.1849  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     453.33
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3351.1849               Pseudo R2         =     0.0986

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   1.224341   .1249987     9.79   0.000     .9793476    1.469333
               age |  -.0900218    .014031    -6.42   0.000    -.1175221   -.0625215
              age2 |   .0010874   .0001578     6.89   0.000     .0007782    .0013967
         logincome |  -2.498586    .845691    -2.95   0.003     -4.15611   -.8410623
        logincome2 |   .1448278   .0411828     3.52   0.000     .0641109    .2255447
      female_dummy |  -.0948499   .0779297    -1.22   0.224    -.2475893    .0578896
    nonwhite_dummy |  -.0098956    .082247    -0.12   0.904    -.1710968    .1513056
     marital_dummy |   .2210353   .0830867     2.66   0.008     .0581883    .3838823
 high_school_dummy |   .4110611   .1378587     2.98   0.003      .140863    .6812591
     college_dummy |   .3781549   .0876704     4.31   0.000      .206324    .5499858
                   |
              year |
             2015  |   .0044159   .0973446     0.05   0.964    -.1863761    .1952078
             2018  |   .0675811   .0941051     0.72   0.473    -.1168614    .2520237
                   |
        state_cate |
                2  |   .2066825   .3474641     0.59   0.552    -.4743346    .8876997
                3  |   -.240245    .329783    -0.73   0.466    -.8866079    .4061178
                4  |  -.5596269   .3034561    -1.84   0.065     -1.15439    .0351361
                5  |  -.2251673   .2729964    -0.82   0.409    -.7602303    .3098958
                6  |  -.3896212   .3269076    -1.19   0.233    -1.030348     .251106
                7  |  -.5710051   .3346516    -1.71   0.088     -1.22691    .0848999
                8  |  -.5214879   .3443295    -1.51   0.130    -1.196361    .1533854
                9  |  -.1295529   .3118712    -0.42   0.678    -.7408093    .4817035
               10  |  -.4398986   .2943289    -1.49   0.135    -1.016773    .1369754
               11  |  -.3731782    .293274    -1.27   0.203    -.9479846    .2016282
               12  |  -.3603329   .3477118    -1.04   0.300    -1.041835    .3211697
               13  |  -.3042419   .3540791    -0.86   0.390    -.9982241    .3897403
               14  |  -.0698649    .287966    -0.24   0.808    -.6342679    .4945381
               15  |  -.8419294   .3413361    -2.47   0.014    -1.510936    -.172923
               16  |  -.4816042   .3389507    -1.42   0.155    -1.145935     .182727
               17  |  -.2029898   .3182819    -0.64   0.524    -.8268108    .4208312
               18  |  -.2822449   .3105548    -0.91   0.363     -.890921    .3264313
               19  |  -.3187135   .3052298    -1.04   0.296    -.9169529     .279526
               20  |  -.6098034   .3364903    -1.81   0.070    -1.269312    .0497054
               21  |  -.8391053   .3195356    -2.63   0.009    -1.465384    -.212827
               22  |    -.58056    .328008    -1.77   0.077    -1.223444    .0623238
               23  |   -.402461   .2946329    -1.37   0.172    -.9799309    .1750088
               24  |  -.2903816   .3125507    -0.93   0.353    -.9029696    .3222065
               25  |  -.3647831   .2917682    -1.25   0.211    -.9366382    .2070721
               26  |  -.5872506   .3129216    -1.88   0.061    -1.200566    .0260646
               27  |  -1.204996   .4513806    -2.67   0.008    -2.089685    -.320306
               28  |  -.1292058   .3389981    -0.38   0.703    -.7936298    .5352183
               29  |  -.5212196    .319644    -1.63   0.103     -1.14771    .1052711
               30  |   .1476356   .3220178     0.46   0.647    -.4835077     .778779
               31  |  -.9629159   .3007663    -3.20   0.001    -1.552407   -.3734248
               32  |  -.1774938   .3559966    -0.50   0.618    -.8752343    .5202468
               33  |  -.3144931   .2665034    -1.18   0.238    -.8368301    .2078438
               34  |  -.0689908   .2830044    -0.24   0.807    -.6236692    .4856877
               35  |   .3903181   .3237022     1.21   0.228    -.2441266    1.024763
               36  |  -.2050631   .3067123    -0.67   0.504     -.806208    .3960819
               37  |  -.9177825   .3388345    -2.71   0.007    -1.581886   -.2536791
               38  |  -.3708937   .3133116    -1.18   0.236    -.9849731    .2431857
               39  |  -.7843431   .3075611    -2.55   0.011    -1.387152   -.1815344
               40  |  -.5796386   .3189807    -1.82   0.069    -1.204829    .0455521
               41  |  -.2550375    .298985    -0.85   0.394    -.8410373    .3309624
               42  |  -.7412038   .3721175    -1.99   0.046    -1.470541    -.011867
               43  |  -.2566901   .2978519    -0.86   0.389    -.8404691    .3270889
               44  |  -.1564677   .2743125    -0.57   0.568    -.6941103    .3811749
               45  |  -.6898974    .370258    -1.86   0.062     -1.41559     .035795
               46  |  -.5779023   .3619154    -1.60   0.110    -1.287243    .1314389
               47  |  -.4533064    .314326    -1.44   0.149    -1.069374    .1627612
               48  |  -.4857758    .288739    -1.68   0.092    -1.051694    .0801422
               49  |  -.7441147   .3180924    -2.34   0.019    -1.367564   -.1206651
               50  |  -.8361433   .3425569    -2.44   0.015    -1.507542   -.1647441
               51  |  -.8816314   .3795347    -2.32   0.020    -1.625506    -.137757
                   |
             _cons |   10.09481   4.317561     2.34   0.019     1.632548    18.55708
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_knn

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .2041392   .0201058    10.15   0.000     .1647325    .2435458
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/KNN_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit precaution_dummy overconfidence_knn `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -6836.5088  
Iteration 1:   log pseudolikelihood = -5968.3221  
Iteration 2:   log pseudolikelihood =  -5944.259  
Iteration 3:   log pseudolikelihood = -5944.1294  
Iteration 4:   log pseudolikelihood = -5944.1294  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1102.22
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -5944.1294               Pseudo R2         =     0.1305

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |  -1.486174   .4301866    -3.45   0.001    -2.329324   -.6430236
               age |  -.1213746   .0140015    -8.67   0.000     -.148817   -.0939323
              age2 |   .0015137   .0001379    10.98   0.000     .0012434    .0017839
         logincome |  -1.115639   .7630532    -1.46   0.144    -2.611196    .3799178
        logincome2 |   .0894156   .0350594     2.55   0.011     .0207004    .1581308
      female_dummy |   .0385407   .0532744     0.72   0.469    -.0658752    .1429565
    nonwhite_dummy |  -.2352249   .0727771    -3.23   0.001    -.3778655   -.0925843
     marital_dummy |  -.0406398   .0609076    -0.67   0.505    -.1600166    .0787369
 high_school_dummy |   .8527483   .3241674     2.63   0.009     .2173919    1.488105
     college_dummy |   .3715821   .0562452     6.61   0.000     .2613435    .4818206
                   |
              year |
             2015  |   .3119709   .0607209     5.14   0.000     .1929602    .4309816
             2018  |   .3613356   .0647875     5.58   0.000     .2343545    .4883167
                   |
        state_cate |
                2  |   .1253972   .2401228     0.52   0.602    -.3452349    .5960292
                3  |   .1573147    .239434     0.66   0.511    -.3119673    .6265968
                4  |   .2316575    .255345     0.91   0.364    -.2688095    .7321246
                5  |   .0301689   .2404073     0.13   0.900    -.4410207    .5013585
                6  |   .2983881   .2392371     1.25   0.212    -.1705079    .7672842
                7  |   .2583144   .2498363     1.03   0.301    -.2313558    .7479845
                8  |   .2625776   .2534241     1.04   0.300    -.2341246    .7592797
                9  |  -.1003265   .2386768    -0.42   0.674    -.5681245    .3674715
               10  |    .227413   .2701575     0.84   0.400    -.3020859    .7569119
               11  |  -.0067025    .262874    -0.03   0.980    -.5219262    .5085211
               12  |   .3358597   .2430424     1.38   0.167    -.1404947    .8122141
               13  |  -.0153053   .2373724    -0.06   0.949    -.4805466     .449936
               14  |   .2489549    .236663     1.05   0.293    -.2148962    .7128059
               15  |    .074772   .2531066     0.30   0.768    -.4213077    .5708518
               16  |   .3158261   .2435925     1.30   0.195    -.1616065    .7932586
               17  |    .201393   .2413236     0.83   0.404    -.2715926    .6743787
               18  |   .1932188   .2592987     0.75   0.456    -.3149974    .7014349
               19  |   .0458644   .2652244     0.17   0.863    -.4739659    .5656948
               20  |  -.2679221   .2404048    -1.11   0.265    -.7391069    .2032626
               21  |  -.0679925   .2360443    -0.29   0.773    -.5306308    .3946458
               22  |   .4007799    .250503     1.60   0.110    -.0901969    .8917568
               23  |   .1510592   .2547867     0.59   0.553    -.3483134    .6504319
               24  |   .2181191   .2408275     0.91   0.365    -.2538941    .6901324
               25  |  -.1342879   .2573603    -0.52   0.602    -.6387049     .370129
               26  |   .1643517   .2488785     0.66   0.509    -.3234412    .6521446
               27  |   .2994092    .233708     1.28   0.200    -.1586502    .7574685
               28  |   .0453121   .2361542     0.19   0.848    -.4175417     .508166
               29  |   .1921172   .2572306     0.75   0.455    -.3120456      .69628
               30  |  -.0663467   .2280135    -0.29   0.771     -.513245    .3805516
               31  |   .0327596   .2458502     0.13   0.894    -.4490979     .514617
               32  |   .1639079   .2443723     0.67   0.502    -.3150529    .6428688
               33  |    .192604   .2495021     0.77   0.440    -.2964111    .6816191
               34  |   .0712237   .2509987     0.28   0.777    -.4207248    .5631722
               35  |   .2780519   .2379556     1.17   0.243    -.1883326    .7444364
               36  |  -.0603556   .2511129    -0.24   0.810    -.5525277    .4318166
               37  |  -.0031363   .2481055    -0.01   0.990    -.4894141    .4831415
               38  |  -.0476706   .2367193    -0.20   0.840    -.5116319    .4162907
               39  |   .0867394   .2450892     0.35   0.723    -.3936265    .5671053
               40  |   .1294716   .2428395     0.53   0.594    -.3464851    .6054283
               41  |   .0274891   .2582096     0.11   0.915    -.4785924    .5335707
               42  |   .4578498    .238766     1.92   0.055     -.010123    .9258227
               43  |  -.0531671   .2594381    -0.20   0.838    -.5616563    .4553222
               44  |   .0608709   .2490587     0.24   0.807    -.4272752     .549017
               45  |  -.0214259   .2394909    -0.09   0.929    -.4908194    .4479677
               46  |   .0018264   .2345352     0.01   0.994    -.4578542     .461507
               47  |  -.0463553   .2475052    -0.19   0.851    -.5314565    .4387459
               48  |   .2996635   .2388195     1.25   0.210     -.168414    .7677411
               49  |   .3062968   .2661919     1.15   0.250    -.2154297    .8280233
               50  |  -.1309272   .2345917    -0.56   0.577    -.5907185    .3288642
               51  |   .2243986   .2370956     0.95   0.344    -.2403003    .6890975
                   |
             _cons |   2.704193   4.187738     0.65   0.518    -5.503622    10.91201
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_knn

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |  -.2642313    .076214    -3.47   0.001    -.4136079   -.1148546
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/KNN_het.tex
dir : seeout

.         
. *** financial market participation
. ***** low true literacy subgroup
. logit fin_par_dummy overconfidence_knn `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =  -2155.857  
Iteration 1:   log pseudolikelihood = -1890.6995  
Iteration 2:   log pseudolikelihood = -1780.4325  
Iteration 3:   log pseudolikelihood = -1776.6471  
Iteration 4:   log pseudolikelihood = -1776.6385  
Iteration 5:   log pseudolikelihood = -1776.6385  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     529.83
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1776.6385               Pseudo R2         =     0.1759

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   1.162445   .1585073     7.33   0.000      .851776    1.473113
               age |  -.0672648    .020168    -3.34   0.001    -.1067934   -.0277362
              age2 |    .000944   .0002234     4.22   0.000     .0005061    .0013819
         logincome |  -.0224806    1.29092    -0.02   0.986    -2.552637    2.507676
        logincome2 |   .0449618   .0609766     0.74   0.461    -.0745501    .1644737
      female_dummy |  -.3640722   .1095047    -3.32   0.001    -.5786974    -.149447
    nonwhite_dummy |   -.213739   .1244104    -1.72   0.086    -.4575788    .0301009
     marital_dummy |   .1221244   .1231829     0.99   0.321    -.1193096    .3635584
 high_school_dummy |   .9681058   .2712161     3.57   0.000      .436532    1.499679
     college_dummy |   .4459186   .1210256     3.68   0.000     .2087127    .6831245
                   |
              year |
             2015  |  -.1822673   .1365409    -1.33   0.182    -.4498826     .085348
             2018  |  -.2996561   .1353187    -2.21   0.027     -.564876   -.0344362
                   |
        state_cate |
                2  |   .2204121   .4689278     0.47   0.638    -.6986695    1.139494
                3  |  -.1601033   .4821384    -0.33   0.740    -1.105077    .7848706
                4  |  -.4117316   .4996783    -0.82   0.410    -1.391083    .5676199
                5  |   .2390845   .4054404     0.59   0.555    -.5555641    1.033733
                6  |   .1636035   .4841552     0.34   0.735    -.7853232     1.11253
                7  |  -.1397776   .4833571    -0.29   0.772     -1.08714    .8075849
                8  |  -.3524537   .5490965    -0.64   0.521    -1.428663    .7237558
                9  |   .5003153   .4263003     1.17   0.241    -.3352179    1.335849
               10  |  -.1450395   .4681263    -0.31   0.757     -1.06255    .7724711
               11  |  -.1947904   .4743967    -0.41   0.681    -1.124591    .7350099
               12  |  -.7766455   .7066261    -1.10   0.272    -2.161607    .6083162
               13  |  -1.225546   .6273095    -1.95   0.051     -2.45505    .0039583
               14  |  -.1759928   .4212641    -0.42   0.676    -1.001655    .6496697
               15  |  -1.546134   .6881513    -2.25   0.025    -2.894886   -.1973821
               16  |  -.2524743   .5358626    -0.47   0.638    -1.302746    .7977972
               17  |  -.2678158   .5103045    -0.52   0.600    -1.267994    .7323626
               18  |    .047142   .4655049     0.10   0.919    -.8652309    .9595149
               19  |   -.676124   .5448197    -1.24   0.215    -1.743951    .3917031
               20  |   .0967503   .5101916     0.19   0.850     -.903207    1.096708
               21  |   .3536826   .4426721     0.80   0.424    -.5139388    1.221304
               22  |  -.5123436   .5329792    -0.96   0.336    -1.556964    .5322764
               23  |   .2046703   .4402061     0.46   0.642    -.6581178    1.067458
               24  |  -.1725828   .4826307    -0.36   0.721    -1.118521     .773356
               25  |  -.4367555   .4917516    -0.89   0.374    -1.400571      .52706
               26  |    .201353   .4513094     0.45   0.655    -.6831972    1.085903
               27  |   .3606636   .5211169     0.69   0.489    -.6607067    1.382034
               28  |   .8725151   .4640687     1.88   0.060    -.0370428    1.782073
               29  |  -.0498289   .4936446    -0.10   0.920    -1.017355    .9176969
               30  |   -.034083   .4750622    -0.07   0.943    -.9651878    .8970217
               31  |  -.5146936   .4573195    -1.13   0.260    -1.411023    .3816362
               32  |   -.173364   .5766985    -0.30   0.764    -1.303672    .9569443
               33  |   .2336974   .3926322     0.60   0.552    -.5358477    1.003242
               34  |  -.2066479   .4728011    -0.44   0.662    -1.133321    .7200252
               35  |   .3760116   .4503413     0.83   0.404    -.5066412    1.258664
               36  |  -.1565516   .4726676    -0.33   0.740    -1.082963    .7698598
               37  |   .0844611   .4693229     0.18   0.857    -.8353948    1.004317
               38  |   .3425481   .4716984     0.73   0.468    -.5819639     1.26706
               39  |   .0444322   .4390582     0.10   0.919    -.8161062    .9049705
               40  |  -.4969214   .4982582    -1.00   0.319     -1.47349    .4796468
               41  |    .353884   .4413588     0.80   0.423    -.5111634    1.218931
               42  |  -.0890848   .5110788    -0.17   0.862    -1.090781    .9126111
               43  |  -.0152863   .5078718    -0.03   0.976    -1.010697    .9801242
               44  |  -.2753365   .4235488    -0.65   0.516    -1.105477    .5548039
               45  |  -.0780546   .6065938    -0.13   0.898    -1.266957    1.110847
               46  |   .3010265    .480587     0.63   0.531    -.6409068     1.24296
               47  |  -.2283453   .4873639    -0.47   0.639    -1.183561    .7268704
               48  |   .1816175   .4234524     0.43   0.668    -.6483339    1.011569
               49  |  -.2577851   .4857639    -0.53   0.596    -1.209865    .6942947
               50  |  -.5050265   .5367665    -0.94   0.347    -1.557069    .5470165
               51  |    .332253   .5436561     0.61   0.541    -.7332933    1.397799
                   |
             _cons |   -7.12923   6.863734    -1.04   0.299     -20.5819    6.323442
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_knn

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |   .0904818   .0122786     7.37   0.000     .0664161    .1145474
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/KNN_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit fin_par_dummy overconfidence_knn `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -7436.5574  
Iteration 1:   log pseudolikelihood = -6641.7015  
Iteration 2:   log pseudolikelihood = -6638.0289  
Iteration 3:   log pseudolikelihood = -6638.0276  
Iteration 4:   log pseudolikelihood = -6638.0276  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =     981.34
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6638.0276               Pseudo R2         =     0.1074

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |  -1.564887    .477962    -3.27   0.001    -2.501675   -.6280987
               age |  -.0717444   .0132891    -5.40   0.000    -.0977906   -.0456982
              age2 |    .000921   .0001286     7.16   0.000     .0006689    .0011731
         logincome |  -1.333592   .7848069    -1.70   0.089    -2.871785    .2046012
        logincome2 |   .0986778   .0356137     2.77   0.006     .0288762    .1684795
      female_dummy |   -.108701   .0487982    -2.23   0.026    -.2043437   -.0130583
    nonwhite_dummy |  -.0446514   .0695895    -0.64   0.521    -.1810443    .0917415
     marital_dummy |  -.0334925    .056395    -0.59   0.553    -.1440247    .0770396
 high_school_dummy |     .88316    .379593     2.33   0.020     .1391713    1.627149
     college_dummy |   .3735875   .0521095     7.17   0.000     .2714548    .4757203
                   |
              year |
             2015  |  -.2342398   .0569253    -4.11   0.000    -.3458114   -.1226682
             2018  |  -.1869357   .0604511    -3.09   0.002    -.3054177   -.0684537
                   |
        state_cate |
                2  |   .3872374   .2075465     1.87   0.062    -.0195461     .794021
                3  |   .3990471   .2087762     1.91   0.056    -.0101467    .8082409
                4  |   .4580899   .2211845     2.07   0.038     .0245763    .8916035
                5  |   .3142217   .2078114     1.51   0.131    -.0930811    .7215246
                6  |   .4391426   .2121559     2.07   0.038     .0233246    .8549606
                7  |   .7237496   .2172891     3.33   0.001     .2978707    1.149628
                8  |   .4647478   .2156942     2.15   0.031     .0419949    .8875007
                9  |   .4245684    .218104     1.95   0.052    -.0029076    .8520443
               10  |   .5433166   .2431682     2.23   0.025     .0667157    1.019918
               11  |   .3354505   .2346292     1.43   0.153    -.1244144    .7953153
               12  |   .9073629   .2181482     4.16   0.000     .4798003    1.334925
               13  |   .4238891   .2108985     2.01   0.044     .0105356    .8372425
               14  |   .4563252    .205436     2.22   0.026     .0536781    .8589724
               15  |   .2766843   .2200014     1.26   0.209    -.1545106    .7078792
               16  |   .5665986   .2093545     2.71   0.007     .1562714    .9769258
               17  |   .5553742   .2135318     2.60   0.009     .1368595    .9738889
               18  |   .2709354   .2238412     1.21   0.226    -.1677853     .709656
               19  |   .2559295   .2463544     1.04   0.299    -.2269161    .7387752
               20  |   .2355239   .2097803     1.12   0.262     -.175638    .6466858
               21  |   .2913559   .2172357     1.34   0.180    -.1344182    .7171299
               22  |   .4885517   .2164189     2.26   0.024     .0643786    .9127249
               23  |   .1760042   .2197609     0.80   0.423    -.2547192    .6067276
               24  |   .1246138   .2081538     0.60   0.549    -.2833601    .5325877
               25  |   .0544645   .2330547     0.23   0.815    -.4023142    .5112433
               26  |   .2958055   .2153042     1.37   0.169     -.126183    .7177939
               27  |     .42263    .205604     2.06   0.040     .0196537    .8256064
               28  |   .2162738   .2051643     1.05   0.292    -.1858408    .6183885
               29  |   .2749923    .219969     1.25   0.211    -.1561391    .7061238
               30  |   .0451078   .1990241     0.23   0.821    -.3449722    .4351878
               31  |   .8031561   .2210454     3.63   0.000     .3699152    1.236397
               32  |    .173413   .2159099     0.80   0.422    -.2497626    .5965887
               33  |   .3699277   .2141077     1.73   0.084    -.0497156     .789571
               34  |    .572772   .2241439     2.56   0.011     .1334581    1.012086
               35  |   .4130291   .2070604     1.99   0.046     .0071982      .81886
               36  |    .338631    .223632     1.51   0.130    -.0996795    .7769416
               37  |   .1292475   .2190042     0.59   0.555    -.2999928    .5584878
               38  |   .2952293   .2042353     1.45   0.148    -.1050645    .6955231
               39  |   .4965317   .2185739     2.27   0.023     .0681347    .9249286
               40  |   .3888696   .2084078     1.87   0.062    -.0196021    .7973413
               41  |    .020227   .2205051     0.09   0.927     -.411955     .452409
               42  |    .603365   .2089963     2.89   0.004     .1937399     1.01299
               43  |   .1736303   .2241259     0.77   0.439    -.2656485    .6129091
               44  |    .026643   .2168868     0.12   0.902    -.3984474    .4517334
               45  |   .1445908   .2087335     0.69   0.488    -.2645193     .553701
               46  |    .231521   .2070746     1.12   0.264    -.1743378    .6373797
               47  |   .4002255   .2134351     1.88   0.061    -.0180997    .8185507
               48  |   .5375935   .2082827     2.58   0.010      .129367      .94582
               49  |   .2702111   .2269737     1.19   0.234    -.1746492    .7150714
               50  |   .4278306   .2091829     2.05   0.041     .0178396    .8378216
               51  |   .2820522   .2057382     1.37   0.170    -.1211874    .6852917
                   |
             _cons |   2.754037   4.422646     0.62   0.533    -5.914191    11.42226
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_knn) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_knn

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_knn |  -.3202511   .0975253    -3.28   0.001    -.5113972    -.129105
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/KNN_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/KNN_het.tex
dir : seeout

.         
. * heterogeneous effects with MLP
. *** retirement readiness
. ***** without state dummies
. logit retire_dummy overconfidence_mlp `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -2789.9313  
Iteration 1:   log pseudolikelihood = -2487.9709  
Iteration 2:   log pseudolikelihood = -2444.1885  
Iteration 3:   log pseudolikelihood = -2443.7907  
Iteration 4:   log pseudolikelihood = -2443.7903  
Iteration 5:   log pseudolikelihood = -2443.7903  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     456.16
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -2443.7903               Pseudo R2         =     0.1241

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   1.295774   .1325686     9.77   0.000     1.035945    1.555604
               age |   .0182602   .0183427     1.00   0.319    -.0176908    .0542112
              age2 |  -.0004492   .0002128    -2.11   0.035    -.0008663   -.0000321
         logincome |  -1.426216   1.017059    -1.40   0.161    -3.419615    .5671822
        logincome2 |   .0923977   .0491432     1.88   0.060    -.0039211    .1887165
      female_dummy |  -.1690245   .0930519    -1.82   0.069     -.351403    .0133539
    nonwhite_dummy |   .1780352   .0965989     1.84   0.065    -.0112951    .3673655
     marital_dummy |   .5101957   .1033913     4.93   0.000     .3075524    .7128389
 high_school_dummy |   .5596997   .1916233     2.92   0.003      .184125    .9352744
     college_dummy |   .4771959   .1014766     4.70   0.000     .2783054    .6760864
                   |
              year |
             2015  |   .0722021    .118695     0.61   0.543    -.1604358    .3048401
             2018  |   .0726672   .1173872     0.62   0.536    -.1574074    .3027418
                   |
        state_cate |
                2  |   .2355467   .3703342     0.64   0.525    -.4902949    .9613883
                3  |  -.4614807   .4040919    -1.14   0.253    -1.253486    .3305248
                4  |  -.4818994   .3855298    -1.25   0.211    -1.237524    .2737251
                5  |  -.2124313   .3093383    -0.69   0.492    -.8187232    .3938605
                6  |   -.405105   .3833184    -1.06   0.291    -1.156395    .3461853
                7  |  -.2882013   .3777937    -0.76   0.446    -1.028663    .4522608
                8  |  -.2555508    .389983    -0.66   0.512    -1.019903    .5088019
                9  |   .0585236   .3581687     0.16   0.870    -.6434742    .7605213
               10  |  -.0008352   .3341334    -0.00   0.998    -.6557247    .6540542
               11  |  -.5051446    .342255    -1.48   0.140    -1.175952    .1656629
               12  |  -1.130234   .5521947    -2.05   0.041    -2.212516   -.0479521
               13  |  -1.182191   .6965319    -1.70   0.090    -2.547369    .1829859
               14  |  -.4367084   .3421075    -1.28   0.202    -1.107227      .23381
               15  |   -.579074   .3998576    -1.45   0.148    -1.362781    .2046326
               16  |  -.4957284   .4156932    -1.19   0.233    -1.310472    .3190154
               17  |  -.2895006   .4083691    -0.71   0.478    -1.089889    .5108881
               18  |   .0611544   .3660771     0.17   0.867    -.6563435    .7786524
               19  |  -.5734157   .3765828    -1.52   0.128    -1.311504    .1646731
               20  |  -.4077032   .4029358    -1.01   0.312    -1.197443    .3820365
               21  |  -.4847455   .3782511    -1.28   0.200    -1.226104    .2566131
               22  |  -.0005056   .3735428    -0.00   0.999    -.7326359    .7316248
               23  |  -.1413054   .3320356    -0.43   0.670    -.7920833    .5094724
               24  |  -.5860467   .3789479    -1.55   0.122    -1.328771    .1566775
               25  |  -.6177185   .3596555    -1.72   0.086     -1.32263    .0871933
               26  |  -.8568896   .3977783    -2.15   0.031    -1.636521   -.0772585
               27  |  -.1743065   .4297644    -0.41   0.685    -1.016629    .6680163
               28  |  -.7739848   .4441783    -1.74   0.081    -1.644558    .0965886
               29  |  -.1634951   .3635077    -0.45   0.653    -.8759572     .548967
               30  |  -.1774095   .4352745    -0.41   0.684    -1.030532    .6757129
               31  |  -.3611774   .3381337    -1.07   0.285    -1.023907    .3015524
               32  |  -.0803134   .3999824    -0.20   0.841    -.8642645    .7036378
               33  |  -.4029425   .3153254    -1.28   0.201    -1.020969    .2150839
               34  |  -.9519115   .3936301    -2.42   0.016    -1.723412   -.1804105
               35  |   -.038334   .3801747    -0.10   0.920    -.7834627    .7067947
               36  |  -.6545547   .3980363    -1.64   0.100    -1.434691    .1255821
               37  |  -.4120205   .3793081    -1.09   0.277    -1.155451    .3314097
               38  |  -.5906269   .3643792    -1.62   0.105    -1.304797    .1235432
               39  |  -.6431738   .3705324    -1.74   0.083    -1.369404    .0830564
               40  |  -.8632811   .4075144    -2.12   0.034    -1.661995   -.0645676
               41  |  -.4024164    .353842    -1.14   0.255    -1.095934    .2911011
               42  |   -.207018   .4357013    -0.48   0.635    -1.060977     .646941
               43  |  -.1752765   .3700134    -0.47   0.636    -.9004894    .5499364
               44  |  -.5325388   .3336307    -1.60   0.110    -1.186443    .1213654
               45  |  -.7030822   .4613599    -1.52   0.128    -1.607331    .2011666
               46  |  -.4201756   .4162234    -1.01   0.313    -1.235959    .3956073
               47  |  -.0635581   .3473873    -0.18   0.855    -.7444247    .6173085
               48  |  -.3176102   .3324924    -0.96   0.339    -.9692832    .3340629
               49  |  -.1752228   .3811165    -0.46   0.646    -.9221975    .5717519
               50  |  -.5741681   .4278856    -1.34   0.180    -1.412808    .2644722
               51  |  -.1275844   .4010039    -0.32   0.750    -.9135375    .6583687
                   |
             _cons |   2.068588   5.244527     0.39   0.693    -8.210496    12.34767
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .1453983   .0144946    10.03   0.000     .1169895    .1738071
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP_het.tex", tex replace addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/MLP_het.tex
dir : seeout

. 
. ***** with state dummies
. logit retire_dummy overconfidence_mlp `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =   -7639.91  
Iteration 1:   log pseudolikelihood = -6361.7492  
Iteration 2:   log pseudolikelihood = -6348.4995  
Iteration 3:   log pseudolikelihood = -6348.4614  
Iteration 4:   log pseudolikelihood = -6348.4614  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1620.38
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6348.4614               Pseudo R2         =     0.1690

------------------------------------------------------------------------------------
                   |               Robust
      retire_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |  -2.887484   .4583877    -6.30   0.000    -3.785907    -1.98906
               age |   .2141091   .0128901    16.61   0.000      .188845    .2393731
              age2 |  -.0026431   .0001268   -20.84   0.000    -.0028917   -.0023946
         logincome |  -1.859784   .7074471    -2.63   0.009    -3.246355   -.4732134
        logincome2 |   .1089742   .0322736     3.38   0.001     .0457192    .1722293
      female_dummy |  -.0016763   .0507904    -0.03   0.974    -.1012236    .0978711
    nonwhite_dummy |   .1141245   .0705861     1.62   0.106    -.0242216    .2524707
     marital_dummy |  -.0360676    .060867    -0.59   0.553    -.1553648    .0832296
 high_school_dummy |   .2781726   .4005815     0.69   0.487    -.5069527    1.063298
     college_dummy |   .2726206   .0543293     5.02   0.000     .1661371     .379104
                   |
              year |
             2015  |   .0170995   .0590733     0.29   0.772     -.098682    .1328811
             2018  |   .0872466   .0623161     1.40   0.161    -.0348908    .2093839
                   |
        state_cate |
                2  |  -.0233148     .21565    -0.11   0.914     -.445981    .3993515
                3  |  -.1455934   .2290077    -0.64   0.525    -.5944403    .3032534
                4  |  -.5388589   .2335149    -2.31   0.021    -.9965396   -.0811781
                5  |  -.3821021   .2232873    -1.71   0.087    -.8197371     .055533
                6  |  -.1071486   .2239655    -0.48   0.632    -.5461129    .3318157
                7  |  -.0497642   .2192843    -0.23   0.820    -.4795535    .3800251
                8  |  -.3064692   .2173495    -1.41   0.159    -.7324663    .1195279
                9  |  -.0927559   .2255901    -0.41   0.681    -.5349043    .3493926
               10  |  -.4645945   .2544677    -1.83   0.068    -.9633421    .0341531
               11  |  -.3319947    .235475    -1.41   0.159    -.7935172    .1295279
               12  |   -.314095   .2126094    -1.48   0.140    -.7308018    .1026118
               13  |  -.2922428    .222756    -1.31   0.190    -.7288366     .144351
               14  |  -.0634157    .215491    -0.29   0.769    -.4857704     .358939
               15  |   .2464212   .2287279     1.08   0.281    -.2018772    .6947196
               16  |  -.1080482   .2210693    -0.49   0.625    -.5413361    .3252397
               17  |  -.1813155   .2188344    -0.83   0.407     -.610223     .247592
               18  |    .064051   .2334335     0.27   0.784    -.3934703    .5215723
               19  |  -.0517154   .2676386    -0.19   0.847    -.5762774    .4728466
               20  |   .2319824   .2172144     1.07   0.286      -.19375    .6577147
               21  |   -.206106   .2265923    -0.91   0.363    -.6502188    .2380067
               22  |  -.1446702   .2177375    -0.66   0.506    -.5714279    .2820874
               23  |  -.3139709   .2339623    -1.34   0.180    -.7725285    .1445867
               24  |  -.3684769   .2134384    -1.73   0.084    -.7868084    .0498546
               25  |  -.0194047   .2318639    -0.08   0.933    -.4738496    .4350402
               26  |  -.3425807   .2281577    -1.50   0.133    -.7897616    .1046003
               27  |   .1615902   .2117332     0.76   0.445    -.2533992    .5765796
               28  |  -.0067552    .218305    -0.03   0.975    -.4346251    .4211146
               29  |  -.3300306   .2346627    -1.41   0.160     -.789961    .1298997
               30  |  -.1954562   .2113287    -0.92   0.355    -.6096528    .2187403
               31  |  -.3401726   .2291759    -1.48   0.138    -.7893492     .109004
               32  |  -.5411953   .2278077    -2.38   0.018    -.9876902   -.0947003
               33  |  -.0959415    .224524    -0.43   0.669    -.5360005    .3441176
               34  |  -.0784265   .2257681    -0.35   0.728     -.520924    .3640709
               35  |   .2316146   .2192936     1.06   0.291     -.198193    .6614222
               36  |  -.1858542   .2363229    -0.79   0.432    -.6490385    .2773301
               37  |  -.2027545    .220019    -0.92   0.357    -.6339838    .2284747
               38  |  -.0854823   .2125973    -0.40   0.688    -.5021654    .3312009
               39  |  -.2256314   .2321333    -0.97   0.331    -.6806044    .2293416
               40  |  -.3822187   .2193708    -1.74   0.081    -.8121775    .0477401
               41  |  -.3368566   .2328396    -1.45   0.148    -.7932139    .1195006
               42  |   .0006179   .2126976     0.00   0.998    -.4162618    .4174976
               43  |  -.1657875   .2370676    -0.70   0.484    -.6304316    .2988565
               44  |  -.4179486   .2296329    -1.82   0.069    -.8680209    .0321236
               45  |   .1655213   .2169989     0.76   0.446    -.2597887    .5908313
               46  |  -.2367851   .2121147    -1.12   0.264    -.6525223    .1789521
               47  |  -.3235365   .2220327    -1.46   0.145    -.7587126    .1116395
               48  |  -.3320531   .2137069    -1.55   0.120     -.750911    .0868047
               49  |   .1894702   .2320929     0.82   0.414    -.2654234    .6443639
               50  |   -.184118   .2171721    -0.85   0.397    -.6097675    .2415315
               51  |   .2037137   .2118147     0.96   0.336    -.2114355    .6188629
                   |
             _cons |   3.319672   3.903887     0.85   0.395    -4.331806    10.97115
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(retire_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   -.558836   .0879363    -6.36   0.000    -.7311881    -.386484
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Readiness")
../outputs/tables/MLP_het.tex
dir : seeout

.         
. *** precautionary saving
. ***** low true literacy subgroup
. logit precaution_dummy overconfidence_mlp `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -3717.9486  
Iteration 1:   log pseudolikelihood = -3356.6527  
Iteration 2:   log pseudolikelihood =   -3344.63  
Iteration 3:   log pseudolikelihood = -3344.5865  
Iteration 4:   log pseudolikelihood = -3344.5865  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     460.39
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -3344.5865               Pseudo R2         =     0.1004

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   1.211505   .1195971    10.13   0.000     .9770993    1.445911
               age |  -.0959209   .0139865    -6.86   0.000     -.123334   -.0685078
              age2 |     .00107   .0001575     6.79   0.000     .0007613    .0013787
         logincome |  -1.592923   .8432183    -1.89   0.059      -3.2456    .0597549
        logincome2 |    .104181    .041095     2.54   0.011     .0236362    .1847258
      female_dummy |  -.0924097   .0782245    -1.18   0.237    -.2457269    .0609076
    nonwhite_dummy |  -.0125998    .082474    -0.15   0.879    -.1742458    .1490462
     marital_dummy |   .2053835   .0835496     2.46   0.014     .0416294    .3691377
 high_school_dummy |   .4004828   .1372764     2.92   0.004      .131426    .6695395
     college_dummy |   .3804322   .0885501     4.30   0.000     .2068773    .5539871
                   |
              year |
             2015  |   .0063033   .0973488     0.06   0.948    -.1844967    .1971034
             2018  |   .0685241   .0942289     0.73   0.467    -.1161611    .2532093
                   |
        state_cate |
                2  |   .2552015   .3427682     0.74   0.457    -.4166118    .9270147
                3  |  -.2206791   .3296846    -0.67   0.503     -.866849    .4254907
                4  |  -.5203241   .3050877    -1.71   0.088    -1.118285    .0776368
                5  |  -.1866646   .2761714    -0.68   0.499    -.7279505    .3546213
                6  |  -.3426026   .3287832    -1.04   0.297    -.9870058    .3018005
                7  |  -.5586142   .3355268    -1.66   0.096    -1.216235    .0990062
                8  |  -.4653541   .3456557    -1.35   0.178    -1.142827    .2121186
                9  |  -.1195212   .3140887    -0.38   0.704    -.7351238    .4960814
               10  |  -.4056005   .2959976    -1.37   0.171    -.9857451    .1745441
               11  |  -.3510255   .2951494    -1.19   0.234    -.9295076    .2274566
               12  |  -.3422186   .3449189    -0.99   0.321    -1.018247      .33381
               13  |  -.2415747   .3551402    -0.68   0.496    -.9376366    .4544872
               14  |  -.0284683   .2891515    -0.10   0.922    -.5951949    .5382582
               15  |  -.8233804   .3442973    -2.39   0.017    -1.498191     -.14857
               16  |  -.4333541   .3430522    -1.26   0.207    -1.105724    .2390159
               17  |  -.1528935   .3212354    -0.48   0.634    -.7825032    .4767163
               18  |  -.2552875   .3114752    -0.82   0.412    -.8657676    .3551927
               19  |  -.2638638   .3041203    -0.87   0.386    -.8599287    .3322011
               20  |  -.5828899   .3351416    -1.74   0.082    -1.239755    .0739755
               21  |  -.8205489   .3212106    -2.55   0.011     -1.45011   -.1909877
               22  |  -.5483845   .3286789    -1.67   0.095    -1.192583    .0958143
               23  |   -.381792   .2968274    -1.29   0.198     -.963563     .199979
               24  |  -.2387003   .3148033    -0.76   0.448    -.8557034    .3783028
               25  |  -.3230135   .2917791    -1.11   0.268    -.8948901     .248863
               26  |  -.5533768    .313458    -1.77   0.077    -1.167743    .0609896
               27  |  -1.164028   .4481177    -2.60   0.009    -2.042323   -.2857336
               28  |  -.1165231   .3370374    -0.35   0.730    -.7771042     .544058
               29  |  -.4972777   .3188085    -1.56   0.119    -1.122131    .1275756
               30  |   .1873365   .3235175     0.58   0.563    -.4467461     .821419
               31  |  -.9185374   .3010555    -3.05   0.002    -1.508595   -.3284795
               32  |  -.1279191   .3529238    -0.36   0.717    -.8196371    .5637989
               33  |  -.3124952   .2698722    -1.16   0.247    -.8414351    .2164446
               34  |  -.0372202   .2837706    -0.13   0.896    -.5934003    .5189598
               35  |   .4387103   .3231718     1.36   0.175    -.1946948    1.072115
               36  |  -.1669092   .3076775    -0.54   0.587     -.769946    .4361276
               37  |  -.8790974   .3375979    -2.60   0.009    -1.540777   -.2174177
               38  |  -.3520992   .3140307    -1.12   0.262    -.9675881    .2633897
               39  |  -.7667095   .3092349    -2.48   0.013    -1.372799   -.1606203
               40  |  -.5327512   .3206777    -1.66   0.097    -1.161268    .0957656
               41  |   -.217654   .2991473    -0.73   0.467    -.8039719    .3686638
               42  |  -.7284791   .3763047    -1.94   0.053    -1.466023    .0090646
               43  |  -.2377349    .297708    -0.80   0.425    -.8212319    .3457621
               44  |  -.1273077   .2758566    -0.46   0.644    -.6679767    .4133613
               45  |  -.6637909   .3754329    -1.77   0.077    -1.399626    .0720441
               46  |  -.5261251   .3607941    -1.46   0.145    -1.233269    .1810184
               47  |  -.4343371   .3193626    -1.36   0.174    -1.060276    .1916022
               48  |  -.4343053   .2910675    -1.49   0.136    -1.004787    .1361765
               49  |  -.6917077    .319964    -2.16   0.031    -1.318826   -.0645898
               50  |   -.786955   .3452116    -2.28   0.023    -1.463557   -.1103526
               51  |  -.8592398   .3771471    -2.28   0.023    -1.598435   -.1200451
                   |
             _cons |   5.442046   4.307491     1.26   0.206    -3.000482    13.88457
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |    .201378   .0191309    10.53   0.000     .1638821    .2388738
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/MLP_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit precaution_dummy overconfidence_mlp `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -6836.5088  
Iteration 1:   log pseudolikelihood = -5934.1703  
Iteration 2:   log pseudolikelihood = -5909.6227  
Iteration 3:   log pseudolikelihood = -5909.5251  
Iteration 4:   log pseudolikelihood = -5909.5251  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =    1134.39
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -5909.5251               Pseudo R2         =     0.1356

------------------------------------------------------------------------------------
                   |               Robust
  precaution_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |  -3.342448   .4216142    -7.93   0.000    -4.168796   -2.516099
               age |  -.1058024   .0135144    -7.83   0.000    -.1322902   -.0793146
              age2 |   .0013866   .0001349    10.28   0.000     .0011222    .0016511
         logincome |  -.7558812   .7548318    -1.00   0.317    -2.235324    .7235619
        logincome2 |   .0673102   .0348393     1.93   0.053    -.0009737     .135594
      female_dummy |   .0584901   .0535939     1.09   0.275     -.046552    .1635321
    nonwhite_dummy |  -.2297895   .0729833    -3.15   0.002     -.372834   -.0867449
     marital_dummy |  -.0366953   .0609208    -0.60   0.547    -.1560979    .0827072
 high_school_dummy |   .8385769   .3178104     2.64   0.008     .2156799    1.461474
     college_dummy |   .3608536   .0565328     6.38   0.000     .2500513    .4716558
                   |
              year |
             2015  |   .3099929   .0609035     5.09   0.000     .1906242    .4293616
             2018  |   .3627851   .0650636     5.58   0.000     .2352628    .4903075
                   |
        state_cate |
                2  |   .1364926    .239435     0.57   0.569    -.3327914    .6057767
                3  |   .1832841    .239085     0.77   0.443     -.285314    .6518822
                4  |   .2088238   .2546647     0.82   0.412    -.2903098    .7079573
                5  |   .0531415   .2386805     0.22   0.824    -.4146636    .5209466
                6  |    .292889   .2381179     1.23   0.219    -.1738135    .7595914
                7  |   .2455155   .2499472     0.98   0.326     -.244372    .7354031
                8  |   .2442496   .2532621     0.96   0.335     -.252135    .7406342
                9  |  -.0946485   .2371615    -0.40   0.690    -.5594764    .3701795
               10  |   .2189003   .2710891     0.81   0.419    -.3124246    .7502251
               11  |  -.0195894   .2619846    -0.07   0.940    -.5330697     .493891
               12  |   .3507737   .2429614     1.44   0.149    -.1254219    .8269693
               13  |  -.0311274   .2361447    -0.13   0.895    -.4939626    .4317078
               14  |   .2499787   .2354425     1.06   0.288    -.2114801    .7114376
               15  |   .0700292   .2545404     0.28   0.783    -.4288607    .5689191
               16  |   .3017164   .2417761     1.25   0.212    -.1721561    .7755889
               17  |   .2076119   .2413498     0.86   0.390    -.2654251    .6806488
               18  |   .1987323   .2580973     0.77   0.441    -.3071292    .7045937
               19  |   .0525261   .2640995     0.20   0.842    -.4650994    .5701517
               20  |   -.271392    .239871    -1.13   0.258    -.7415305    .1987464
               21  |  -.0632029   .2346403    -0.27   0.788    -.5230894    .3966835
               22  |   .3821916   .2496399     1.53   0.126    -.1070935    .8714768
               23  |   .1817391   .2532485     0.72   0.473    -.3146189    .6780971
               24  |   .2173272   .2399812     0.91   0.365    -.2530274    .6876818
               25  |  -.1604534   .2572302    -0.62   0.533    -.6646154    .3437087
               26  |   .1757645   .2483416     0.71   0.479     -.310976    .6625051
               27  |   .2933145   .2323737     1.26   0.207    -.1621296    .7487587
               28  |   .0276571    .235929     0.12   0.907    -.4347553    .4900695
               29  |   .1680958   .2570724     0.65   0.513    -.3357568    .6719483
               30  |  -.0760017   .2266772    -0.34   0.737    -.5202809    .3682775
               31  |   .0265205   .2435531     0.11   0.913    -.4508347    .5038757
               32  |   .1491188   .2436282     0.61   0.540    -.3283837    .6266213
               33  |    .208223   .2502123     0.83   0.405     -.282184    .6986301
               34  |    .077346   .2508674     0.31   0.758     -.414345    .5690371
               35  |   .2725092    .236989     1.15   0.250    -.1919807    .7369992
               36  |  -.0717481    .251457    -0.29   0.775    -.5645948    .4210986
               37  |  -.0326976   .2479241    -0.13   0.895    -.5186199    .4532246
               38  |  -.0449313   .2364137    -0.19   0.849    -.5082936     .418431
               39  |   .0687758   .2436739     0.28   0.778    -.4088162    .5463679
               40  |   .1349272   .2409356     0.56   0.575    -.3372979    .6071523
               41  |   .0202035   .2570026     0.08   0.937    -.4835123    .5239194
               42  |   .4396595   .2371728     1.85   0.064    -.0251906    .9045095
               43  |  -.0613349   .2603365    -0.24   0.814    -.5715849    .4489152
               44  |   .0696411   .2487842     0.28   0.780     -.417967    .5572493
               45  |  -.0318061   .2382921    -0.13   0.894    -.4988501    .4352379
               46  |   -.005151   .2322148    -0.02   0.982    -.4602837    .4499817
               47  |  -.0460992   .2467243    -0.19   0.852    -.5296698    .4374715
               48  |   .3057998   .2402747     1.27   0.203    -.1651298    .7767295
               49  |   .3068676    .265899     1.15   0.248    -.2142848      .82802
               50  |  -.1039844   .2333948    -0.45   0.656    -.5614298    .3534611
               51  |   .1926083   .2365884     0.81   0.416    -.2710965    .6563131
                   |
             _cons |   1.151917   4.094438     0.28   0.778    -6.873035    9.176868
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(precaution_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |  -.5901815   .0735401    -8.03   0.000    -.7343175   -.4460455
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Precaution")
../outputs/tables/MLP_het.tex
dir : seeout

.         
. *** financial market participation
. ***** low true literacy subgroup
. logit fin_par_dummy overconfidence_mlp `household_X' ///
>         i.year i.state_cate if fin_low_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood =  -2155.857  
Iteration 1:   log pseudolikelihood = -1889.6565  
Iteration 2:   log pseudolikelihood = -1769.0621  
Iteration 3:   log pseudolikelihood = -1764.7839  
Iteration 4:   log pseudolikelihood = -1764.7713  
Iteration 5:   log pseudolikelihood = -1764.7713  

Logistic regression                             Number of obs     =      5,886
                                                Wald chi2(62)     =     560.00
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -1764.7713               Pseudo R2         =     0.1814

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   1.221932   .1446435     8.45   0.000     .9384358    1.505428
               age |  -.0759012   .0199939    -3.80   0.000    -.1150885   -.0367139
              age2 |   .0009612   .0002226     4.32   0.000      .000525    .0013975
         logincome |   .8112102   1.303301     0.62   0.534    -1.743213    3.365634
        logincome2 |   .0075895   .0615644     0.12   0.902    -.1130745    .1282535
      female_dummy |  -.3506369   .1103996    -3.18   0.001    -.5670161   -.1342577
    nonwhite_dummy |  -.2155583   .1249376    -1.73   0.084    -.4604315     .029315
     marital_dummy |   .1055676   .1239057     0.85   0.394    -.1372832    .3484184
 high_school_dummy |   .9432488   .2703892     3.49   0.000     .4132957    1.473202
     college_dummy |   .4389791   .1225075     3.58   0.000     .1988688    .6790894
                   |
              year |
             2015  |  -.1811338   .1370752    -1.32   0.186    -.4497963    .0875288
             2018  |   -.294723    .136133    -2.16   0.030    -.5615388   -.0279072
                   |
        state_cate |
                2  |   .2921624   .4642662     0.63   0.529    -.6177825    1.202107
                3  |  -.1371507   .4825827    -0.28   0.776    -1.082995     .808694
                4  |  -.3948859   .5018032    -0.79   0.431    -1.378402    .5886303
                5  |   .2773621   .4081924     0.68   0.497    -.5226804    1.077405
                6  |   .2117023   .4882742     0.43   0.665    -.7452975    1.168702
                7  |  -.1154424   .4790155    -0.24   0.810    -1.054296    .8234108
                8  |  -.3066438   .5519078    -0.56   0.578    -1.388363    .7750755
                9  |   .5150382   .4242285     1.21   0.225    -.3164345    1.346511
               10  |  -.1037386   .4705453    -0.22   0.826     -1.02599    .8185133
               11  |  -.1795828   .4767672    -0.38   0.706    -1.114029    .7548637
               12  |  -.7448725   .7095255    -1.05   0.294    -2.135517    .6457719
               13  |  -1.167294   .6333217    -1.84   0.065    -2.408581    .0739939
               14  |  -.1272223   .4231036    -0.30   0.764      -.95649    .7020455
               15  |  -1.549403   .6957541    -2.23   0.026    -2.913056   -.1857502
               16  |  -.1975152   .5313563    -0.37   0.710    -1.238954    .8439239
               17  |  -.2233605    .513316    -0.44   0.663    -1.229441    .7827204
               18  |    .072784   .4669893     0.16   0.876    -.8424982    .9880662
               19  |  -.6171549   .5505785    -1.12   0.262    -1.696269    .4619591
               20  |   .1246501   .5128874     0.24   0.808    -.8805908    1.129891
               21  |   .3813363   .4423782     0.86   0.389    -.4857091    1.248382
               22  |  -.4889344   .5350099    -0.91   0.361    -1.537535    .5596657
               23  |   .2306577   .4408721     0.52   0.601    -.6334357    1.094751
               24  |  -.1191915   .4790846    -0.25   0.804     -1.05818    .8197972
               25  |  -.3827288   .4909813    -0.78   0.436    -1.345034    .5795769
               26  |   .2294384   .4501069     0.51   0.610    -.6527548    1.111632
               27  |   .4039637   .5220341     0.77   0.439    -.6192043    1.427132
               28  |   .8900913   .4637028     1.92   0.055    -.0187495    1.798932
               29  |  -.0247758   .4909682    -0.05   0.960    -.9870558    .9375043
               30  |   .0116015   .4777255     0.02   0.981    -.9247232    .9479262
               31  |  -.4419893   .4545806    -0.97   0.331    -1.332951    .4489723
               32  |  -.1225554   .5764977    -0.21   0.832     -1.25247    1.007359
               33  |   .2184653   .3951135     0.55   0.580    -.5559429    .9928735
               34  |  -.1843216   .4742479    -0.39   0.698     -1.11383    .7451872
               35  |   .4247102   .4524049     0.94   0.348    -.4619871    1.311408
               36  |  -.1128315   .4675319    -0.24   0.809    -1.029177    .8035141
               37  |   .1266882   .4665478     0.27   0.786    -.7877287    1.041105
               38  |    .365641   .4723115     0.77   0.439    -.5600724    1.291354
               39  |   .0597444   .4410622     0.14   0.892    -.8047216    .9242103
               40  |  -.4406176   .5017983    -0.88   0.380    -1.424124    .5428889
               41  |   .3996997   .4396089     0.91   0.363     -.461918    1.261317
               42  |   -.080358   .5132367    -0.16   0.876    -1.086284    .9255674
               43  |  -.0008866   .5111006    -0.00   0.999    -1.002625    1.000852
               44  |  -.2534673   .4244851    -0.60   0.550    -1.085443    .5785083
               45  |  -.0543282   .6114456    -0.09   0.929     -1.25274    1.144083
               46  |   .3676504     .47608     0.77   0.440    -.5654492     1.30075
               47  |  -.2293676   .4874843    -0.47   0.638    -1.184819    .7260841
               48  |   .2466238   .4246094     0.58   0.561    -.5855953    1.078843
               49  |  -.2007999   .4849284    -0.41   0.679    -1.151242    .7496422
               50  |  -.4626029   .5378183    -0.86   0.390    -1.516707    .5915016
               51  |   .3596227   .5499265     0.65   0.513    -.7182134    1.437459
                   |
             _cons |  -11.37756   6.921158    -1.64   0.100    -24.94278    2.187663
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp) post

Average marginal effects                        Number of obs     =      5,886
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |   .0943189   .0110886     8.51   0.000     .0725856    .1160523
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP_het.tex", tex append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, Low Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/MLP_het.tex
dir : seeout

. 
. ***** high true literacy subgroup
. logit fin_par_dummy overconfidence_mlp `household_X' ///
>         i.year i.state_cate if fin_high_dummy == 1 [pw=weights]

Iteration 0:   log pseudolikelihood = -7436.5574  
Iteration 1:   log pseudolikelihood = -6619.5792  
Iteration 2:   log pseudolikelihood = -6615.6214  
Iteration 3:   log pseudolikelihood = -6615.6202  
Iteration 4:   log pseudolikelihood = -6615.6202  

Logistic regression                             Number of obs     =     12,539
                                                Wald chi2(62)     =     998.71
                                                Prob > chi2       =     0.0000
Log pseudolikelihood = -6615.6202               Pseudo R2         =     0.1104

------------------------------------------------------------------------------------
                   |               Robust
     fin_par_dummy |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |  -2.779501   .4095552    -6.79   0.000    -3.582215   -1.976788
               age |  -.0563994   .0128267    -4.40   0.000    -.0815393   -.0312594
              age2 |   .0007927   .0001257     6.30   0.000     .0005462    .0010391
         logincome |  -.9248809   .7596623    -1.22   0.223    -2.413792    .5640299
        logincome2 |   .0759426    .034669     2.19   0.028     .0079925    .1438926
      female_dummy |  -.0939651   .0490411    -1.92   0.055    -.1900838    .0021537
    nonwhite_dummy |  -.0401568     .06962    -0.58   0.564    -.1766094    .0962958
     marital_dummy |  -.0283851   .0564096    -0.50   0.615    -.1389459    .0821757
 high_school_dummy |   .8734539   .3775462     2.31   0.021      .133477    1.613431
     college_dummy |   .3655745   .0522449     7.00   0.000     .2631764    .4679725
                   |
              year |
             2015  |  -.2374994   .0570099    -4.17   0.000    -.3492366   -.1257621
             2018  |  -.1881656   .0605795    -3.11   0.002    -.3068993    -.069432
                   |
        state_cate |
                2  |   .3970909   .2084789     1.90   0.057    -.0115203    .8057021
                3  |   .4233541   .2078666     2.04   0.042      .015943    .8307652
                4  |   .4435931   .2200477     2.02   0.044     .0123075    .8748786
                5  |   .3387508   .2063825     1.64   0.101    -.0657514     .743253
                6  |   .4366868   .2107326     2.07   0.038     .0236584    .8497152
                7  |   .7186175   .2161137     3.33   0.001     .2950424    1.142193
                8  |   .4553638   .2147707     2.12   0.034     .0344209    .8763067
                9  |   .4313807   .2174279     1.98   0.047     .0052298    .8575316
               10  |   .5453723   .2429855     2.24   0.025     .0691295    1.021615
               11  |   .3301649   .2345169     1.41   0.159    -.1294798    .7898096
               12  |   .9217929   .2191649     4.21   0.000     .4922377    1.351348
               13  |   .4179062   .2108538     1.98   0.047     .0046403     .831172
               14  |   .4630563   .2050144     2.26   0.024     .0612355    .8648771
               15  |   .2767734   .2206759     1.25   0.210    -.1557435    .7092903
               16  |   .5535863   .2081052     2.66   0.008     .1457076    .9614651
               17  |   .5644273   .2141399     2.64   0.008     .1447209    .9841337
               18  |    .275854   .2234695     1.23   0.217    -.1621382    .7138462
               19  |   .2634133   .2454755     1.07   0.283    -.2177097    .7445364
               20  |   .2368691    .209083     1.13   0.257     -.172926    .6466642
               21  |   .2979009   .2169305     1.37   0.170     -.127275    .7230768
               22  |   .4793823   .2157046     2.22   0.026      .056609    .9021556
               23  |   .1966976   .2192179     0.90   0.370    -.2329615    .6263567
               24  |   .1294722   .2072807     0.62   0.532    -.2767905    .5357349
               25  |   .0364574   .2313736     0.16   0.875    -.4170265    .4899412
               26  |    .308692    .215192     1.43   0.151    -.1130765    .7304605
               27  |   .4192668   .2052831     2.04   0.041     .0169194    .8216143
               28  |   .2051065   .2044046     1.00   0.316    -.1955192    .6057322
               29  |   .2590154   .2196549     1.18   0.238    -.1715002    .6895311
               30  |   .0395954    .198543     0.20   0.842    -.3495417    .4287325
               31  |   .8009598   .2192466     3.65   0.000     .3712443    1.230675
               32  |   .1671853   .2152373     0.78   0.437    -.2546721    .5890427
               33  |    .384376   .2138425     1.80   0.072    -.0347477    .8034997
               34  |     .57842    .224084     2.58   0.010     .1392234    1.017617
               35  |   .4154105   .2070834     2.01   0.045     .0095345    .8212865
               36  |   .3371063   .2241162     1.50   0.133    -.1021534    .7763659
               37  |   .1102809   .2181448     0.51   0.613    -.3172751    .5378369
               38  |   .2980071   .2042643     1.46   0.145    -.1023437    .6983578
               39  |   .4932492   .2174382     2.27   0.023     .0670781    .9194202
               40  |   .3971042   .2082811     1.91   0.057    -.0111193    .8053276
               41  |   .0149421    .219969     0.07   0.946    -.4161891    .4460734
               42  |   .5953941   .2076909     2.87   0.004     .1883274    1.002461
               43  |   .1695556   .2248627     0.75   0.451    -.2711672    .6102784
               44  |   .0347581    .215808     0.16   0.872    -.3882178    .4577341
               45  |   .1360563   .2075249     0.66   0.512     -.270685    .5427976
               46  |   .2279477   .2063972     1.10   0.269    -.1765834    .6324788
               47  |    .399401   .2126193     1.88   0.060    -.0173252    .8161271
               48  |   .5465855   .2086638     2.62   0.009      .137612    .9555591
               49  |    .270688    .226254     1.20   0.232    -.1727616    .7141376
               50  |   .4588318   .2085986     2.20   0.028      .049986    .8676776
               51  |   .2613401   .2050589     1.27   0.202     -.140568    .6632482
                   |
             _cons |   .7085018   4.219762     0.17   0.867     -7.56208    8.979083
------------------------------------------------------------------------------------

. scalar r2 = e(r2_p)

. margins, dydx(overconfidence_mlp) post

Average marginal effects                        Number of obs     =     12,539
Model VCE    : Robust

Expression   : Pr(fin_par_dummy), predict()
dy/dx w.r.t. : overconfidence_mlp

------------------------------------------------------------------------------------
                   |            Delta-method
                   |      dy/dx   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------------+----------------------------------------------------------------
overconfidence_mlp |  -.5662993   .0825256    -6.86   0.000    -.7280466   -.4045521
------------------------------------------------------------------------------------

. outreg2 using "${tables_dir}/MLP_het.tex", tex word append addstat(Pseudo R-squared, r2) ///
>         addtext(Sample, High Lit., Demo. chars., Yes, Year dummies, Yes, State dummies, Yes) ///
>         ctitle("Participation")
../outputs/tables/MLP_het.tex
../outputs/tables/MLP_het.rtf
dir : seeout

. 
. * stop capturing log and translate into pdf
. log close analysis_NFCS
      name:  analysis_NFCS
       log:  C:\Users\Thinkpad\Perspective\Overconfidence-Financial-Behaviors\codes\../outputs/log
> s/analysis_log.smcl
  log type:  text
 closed on:  11 Jun 2020, 19:05:23
--------------------------------------------------------------------------------------------------
